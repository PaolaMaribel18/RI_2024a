{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaolaMaribel18/RI_2024a/blob/main/week11/podcast_ir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Q0eSY1ns7c",
        "outputId": "4d96d224-57b6-4324-9f76-ab83d41ad63e"
      },
      "id": "f3Q0eSY1ns7c",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "333ae546d607a744"
      },
      "cell_type": "markdown",
      "source": [
        "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
        "\n",
        "## Objective:\n",
        "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
      ],
      "id": "333ae546d607a744"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions:\n",
        "\n",
        "### Step 1: Import Libraries\n",
        "Import necessary libraries for data handling, text processing, and machine learning.\n"
      ],
      "metadata": {
        "id": "MTFo3RlkoD0y"
      },
      "id": "MTFo3RlkoD0y"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "import gensim.downloader as api\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "XsR5gWH-oGC8"
      },
      "id": "XsR5gWH-oGC8",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmo5I81YoM9I",
        "outputId": "851e7bc0-3732-417f-efb3-0f2d9e91e030"
      },
      "id": "tmo5I81YoM9I",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_set = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "yFbHSJFsrOe1"
      },
      "id": "yFbHSJFsrOe1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stopwords_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJDwMeCEwvWB",
        "outputId": "4c7657eb-002d-4c90-d8fc-9d7467d9f64a"
      },
      "id": "sJDwMeCEwvWB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load the Dataset\n",
        "\n",
        "Load the dataset of podcast transcripts.\n",
        "\n",
        "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
      ],
      "metadata": {
        "id": "iXQlknIaoksD"
      },
      "id": "iXQlknIaoksD"
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/week11/data/podcastdata_dataset.csv'\n",
        "podcast_df = pd.read_csv(file_path, index_col=0)\n",
        "podcast_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "3ZBb730Lot1Z",
        "outputId": "81a786c8-0e1b-45ed-adea-e7f78c55ffb4"
      },
      "id": "3ZBb730Lot1Z",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              guest                    title  \\\n",
              "id                                             \n",
              "1       Max Tegmark                 Life 3.0   \n",
              "2     Christof Koch            Consciousness   \n",
              "3     Steven Pinker  AI in the Age of Reason   \n",
              "4     Yoshua Bengio            Deep Learning   \n",
              "5   Vladimir Vapnik     Statistical Learning   \n",
              "\n",
              "                                                 text  \n",
              "id                                                     \n",
              "1   As part of MIT course 6S099, Artificial Genera...  \n",
              "2   As part of MIT course 6S099 on artificial gene...  \n",
              "3   You've studied the human mind, cognition, lang...  \n",
              "4   What difference between biological neural netw...  \n",
              "5   The following is a conversation with Vladimir ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c57585f4-d77f-4a80-9c2b-f7d063a04ae1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guest</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Max Tegmark</td>\n",
              "      <td>Life 3.0</td>\n",
              "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christof Koch</td>\n",
              "      <td>Consciousness</td>\n",
              "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steven Pinker</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "      <td>You've studied the human mind, cognition, lang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yoshua Bengio</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>What difference between biological neural netw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Vladimir Vapnik</td>\n",
              "      <td>Statistical Learning</td>\n",
              "      <td>The following is a conversation with Vladimir ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c57585f4-d77f-4a80-9c2b-f7d063a04ae1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c57585f4-d77f-4a80-9c2b-f7d063a04ae1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c57585f4-d77f-4a80-9c2b-f7d063a04ae1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c04aff5c-bf40-4a14-8908-4a27088bc695\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c04aff5c-bf40-4a14-8908-4a27088bc695')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c04aff5c-bf40-4a14-8908-4a27088bc695 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "podcast_df",
              "summary": "{\n  \"name\": \"podcast_df\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 93,\n        \"min\": 1,\n        \"max\": 325,\n        \"num_unique_values\": 318,\n        \"samples\": [\n          74,\n          281,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"guest\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 281,\n        \"samples\": [\n          \"Keoki Jackson\",\n          \"Sergey Nazarov\",\n          \"Dan Reynolds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Deep Learning, Education, and Real-World AI\",\n          \"Bad Vegan\",\n          \"Thousand Brains Theory of Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 318,\n        \"samples\": [\n          \"The following is a conversation with Michael I. Jordan, a professor at Berkeley and one of the most influential people in the history of machine learning, statistics, and artificial intelligence. He has been cited over 170,000 times and he has mentored many of the world class researchers defining the field of AI today, including Andrew Ng, Zubin Garamani, Ben Taskar, and Yoshua Bengio. All this, to me, is as impressive as the over 32,000 points in the six NBA championships of the Michael J. Jordan of basketball fame. There's a nonzero probability that I talked to the other Michael Jordan given my connection to and love of the Chicago Bulls of the 90s, but if I had to pick one, I'm going with the Michael Jordan of statistics and computer science, or as Yann LeCun calls him, the Miles Davis of machine learning. In his blog post titled Artificial Intelligence, the Revolution Hasn't Happened Yet, Michael argues for broadening the scope of the artificial intelligence field. In many ways, the underlying spirit of this podcast is the same, to see artificial intelligence as a deeply human endeavor, to not only engineer algorithms and robots, but to understand and empower human beings at all levels of abstraction, from the individual to our civilization as a whole. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe and YouTube, give it five stars at Apple Podcast, support it on Patreon, or simply connect with me on Twitter at Lex Friedman spelled F R I D M A N. As usual, I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance app in the App Store. When you get it, use code LEX PODCAST. Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with as little as $1. Since Cash App does fractional share trading, let me mention that the order execution algorithm that worked behind the scenes to create the abstraction of the fractional orders is to me an algorithmic marvel. Great props for the Cash App engineers for solving a hard problem that in the end provides an easy interface that takes a step up to the next layer of abstraction over the stock market, making trading more accessible for new investors and diversification much easier. So once again, if you get Cash App from the App Store or Google Play and use the code LEX PODCAST, you'll get $10 and Cash App will also donate $10 to First, one of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. And now, here's my conversation with Michael I. Jordan. Given that you're one of the greats in the field of AI, machine learning, computer science, and so on, you're trivially called the Michael Jordan of machine learning, although as you know, you were born first, so technically MJ is the Michael I. Jordan of basketball. But anyway, my favorite is Yann LeCun calling you the Miles Davis of machine learning because as he says, you reinvent yourself periodically and sometimes leave fans scratching their heads after you change direction. So can you put at first your historian hat on and give a history of computer science and AI as you saw it, as you experienced it, including the four generations of AI successes that I've seen you talk about? Sure. Yeah, first of all, I much prefer Yann's metaphor. Miles Davis was a real explorer in jazz and he had a coherent story. So I think I have one, but it's not just the one you lived, it's the one you think about later. What the historian does is they look back and they revisit. I think what's happening right now is not AI, that was an intellectual aspiration that's still alive today as an aspiration. But I think this is akin to the development of chemical engineering from chemistry or electrical engineering from electromagnetism. So if you go back to the 30s or 40s, there wasn't yet chemical engineering. There was chemistry, there was fluid flow, there was mechanics and so on. But people pretty clearly viewed interesting goals to try to build factories that make chemicals products and do it viably, safely, make good ones, do it at scale. So people started to try to do that, of course, and some factories worked, some didn't, some were not viable, some exploded, but in parallel, developed a whole field called chemical engineering. Electrical engineering is a field, it's no bones about it, it has theoretical aspects to it, it has practical aspects. It's not just engineering, quote unquote, it's the real thing, real concepts are needed. Same thing with electrical engineering. There was Maxwell's equations, which in some sense were everything you know about electromagnetism, but you needed to figure out how to build circuits, how to build modules, how to put them together, how to bring electricity from one point to another safely and so on and so forth. So a whole field that developed called electrical engineering. I think that's what's happening right now, is that we have a proto field, which is statistics, more of the theoretical side of it, algorithmic side of computer science, that was enough to start to build things, but what things? Systems that bring value to human beings and use human data and mix in human decisions. The engineering side of that is all ad hoc. That's what's emerging. In fact, if you wanna call machine learning a field, I think that's what it is, that it's a proto form of engineering based on statistical and computational ideas of previous generations. But do you think there's something deeper about AI in his dreams and aspirations as compared to chemical engineering and electrical engineering? Well the dreams and aspirations maybe, but those are 500 years from now. I think that that's like the Greeks sitting there and saying, it would be neat to get to the moon someday. I think we have no clue how the brain does computation. We're just a clueless. We're even worse than the Greeks on most anything interesting scientifically of our era. Can you linger on that just for a moment because you stand not completely unique, but a little bit unique in the clarity of that. Can you elaborate your intuition of why we're, like where we stand in our understanding of the human brain? And a lot of people say, you know, scientists say we're not very far in understanding human brain, but you're like, you're saying we're in the dark here. Well, I know I'm not unique. I don't even think in the clarity, but if you talk to real neuroscientists that really study real synapses or real neurons, they agree, they agree. It's a hundreds of year task and they're building it up slowly and surely. What the signal is there is not clear. We think we have all of our metaphors. We think it's electrical, maybe it's chemical, it's a whole soup, it's ions and proteins and it's a cell. And that's even around like a single synapse. If you look at a electron micrograph of a single synapse, it's a city of its own. And that's one little thing on a dendritic tree, which is extremely complicated electrochemical thing. And it's doing these spikes and voltages are flying around and then proteins are taking that and taking it down into the DNA and who knows what. So it is the problem of the next few centuries. It is fantastic. But we have our metaphors about it. Is it an economic device? Is it like the immune system or is it like a layered set of, you know, arithmetic computations? We have all these metaphors and they're fun. But that's not real science per se. There is neuroscience. That's not neuroscience. All right. That's like the Greek speculating about how to get to the moon, fun, right? And I think that I like to say this fairly strongly because I think a lot of young people think we're on the verge because a lot of people who don't talk about it clearly let it be understood that, yes, we kind of, this is a brain inspired, we're kind of close, you know, breakthroughs are on the horizon. And that's scrupulous people sometimes who need money for their labs. That's what I'm saying, scrupulous, but people will oversell, I need money for my lab, I'm studying computational neuroscience, I'm going to oversell it. And so there's been too much of that. So I'll step into the gray area between metaphor and engineering with, I'm not sure if you're familiar with brain computer interfaces. So a company like Elon Musk has Neuralink that's working on putting electrodes into the brain and trying to be able to read, both read and send electrical signals. Just as you said, even the basic mechanism of communication in the brain is not something we understand. But do you hope without understanding the fundamental principles of how the brain works, we'll be able to do something interesting at that gray area of metaphor? It's not my area. So I hope in the sense, like anybody else hopes for some interesting things to happen from research, I would expect more something like Alzheimer's will get figured out from modern neuroscience. There's a lot of human suffering based on brain disease and we throw things like lithium at the brain, it kind of works, no one has a clue why. That's not quite true, but mostly we don't know. And that's even just about the biochemistry of the brain and how it leads to mood swings and so on. How thought emerges from that, we were really, really completely dim. So that you might want to hook up electrodes and try to do some signal processing on that and try to find patterns, fine, by all means, go for it. It's just not scientific at this point. So it's like kind of sitting in a satellite and watching the emissions from a city and trying to infer things about the microeconomy, even though you don't have microeconomic concepts. It's really that kind of thing. And so yes, can you find some signals that do something interesting or useful? Can you control a cursor or mouse with your brain? Yeah, absolutely, and then I can imagine business models based on that and even medical applications of that. But from there to understanding algorithms that allow us to really tie in deeply from the brain to computer, I just, no, I don't agree with Elon Musk. I don't think that's even, that's not for our generations, not even for the century. So just in hopes of getting you to dream, you've mentioned Kolmogorov and Turing might pop up, do you think that there might be breakthroughs that will get you to sit back in five, 10 years and say, wow? Oh, I'm sure there will be, but I don't think that there'll be demos that impress me. I don't think that having a computer call a restaurant and pretend to be a human is a breakthrough. Right. And people, you know, some people present it as such. It's imitating human intelligence. It's even putting coughs in the thing to make a bit of a PR stunt. And so fine that the world runs on those things too. And I don't want to diminish all the hard work and engineering that goes behind things like that and the ultimate value to the human race. But that's not scientific understanding. And I know the people that work on these things, they are after scientific understanding. In the meantime, they've got to kind of, you know, the trains got to run and they got mouths to feed and they got things to do and there's nothing wrong with all that. I would call that though, just engineering. And I want to distinguish that between an engineering field, like electrical engineering and chemical engineering that originally emerged, that had real principles and you really know what you're doing and you had a little scientific understanding, maybe not even complete. So it became more predictable and it really gave value to human life because it was understood. And so we don't want to muddle too much these waters of, you know, what we're able to do versus what we really can't do in a way that's going to impress the next. So I don't need to be wowed, but I think that someone comes along in 20 years, a younger person who's absorbed all the technology and for them to be wowed, I think they have to be more deeply impressed. A young Kolmogorov would not be wowed by some of the stunts that you see right now coming from the big companies. The demos, but do you think the breakthroughs from Kolmogorov would be, and give this question a chance, do you think there'll be in the scientific fundamental principles arena or do you think it's possible to have fundamental breakthroughs in engineering? Meaning, you know, I would say some of the things that Elon Musk is working with SpaceX and then others sort of trying to revolutionize the fundamentals of engineering, of manufacturing, of saying, here's a problem we know how to do a demo of and actually taking it to scale. Yeah. So there's going to be all kinds of breakthroughs. I just don't like that terminology. I'm a scientist and I work on things day in and day out and things move along and eventually you say, wow, something happened, but I don't like that language very much. Also I don't like to prize theoretical breakthroughs over practical ones. I tend to be more of a theoretician and I think there's lots to do in that arena right now. And so I wouldn't point to the Kolmogorovs, I might point to the Edisons of the era and maybe Musk is a bit more like that. But you know, Musk, God bless him, also will say things about AI that he knows very little about and he leads people astray when he talks about things he doesn't know anything about. Trying to program a computer to understand natural language, to be involved in a dialogue we're having right now, that ain't going to happen in our lifetime. You could fake it, you can mimic, sort of take old sentences that humans use and retread them, but the deep understanding of language, no, it's not going to happen. And so from that, I hope you can perceive that the deeper, yet deeper kind of aspects and intelligence are not going to happen. Now will there be breakthroughs? No, I think that Google was a breakthrough, I think Amazon is a breakthrough, you know, I think Uber is a breakthrough, you know, that bring value to human beings at scale in new, brand new ways based on data flows and so on. A lot of these things are slightly broken because there's not kind of an engineering field that takes economic value in context of data and, you know, planetary scale and worries about all the externalities, the privacy, you know, we don't have that field so we don't think these things through very well. I see that as emerging and that will be, you know, looking back from 100 years, that will be a constituted breakthrough in this era, just like electrical engineering was a breakthrough in the early part of the last century and chemical engineering was a breakthrough. So the scale, the markets that you talk about and we'll get to will be seen as sort of breakthrough and we're in the very early days of really doing interesting stuff there and we'll get to that, but just taking a quick step back, can you give, kind of throw off the historian hat. I mean, you briefly said that the history of AI kind of mimics the history of chemical engineering, but... I keep saying machine learning. You keep wanting to say AI, just to let you know, I don't, you know, I resist that. I don't think this is about AI really was John McCarthy as almost a philosopher saying, wouldn't it be cool if we could put thought in a computer? If we could mimic the human capability to think or put intelligence in, in some sense into a computer. That's an interesting philosophical question and he wanted to make it more than philosophy. He wanted to actually write down a logical formula and algorithms that would do that. And that is a perfectly valid, reasonable thing to do. That's not what's happening in this era. So the reason I keep saying AI actually, and I'd love to hear what you think about it. Machine learning has a very particular set of methods and tools. Maybe your version of it is that mine doesn't, it's very, very open. It does optimization, it does sampling, it does... So systems that learn is what machine learning is. Systems that learn and make decisions. And make decisions. So it's not just pattern recognition and, you know, finding patterns, it's all about making decisions in real worlds and having close feedback loops. So something like symbolic AI, expert systems, reasoning systems, knowledge based representation, all of those kinds of things, search, does that neighbor fit into what you think of as machine learning? So I don't even like the word machine learning, I think that what the field you're talking about is all about making large collections of decisions under uncertainty by large collections of entities. Right? And there are principles for that, at that scale. You don't have to say the principles are for a single entity that's making decisions, single agent or single human. It really immediately goes to the network of decisions. Is a good word for that or no? No, there's no good words for any of this. That's kind of part of the problem. So we can continue the conversation to use AI for all that. I just want to kind of raise the flag here that this is not about, we don't know what intelligence is and real intelligence. We don't know much about abstraction and reasoning at the level of humans. We don't have a clue. We're not trying to build that because we don't have a clue. Eventually it may emerge. They'll make, I don't know if there'll be breakthroughs, but eventually we'll start to get glimmers of that. It's not what's happening right now. Okay. We're taking data. We're trying to make good decisions based on that. We're trying to scale. We're trying to economically viably, we're trying to build markets. We're trying to keep value at that scale and aspects of this will look intelligent. Computers were so dumb before, they will seem more intelligent. We will use that buzzword of intelligence so we can use it in that sense. So machine learning, you can scope it narrowly as just learning from data and pattern recognition. But when I talk about these topics, maybe data science is another word you could throw in the mix, it really is important that the decisions are as part of it. It's consequential decisions in the real world. Am I going to have a medical operation? Am I going to drive down the street? Things where there's scarcity, things that impact other human beings or other environments and so on. How do I do that based on data? How do I do that adaptively? How do I use computers to help those kinds of things go forward? Whatever you want to call that. So let's call it AI. Let's agree to call it AI, but let's not say that the goal of that is intelligence. The goal of that is really good working systems at planetary scale that we've never seen before. So reclaim the word AI from the Dartmouth conference from many decades ago of the dream of humans. I don't want to reclaim it. I want a new word. I think it was a bad choice. I mean, if you read one of my little things, the history was basically that McCarthy needed a new name because cybernetics already existed and he didn't like, no one really liked Norbert Wiener. Norbert Wiener was kind of an island to himself and he felt that he had encompassed all this and in some sense he did. You look at the language of cybernetics, it was everything we're talking about. It was control theory and signal processing and some notions of intelligence and closed feedback loops and data. It was all there. It's just not a word that lived on partly because of the maybe the personalities. But McCarthy needed a new word to say, I'm different from you. I'm not part of your show. I got my own. Invented this word and again, thinking forward about the movies that would be made about it, it was a great choice. But thinking forward about creating a sober academic and real world discipline, it was a terrible choice because it led to promises that are not true that we understand. We understand artificial perhaps, but we don't understand intelligence. It's a small tangent because you're one of the great personalities of machine learning, whatever the heck you call the field. Do you think science progresses by personalities or by the fundamental principles and theories and research that's outside of personalities? Both. And I wouldn't say there should be one kind of personality. I have mine and I have my preferences and I have a kind of network around me that feeds me and some of them agree with me and some of them disagree, but all kinds of personalities are needed. Right now, I think the personality that it's a little too exuberant, a little bit too ready to promise the moon is a little bit too much in ascendance. And I do think that there's some good to that. It certainly attracts lots of young people to our field, but a lot of those people come in with strong misconceptions and they have to then unlearn those and then find something to do. And so I think there's just got to be some multiple voices and I wasn't hearing enough of the more sober voice. So as a continuation of a fun tangent and speaking of vibrant personalities, what would Yeah. And you think technically speaking, it's possible to help. I don't know the answers, but it's a, it's a, it's a less anonymity, a little more locality, you know, worlds that you kind of enter in and you trust the people there in those worlds so that when you start having a discussion, you know, not only is that people are not going to hurt you, but it's not going to be a total waste of your time because there's a lot of wasting of time that, you know, a lot of us, I pulled out of Facebook early on cause it was clearly going to waste a lot of my time even though there was some value. And so, yeah, worlds that are somehow you enter in and you know what you're getting and it's kind of appeals to you and you might, new things might happen, but you kind of have some, some trust in that world. And there's some deep, interesting, complex psychological aspects around anonymity, how that changes human behavior that's quite dark. Quite dark. Yeah. I think a lot of us are, especially those of us who really loved the advent of technology. I love social networks when they came out. I was just, I didn't see any negatives there at all. But then I started seeing comment sections. I think it was maybe, you know, with the CNN or something. And I started to go, wow, this, this darkness I just did not know about and, and our technology is now amplifying it. So sorry for the big philosophical question, but on that topic, do you think human beings, cause you've also, out of all things, had a foot in psychology too, the, do you think human beings are fundamentally good? Like all of us have good intent that could be mind or is it depending on context and environment, everybody could be evil. So my answer is fundamentally good. But fundamentally limited. All of us have very, you know, blinkers on. We don't see the other person's pain that easily. We don't see the other person's point of view that easily. We're very much in our own head, in our own world. And on my good days, I think the technology could open us up to, you know, more perspectives and more less blinkered and more understanding, you know, a lot of wars in human history happened because of just ignorance. They didn't, they, they thought the other person was doing this while their person wasn't doing this. And we have a huge amounts of that. But in my lifetime, I've not seen technology really help in that way yet. And I do, I do, I do believe in that, but you know, no, I think fundamentally humans are good. The people suffer, people have grievances because you have grudges and those things cause them to do things they probably wouldn't want. They regret it often. So no, I, I think it's a, you know, part of the progress of technology is to indeed allow it to be a little easier to be the real good person you actually are. Well, but do you think individual human life or society could be modeled as an optimization problem? Not the way I think typically, I mean, that's, you're talking about one of the most complex phenomenon in the whole, you know, in all of which the individual human life or society as a whole. Both, both. I mean, individual human life is amazingly complex. And so you know, optimization is kind of just one branch of mathematics that talks about certain kinds of things. And it just feels way too limited for the complexity of such things. What properties of optimization problems do you think, so do you think most interesting problems that could be solved through optimization, what kind of properties does that surface have non convexity, convexity, linearity, all those kinds of things, saddle points? Well, so optimization is just one piece of mathematics. You know, there's like, you just, even in our era, we're aware that say sampling is coming up, examples of something coming up with a distribution. What's optimization? What's sampling? Well, they, you can, if you're a kind of a certain kind of mathematician, you can try to blend them and make them seem to be sort of the same thing. But optimization is roughly speaking, trying to find a point that, a single point that is the optimum of a criterion function of some kind. And sampling is trying to, from that same surface, treat that as a distribution or density and find points that have high density. So I want the entire distribution in a sampling paradigm and I want the, you know, the single point, that's the best point in the optimization paradigm. Now if you were optimizing in the space of probability measures, the output of that could be a whole probability distribution. So you can start to make these things the same. But in mathematics, if you go too high up that kind of abstraction hierarchy, you start to lose the, you know, the ability to do the interesting theorems. So you kind of don't try that. You don't try to overly over abstract. So as a small tangent, what kind of worldview do you find more appealing? One that is deterministic or stochastic? Well, that's easy. I mean, I'm a statistician. You know, the world is highly stochastic. I don't know what's going to happen in the next five minutes, right? Because what you're going to ask, what we're going to do, what I'll say. Due to the uncertainty. Due to the... Massive uncertainty. Yeah. You know, massive uncertainty. And so the best I can do is have come rough sense or probability distribution on things and somehow use that in my reasoning about what to do now. So how does the distributed at scale when you have multi agent systems look like? So optimization can optimize sort of, it makes a lot more sense, sort of at least from my from robotics perspective, for a single robot, for a single agent, trying to optimize some objective function. When you start to enter the real world, this game theoretic concept starts popping up. That's how do you see optimization in this? Because you've talked about markets in a scale. What does that look like? Do you see it as optimization? Do you see it as sampling? Do you see like, how should you mark? These all blend together. And a system designer thinking about how to build an incentivized system will have a blend of all these things. So, you know, a particle in a potential well is optimizing a functional called a Lagrangian, right? The particle doesn't know that. There's no algorithm running that does that. It just happens. And so it's a description mathematically of something that helps us understand as analysts what's happening, right? And so the same thing will happen when we talk about, you know, mixtures of humans and computers and markets and so on and so forth, there'll be certain principles that allow us to understand what's happening, whether or not the actual algorithms are being used by any sense is not clear. Now at some point, I may have set up a multi agent or market kind of system. And I'm now thinking about an individual agent in that system. And they're asked to do some task and they're incentivized in some way, they get certain signals and they have some utility. What they will do at that point is they just won't know the answer, they may have to optimize to find an answer. Okay, so an artist could be embedded inside of an overall market. You know, and game theory is very, very broad. It is often studied very narrowly for certain kinds of problems. But it's roughly speaking, this is just the, I don't know what you're going to do. So I kind of anticipate that a little bit, and you anticipate what I'm anticipating. And we kind of go back and forth in our own minds. We run kind of thought experiments. You've talked about this interesting point in terms of game theory, you know, most optimization problems really hate saddle points, maybe you can describe what saddle points are. But I've heard you kind of mentioned that there's a there's a branch of optimization that you could try to explicitly look for saddle points as a good thing. Oh, not optimization. That's just game theory that that so there's all kinds of different equilibria in game theory. And some of them are highly explanatory behavior. They're not attempting to be algorithmic. They're just trying to say, if you happen to be at this equilibrium, you would see certain kind of behavior. And we see that in real life. That's what an economist wants to do, especially behavioral economists in continuous differential game theory, you're in continuous spaces, a some of the simplest equilibria are saddle points and Nash equilibrium as a saddle point. It's a special kind of saddle point. So classically, in game theory, you were trying to find Nash equilibria and an algorithmic game theory, you're trying to find algorithms that would find them. And so you're trying to find saddle points. I mean, so that's literally what you're trying to do. But you know, any economist knows that Nash equilibria have their limitations. They are definitely not that explanatory in many situations. They're not what you really want. There's other kind of equilibria. And there's names associated with these because they came from history with certain people working on them, but there will be new ones emerging. So you know, one example is a Stackelberg equilibrium. So you know, Nash, you and I are both playing this game against each other or for each other, maybe it's cooperative, and we're both going to think it through and then we're going to decide and we're going to do our thing simultaneously. You know, in a Stackelberg, no, I'm going to be the first mover. I'm going to make a move. You're going to look at my move and then you're going to make yours. Now since I know you're going to look at my move, I anticipate what you're going to do. And so I don't do something stupid, but then I know that you are also anticipating me. So we're kind of going back and forth on why, but there is then a first mover thing. And so those are different equilibria, right? And so just mathematically, yeah, these things have certain topologies and certain shapes that are like, what's it, algorithmically or dynamically, how do you move towards them? How do you move away from things? You know, so some of these questions have answers, they've been studied, others do not. And especially if it becomes stochastic, especially if there's large numbers of decentralized things, there's just, you know, young people get in this field who kind of think it's all done because we have, you know, TensorFlow. Well, no, these are all open problems and they're really important and interesting. And it's about strategic settings. How do I collect data? Suppose I don't know what you're going to do because I don't know you very well, right? Well, I got to collect data about you. So maybe I want to push you into a part of the space where I don't know much about you so I can get data. Cause, and then later I'll realize that you'll never, you'll never go there because of the way the game is set up. You know, that's part of the overall, you know, data analysis context is that. Even the game of poker is fascinating space, whenever there's any uncertainty, a lack of information, it's a super exciting space. Just to linger on optimization for a second. So when we look at deep learning, it's essentially minimization of a complicated loss function. So is there something insightful or hopeful that you see in the kinds of function surface that loss functions, the deep learning and in the real world is trying to optimize over? Is there something interesting as it's just the usual kind of problems of optimization? I think from an optimization point of view, that surface, first of all, it's pretty smooth. And secondly, if there's over, if it's over parameterized, there's kind of lots of paths down to reasonable Optima. And so kind of the getting downhill to the, to an optimum is viewed as not as hard as you might've expected in high dimensions. The fact that some Optima tend to be really good ones and others not so good. And you tend to, it's not, sometimes you find the good ones is sort of still needs explanation. Yeah. But, but the particular surface is coming from the particular generation of neural nets. I kind of suspect those will, those will change in 10 years. It will not be exactly those surfaces. There'll be some others that are an optimization theory will help contribute to why other surfaces or why other algorithms. Years of arithmetic operations with a little bit of nonlinearity, that's not, that didn't come from neuroscience per se. I mean, maybe in the minds of some of the people working on it, they were thinking about brains, but they were arithmetic circuits in all kinds of fields, computer science control theory and so on. And that layers of these could transform things in certain ways. And that if it's smooth, maybe you could find parameter values is a sort of big discovery that it's working, it's able to work at this scale. But I don't think that we're stuck with that and we're, we're certainly not stuck with that cause we're understanding the brain. So in terms of on the algorithm side sort of gradient descent, do you think we're stuck with gradient descent as a variance of it? What variance do you find interesting or do you think there'll be something else invented that is able to walk all over these optimization spaces in more interesting ways? So there's a co design of the surface and the, or the architecture and the algorithm. So if you just ask if we stay with the kind of architectures that we have now and not just neural nets, but you know, phase retrieval architectures or matrix completion architectures and so on. You know, I think we've kind of come to a place where yeah, a stochastic gradient algorithms are dominant and there are versions that are a little better than others. They have more guarantees, they're more robust and so on. And there's ongoing research to kind of figure out which is the best arm for which situation. But I think that that'll start to co evolve, that that'll put pressure on the actual architecture. And so we shouldn't do it in this particular way, we should do it in a different way because this other algorithm is now available if you do it in a different way. So that I can't really anticipate that co evolution process, but you know, gradients are amazing mathematical objects. They have a lot of people who start to study them more deeply mathematically are kind of shocked about what they are and what they can do. Think about it this way, suppose that I tell you if you move along the x axis, you go uphill in some objective by three units, whereas if you move along the y axis, you go uphill by seven units, right? Now I'm going to only allow you to move a certain unit distance, right? What are you going to do? Well, most people will say that I'm going to go along the y axis, I'm getting the biggest bang for my buck, you know, and my buck is only one unit, so I'm going to put all of it in the y axis, right? And why should I even take any of my strength, my step size and put any of it in the x axis because I'm getting less bang for my buck. That seems like a completely clear argument and it's wrong because the gradient direction is not to go along the y axis, it's to take a little bit of the x axis. And to understand that, you have to know some math and so even a trivial so called operator like gradient is not trivial and so, you know, exploiting its properties is still very important. Now we know that just pervading descent has got all kinds of problems, it gets stuck in many ways and it had never, you know, good dimension dependence and so on. So my own line of work recently has been about what kinds of stochasticity, how can we get dimension dependence, how can we do the theory of that and we've come up pretty favorable results with certain kinds of stochasticity. We have sufficient conditions generally. We know if you do this, we will give you a good guarantee. We don't have necessary conditions that it must be done a certain way in general. So stochasticity, how much randomness to inject into the walking along the gradient? And what kind of randomness? Why is randomness good in this process? Why is stochasticity good? Yeah, so I can give you simple answers but in some sense again, it's kind of amazing. Stochasticity just, you know, particular features of a surface that could have hurt you if you were doing one thing deterministically won't hurt you because by chance, there's very little chance that you would get hurt. So here stochasticity, it just kind of saves you from some of the particular features of surfaces. In fact, if you think about surfaces that are discontinuous in our first derivative, like an absolute value function, you will go down and hit that point where there's nondifferentiability. And if you're running a deterministic algorithm at that point, you can really do something bad. Whereas stochasticity just means it's pretty unlikely that's going to happen, that you're going to hit that point. So it's again, nontrivial to analyze but especially in higher dimensions, also stochasticity, our intuition isn't very good about it but it has properties that kind of are very appealing in high dimensions for a lot of large number of reasons. So it's all part of the mathematics to kind of, that's what's fun to work in the field is that you get to try to understand this mathematics. But long story short, you know, partly empirically, it was discovered stochastic gradient is very effective and theory kind of followed, I'd say, that but I don't see that we're getting clearly out of that. What's the most beautiful, mysterious, a profound idea to you in optimization? I don't know the most. But let me just say that Nesterov's work on Nesterov acceleration to me is pretty surprising and pretty deep. Can you elaborate? Well Nesterov acceleration is just that, suppose that we are going to use gradients to move around in a space. For the reasons I've alluded to, they're nice directions to move. And suppose that I tell you that you're only allowed to use gradients, you're not going to be allowed to use this local person that can only sense kind of the change in the surface. But I'm going to give you kind of a computer that's able to store all your previous gradients. And so you start to learn some something about the surface. And I'm going to restrict you to maybe move in the direction of like a linear span of all the gradients. So you can't kind of just move in some arbitrary direction, right? So now we have a well defined mathematical complexity model. There's certain classes of algorithms that can do that and others that can't. And we can ask for certain kinds of surfaces, how fast can you get down to the optimum? So there's answers to these. So for a smooth convex function, there's an answer, which is one over the number of steps squared. You will be within a ball of that size after k steps. Gradient descent in particular has a slower rate, it's one over k. So you could ask, is gradient descent actually, even though we know it's a good algorithm, is it the best algorithm? And the answer is no. Well, not clear yet, because one over k squared is a lower bound. That's probably the best you can do. Gradient is one over k, but is there something better? And so I think as a surprise to most, Nesterov discovered a new algorithm that has got two pieces to it. It's two gradients and puts those together in a certain kind of obscure way. And the thing doesn't even move downhill all the time. It sometimes goes back uphill. And if you're a physicist, that kind of makes some sense. You're building up some momentum and that is kind of the right intuition, but that intuition is not enough to understand kind of how to do it and why it works. But it does. It achieves one over k squared and it has a mathematical structure and it's still kind of to this day, a lot of us are writing papers and trying to explore that and understand it. So there are lots of cool ideas and optimization, but just kind of using gradients, I think is number one that goes back, you know, 150 years. And then Nesterov, I think has made a major contribution with this idea. So like you said, gradients themselves are in some sense, mysterious. They're not as trivial as... Not as trivial. Coordinate descent is more of a trivial one. You just pick one of the coordinates. That's how we think. That's how our human mind thinks. That's how our human minds think. And gradients are not that easy for our human mind to grapple with. An absurd question, but what is statistics? So here it's a little bit, it's somewhere between math and science and technology. It's somewhere in that convex hole. So it's a set of principles that allow you to make inferences that have got some reason to be believed and also principles that allow you to make decisions where you can have some reason to believe you're not going to make errors. So all of that requires some assumptions about what do you mean by an error? What do you mean by the probabilities? But after you start making some of those assumptions, you're led to conclusions that, yes, I can guarantee that if you do this in this way, your probability of making an error will be small. Your probability of continuing to not make errors over time will be small. And the probability that you found something that's real will be small, will be high. So decision making is a big part of that. Decision making is a big part. Yeah. So statistics, short history was that, it goes back as a formal discipline, 250 years or so. It was called inverse probability because around that era, probability was developed sort of especially to explain gambling situations. Of course, interesting. So you would say, well, given the state of nature is this, there's a certain roulette board that has a certain mechanism and what kind of outcomes do I expect to see? And especially if I do things long amounts of time, what outcomes will I see? And the physicists started to pay attention to this. And then people said, well, let's turn the problem around. What if I saw certain outcomes, could I infer what the underlying mechanism was? That's an inverse problem. And in fact, for quite a while, statistics was called inverse probability. That was the name of the field. And I believe that it was Laplace who was working in Napoleon's government who needed to do a census of France, learn about the people there. So he went and gathered data and he analyzed that data to determine policy and said, well, let's call this field that does this kind of thing statistics because the word state is in there. In French, that's etat, but it's the study of data for the state. So anyway, that caught on and it's been called statistics ever since. But by the time it got formalized, it was sort of in the 30s. And around that time, there was game theory and decision theory developed nearby. People in that era didn't think of themselves as either computer science or statistics or control or econ. They were all the above. And so Von Neumann is developing game theory, but also thinking of that as decision theory. Wald is an econometrician developing decision theory and then turning that into statistics. And so it's all about, here's not just data and you analyze it, here's a loss function. Here's what you care about. Here's the question you're trying to ask. Here is a probability model and here's the risk you will face if you make certain decisions. And to this day, in most advanced statistical curricula, you teach decision theory as the starting point and then it branches out into the two branches of Bayesian and frequentist. But that's all about decisions. In statistics, what is the most beautiful, mysterious, maybe surprising idea that you've come across? Yeah, good question. I mean, there's a bunch of surprising ones. There's something that's way too technical for this thing, but something called James Stein estimation, which is kind of surprising and really takes time to wrap your head around. Can you try to maybe... I think I don't want to even want to try. Let me just say a colleague at Steven Stigler at University of Chicago wrote a really beautiful paper on James Stein estimation, which helps to... It's views a paradox. It kind of defeats the mind's attempts to understand it, but you can and Steve has a nice perspective on that. So one of the troubles with statistics is that it's like in physics that are in quantum physics, you have multiple interpretations. There's a wave and particle duality in physics and you get used to that over time, but it still kind of haunts you that you don't really quite understand the relationship. The electron's a wave and electron's a particle. Well the same thing happens here. There's Bayesian ways of thinking and frequentist, and they are different. They sometimes become sort of the same in practice, but they are physically different. And then in some practice, they are not the same at all. They give you rather different answers. And so it is very much like wave and particle duality, and that is something that you have to kind of get used to in the field. Can you define Bayesian and frequentist? Yeah in decision theory you can make, I have a video that people could see. It's called are you a Bayesian or a frequentist and kind of help try to make it really clear. It comes from decision theory. So you know, decision theory, you're talking about loss functions, which are a function of data X and parameter theta. They're a function of two arguments. Okay. Neither one of those arguments is known. You don't know the data a priori. It's random and the parameters unknown. All right. So you have a function of two things you don't know, and you're trying to say, I want that function to be small. I want small loss, right? Well what are you going to do? So you sort of say, well, I'm going to average over these quantities or maximize over them or something so that, you know, I turn that uncertainty into something certain. So you could look at the first argument and average over it, or you could look at the second argument and average over it. That's Bayesian and frequentist. So the frequentist says, I'm going to look at the X, the data, and I'm going to take that as random and I'm going to average over the distribution. So I take the expectation loss under X. Theta is held fixed, right? That's called the risk. And so it's looking at other, all the data sets you could get, right? And say, how well will a certain procedure do under all those data sets? That's called a frequentist guarantee, right? So I think it is very appropriate when like you're building a piece of software and you're shipping it out there and people are using it on all kinds of data sets. You want to have a stamp, a guarantee on it that as people run it on many, many data sets that you never even thought about that 95% of the time it will do the right thing. Perfectly reasonable. The Bayesian perspective says, well, no, I'm going to look at the other argument of the loss function, the theta part, okay? That's unknown and I'm uncertain about it. So I could have my own personal probability for what it is, you know, how many tall people are there out there? I'm trying to infer the average height of the population while I have an idea roughly what the height is. So I'm going to average over the theta. So now that loss function as only now, again, one argument's gone, now it's a function of X and that's what a Bayesian does is they say, well, let's just focus on the particular X we got, the data set we got, we condition on that. Conditional on the X, I say something about my loss. That's a Bayesian approach to things. And the Bayesian will argue that it's not relevant to look at all the other data sets you could have gotten and average over them, the frequentist approach. It's really only the data sets you got, right? And I do agree with that, especially in situations where you're working with a scientist, you can learn a lot about the domain and you're really only focused on certain kinds of data and you gathered your data and you make inferences. I don't agree with it though, that, you know, in the sense that there are needs for frequentist guarantees, you're writing software, people are using it out there, you want to say something. So these two things have to got to fight each other a little bit, but they have to blend. So long story short, there's a set of ideas that are right in the middle that are called empirical Bayes. And empirical Bayes sort of starts with the Bayesian framework. It's kind of arguably philosophically more, you know, reasonable and kosher. Write down a bunch of the math that kind of flows from that, and then realize there's a bunch of things you don't know because it's the real world and you don't know everything. So you're uncertain about certain quantities. At that point, ask, is there a reasonable way to plug in an estimate for those things? Okay. And in some cases, there's quite a reasonable thing to do, to plug in, there's a natural thing you can observe in the world that you can plug in and then do a little bit more mathematics and assure yourself it's really good. So based on math or based on human expertise, what's, what, what are good? Oh, they're both going in. The Bayesian framework allows you to put a lot of human expertise in, but the math kind of guides you along that path and then kind of reassures you the end, you could put that stamp of approval under certain assumptions, this thing will work. So you asked the question, what's my favorite, you know, or what's the most surprising, nice idea. So one that is more accessible is something called false discovery rate, which is, you know, you're making not just one hypothesis test or making one decision, you're making a whole bag of them. And in that bag of decisions, you look at the ones where you made a discovery, you announced that something interesting had happened. All right. That's going to be some subset of your big bag. In the ones you made a discovery, which subset of those are bad? Or false, false discoveries. You'd like the fraction of your false discoveries among your discoveries to be small. That's a different criterion than accuracy or precision or recall or sensitivity and specificity. It's a different quantity. Those latter ones are almost all of them have more of a frequentist flavor. They say, given the truth is that the null hypothesis is true. Here's what accuracy I would get, or given that the alternative is true, here's what I would get. So it's kind of going forward from the state of nature to the data. The Bayesian goes the other direction from the data back to the state of nature. And that's actually what false discovery rate is. It says, given you made a discovery, okay, that's conditioned on your data. What's the probability of the hypothesis? It's going the other direction. And so the classical frequency look at that, well, I can't know that there's some priors needed in that. And the empirical Bayesian goes ahead and plows forward and starts writing down these formulas and realizes at some point, some of those things can actually be estimated in a reasonable way. And so it's kind of, it's a beautiful set of ideas. So I, this kind of line of argument has come out. It's not certainly mine, but it sort of came out from Robbins around 1960. Brad Efron has written beautifully about this in various papers and books. And the FDR is, you know, Benjamin in Israel, John Story did this Bayesian interpretation and so on. And he used to absorb these things over the years and find it a very healthy way to think about statistics. Let me ask you about intelligence to jump slightly back out into philosophy, perhaps. You said that maybe you can elaborate, but you said that defining just even the question of what is intelligence is a very difficult question. Is it a useful question? Do you think we'll one day understand the fundamentals of human intelligence and what it means, you know, have good benchmarks for general intelligence that we put before our machines? So I don't work on these topics so much that you're really asking the question for a psychologist really. And I studied some, but I don't consider myself at least an expert at this point. You know, a psychologist aims to understand human intelligence, right? And I think many psychologists I know are fairly humble about this. They might try to understand how a baby understands, you know, whether something's a solid or liquid or whether something's hidden or not. And maybe how a child starts to learn the meaning of certain words, what's a verb, what's a noun and also, you know, slowly but surely trying to figure out things. But humans ability to take a really complicated environment, reason about it, abstract about it, find the right abstractions, communicate about it, interact and so on is just, you know, really staggeringly rich and complicated. And so, you know, I think in all humility, we don't think we're kind of aiming for that in the near future. A certain psychologist doing experiments with babies in the lab or with people talking has a much more limited aspiration. And you know, Kahneman and Tversky would look at our reasoning patterns and they're not deeply understanding all the how we do our reasoning, but they're sort of saying, hey, here's some oddities about the reasoning and some things you should think about it. But also, as I emphasize in some things I've been writing about, you know, AI, the revolution hasn't happened yet. Yeah. Great blog post. I've been emphasizing that, you know, if you step back and look at intelligent systems of any kind and whatever you mean by intelligence, it's not just the humans or the animals or, you know, the plants or whatever, you know, so a market that brings goods into a city, you know, food to restaurants or something every day is a system. It's a decentralized set of decisions. Looking at it from far enough away, it's just like a collection of neurons. Every neuron is making its own little decisions, presumably in some way. And if you step back enough, every little part of an economic system is making all of its decisions. And just like with the brain, who knows what an individual neuron does and what the overall goal is, right? But something happens at some aggregate level, same thing with the economy. People eat in a city and it's robust. It works at all scales, small villages to big cities. It's been working for thousands of years. It works rain or shine, so it's adaptive. So all the kind of, you know, those are adjectives one tends to apply to intelligent systems. Robust, adaptive, you know, you don't need to keep adjusting it, self healing, whatever. Plus not perfect. You know, intelligences are never perfect and markets are not perfect. But I do not believe in this era that you cannot, that you can say, well, our computers are, our humans are smart, but you know, no markets are not, more markets are. So they are intelligent. Now we humans didn't evolve to be markets. We've been participating in them, right? But we are not ourselves a market per se. The neurons could be viewed as the market. There's economic, you know, neuroscience kind of perspective. That's interesting to pursue all that. The point though is, is that if you were to study humans and really be the world's best psychologist studied for thousands of years and come up with the theory of human intelligence, you might have never discovered principles of markets, you know, supply demand curves and you know, matching and auctions and all that. Those are real principles and they lead to a form of intelligence that's not maybe human intelligence. It's arguably another kind of intelligence. There probably are third kinds of intelligence or fourth that none of us are really thinking too much about right now. So if you really, and then all of those are relevant to computer systems in the future. Certainly the market one is relevant right now. Whereas the understanding of human intelligence is not so clear that it's relevant right now. Probably not. So if you want general intelligence, whatever one means by that, or, you know, understanding intelligence in a deep sense and all that, it is definitely has to be not just human intelligence. It's gotta be this broader thing. And that's not a mystery. Markets are intelligent. So, you know, it's definitely not just a philosophical stance to say we've got to move beyond intelligence. That sounds ridiculous. Yeah. But it's not. And in that blog post, you define different kinds of like intelligent infrastructure, AI, which I really like is some of the concepts you've just been describing. Do you see ourselves, if we see earth, human civilization as a single organism, do you think the intelligence of that organism, when you think from the perspective of markets and intelligence infrastructure is increasing, is it increasing linearly? Is it increasing exponentially? What do you think the future of that intelligence? Yeah, I don't know. I don't tend to think, I don't tend to answer questions like that because you know, that's science fiction. I'm hoping to catch you off guard. Well again, because you said it's so far in the future, it's fun to ask and you'll probably, you know, like you said, predicting the future is really nearly impossible. But say as an axiom, one day we create a human level, a superhuman level intelligent, not the scale of markets, but the scale of an individual. What do you think it is, what do you think it would take to do that? Or maybe to ask another question is how would that system be different than the biological human beings that we see around us today? Is it possible to say anything interesting to that question or is it just a stupid question? It's not a stupid question, but it's science fiction. Science fiction. And so I'm totally happy to read science fiction and think about it from time in my own life. I loved, there was this like brain in a vat kind of, you know, little thing that people were talking about when I was a student, I remember, you know, imagine that, you know, between your brain and your body, there's a, you know, there's a bunch of wires, right? And suppose that every one of them was replaced with a literal wire. And then suppose that wire was turned in actually a little wireless, you know, there's a receiver and sender. So the brain has got all the senders and receiver, you know, on all of its exiting, you know, axons and all the dendrites down to the body have replaced with senders and receivers. Now you could move the body off somewhere and put the brain in a vat, right? And then you could do things like start killing off those senders and receivers one by one. And after you've killed off all of them, where is that person? You know, they thought they were out in the body walking around the world and they moved on. So those are science fiction things. Those are fun to think about. It's just intriguing about where is, what is thought, where is it and all that. And I think every 18 year old should take philosophy classes and think about these things. And I think that everyone should think about what could happen in society that's kind of bad and all that. But I really don't think that's the right thing for most of us that are my age group to be doing and thinking about. I really think that we have so many more present, you know, first challenges and dangers and real things to build and all that such that, you know, spending too much time on science fiction, at least in public for like this, I think is not what we should be doing. Maybe over beers in private. That's right. Well, I'm not going to broadcast where I have beers because this is going to go on Facebook and I don't want a lot of people showing up there. But yeah, I'll, I love Facebook, Twitter, Amazon, YouTube. I have I'm optimistic and hopeful, but maybe, maybe I don't have grounds for such optimism and hope. But let me ask, you've mentored some of the brightest sort of some of the seminal figures in the field. Can you give advice to people who are undergraduates today? What does it take to take, you know, advice on their journey if they're interested in machine learning and in the ideas of markets from economics and psychology and all the kinds of things that you've exploring? What steps should they take on that journey? Well, yeah, first of all, the door is open and second, it's a journey. I like your language there. It is not that you're so brilliant and you have great, brilliant ideas and therefore that's just, you know, that's how you have success or that's how you enter into the field. It's that you apprentice yourself, you spend a lot of time, you work on hard things, you try and pull back and you be as broad as you can, you talk to lots of people. And it's like entering in any kind of a creative community. There's years that are needed and human connections are critical to it. So, you know, I think about, you know, being a musician or being an artist or something, you don't just, you know, immediately from day one, you know, you're a genius and therefore you do it. No, you, you know, practice really, really hard on basics and you be humble about where you are and then, and you realize you'll never be an expert on everything. So you kind of pick and there's a lot of randomness and a lot of kind of luck, but luck just kind of picks out which branch of the tree you go down, but you'll go down some branch. So yeah, it's a community. So the graduate school is, I still think is one of the wonderful phenomena that we have in our, in our world. It's very much about apprenticeship with an advisor. It's very much about a group of people you belong to. It's a four or five year process. So it's plenty of time to start from kind of nothing to come up to something, you know, more, more expertise, and then to start to have your own creativity start to flower, even surprising your own self. And it's a very cooperative endeavor. I think a lot of people think of science as highly competitive and I think in some other fields it might be more so. Here it's way more cooperative than you might imagine. And people are always teaching each other something and people are always more than happy to be clear that, so I feel I'm an expert on certain kinds of things, but I'm very much not expert on lots of other things and a lot of them are relevant and a lot of them are, I should know, but should in some society, you know, you don't. So I'm always willing to reveal my ignorance to people around me so they can teach me things. And I think a lot of us feel that way about our field. So it's very cooperative. I might add it's also very international because it's so cooperative. We see no barriers. And so that the nationalism that you see, especially in the current era and everything is just at odds with the way that most of us think about what we're doing here, where this is a human endeavor and we cooperate and are very much trying to do it together for the, you know, the benefit of everybody. So last question, where and how and why did you learn French and which language is more beautiful English or French? Great question. So first of all, I think Italian is actually more beautiful than French and English. And I also speak that. So I'm married to an Italian and I have kids and we speak Italian. Anyway, all kidding aside, every language allows you to express things a bit differently. And it is one of the great fun things to do in life is to explore those things. So in fact, when I kids or teens or college students ask me what they study, I say, well, do what your heart, where your heart is, certainly do a lot of math. Math is good for everybody, but do some poetry and do some history and do some language too. You know, throughout your life, you'll want to be a thinking person. You'll want to have done that. For me, French I learned when I was, I'd say a late teen, I was living in the middle of the country in Kansas and not much was going on in Kansas with all due respect to Kansas. And so my parents happened to have some French books on the shelf and just in my boredom, I pulled them down and I found this is fun. And I kind of learned the language by reading. And when I first heard it spoken, I had no idea what was being spoken, but I realized I had somehow knew it from some previous life and so I made the connection. But then I traveled and just I love to go beyond my own barriers and my own comfort or whatever. And I found myself on trains in France next to say older people who had lived a whole life of their own. And the ability to communicate with them was special and the ability to also see myself in other people's shoes and have empathy and kind of work on that language as part of that. So after that kind of experience and also embedding myself in French culture, which is quite amazing, languages are rich, not just because there's something inherently beautiful about it, but it's all the creativity that went into it. So I learned a lot of songs, read poems, read books. And then I was here actually at MIT where we're doing the podcast today and a young professor not yet married and not having a lot of friends in the area. So I just didn't have, I was kind of a bored person. I said, I heard a lot of Italians around. There's happened to be a lot of Italians at MIT, an Italian professor for some reason. And so I was kind of vaguely understanding what they were talking about. I said, well, I should learn this language too. So I did. And then later met my spouse and Italian became a part of my life. But I go to China a lot these days. I go to Asia, I go to Europe and every time I go, I kind of am amazed by the richness of human experience and the people don't have any idea if you haven't traveled, kind of how amazingly rich and I love the diversity. It's not just a buzzword to me. It really means something. I love to embed myself with other people's experiences. And so yeah, learning language is a big part of that. I think I've said in some interview at some point that if I had millions of dollars and infinite time or whatever, what would you really work on if you really wanted to do AI? And for me, that is natural language and really done right. Deep understanding of language. That's to me, an amazingly interesting scientific challenge. One we're very far away on. One we're very far away, but good natural language. People are kind of really invested then. I think a lot of them see that's where the core of AI is that if you understand that you really help human communication, you understand something about the human mind, the semantics that come out of the human mind and I agree, I think that will be such a long time. So I didn't do that in my career just cause I kind of, I was behind in the early days. I didn't kind of know enough of that stuff. I was at MIT, I didn't learn much language and it was too late at some point to kind of spend a whole career doing that, but I admire that field and so in my little way by learning language, you know, kind of that part of my brain has been trained up. Jan was right. You truly are the Miles Davis of machine learning. I don't think there's a better place than it. Mike it was a huge honor talking to you today. Merci beaucoup. All right. It's been my pleasure. Thanks for listening to this conversation with Michael I. Jordan and thank you to our presenting sponsor, Cash App. Download it, use code LEXPodcast, you'll get $10 and $10 will go to FIRST, an organization that inspires and educates young minds to become science and technology innovators of tomorrow. If you enjoy this podcast, subscribe on YouTube, give it five stars on Apple Podcast, support on Patreon, or simply connect with me on Twitter at Lex Friedman. And now let me leave you with some words of wisdom from Michael I. Jordan from his blog post titled Artificial Intelligence, the revolution hasn't happened yet, calling for broadening the scope of the AI field. We should embrace the fact that what we are witnessing is the creation of a new branch of engineering. The term engineering is often invoked in a narrow sense in academia and beyond with overtones of cold, effectless machinery and negative connotations of loss of control by humans. But an engineering discipline can be what we want it to be. In the current era, we have a real opportunity to conceive of something historically new, a human centric engineering discipline. I will resist giving this emerging discipline a name, but if the acronym AI continues to be used, let's be aware of the very real limitations of this placeholder. Let's broaden our scope, tone down the hype, and recognize the serious challenges ahead. Thank you for listening and hope to see you next time. you say is the most interesting disagreement you have with Jan Lacune? So Jan's an old friend and I just say that I don't think we disagree about very much really. He and I both kind of have a let's build it kind of mentality and does it work kind of mentality and kind of concrete. We both speak French and we speak French more together and we have a lot in common. And so if one wanted to highlight a disagreement, it's not really a fundamental one. I think it's just kind of what we're emphasizing. Jan has emphasized pattern recognition and has emphasized prediction. And it's interesting to try to take that as far as you can. If you could do perfect prediction, what would that give you kind of as a thought experiment? And I think that's way too limited. We cannot do perfect prediction. We will never have the data sets that allow me to figure out what you're about ready to do, what question you're going to ask next. I have no clue. I will never know such things. Moreover, most of us find ourselves during the day in all kinds of situations we had no anticipation of that are kind of very, very novel in various ways. And in that moment, we want to think through what we want. And also there's going to be market forces acting on us. I'd like to go down that street, but now it's full because there's a crane in the street. I got it. I got to think about that. I got to think about what I might really want here. And I got to sort of think about how much it costs me to do this action versus this action. I got to think about the risks involved. A lot of our current pattern recognition and prediction systems don't do any risk evaluations. They have no error bars, right? I got to think about other people's decisions around me. I got to think about a collection of my decisions, even just thinking about like a medical treatment, you know, I'm not going to take a, the prediction of a neural net about my health, about something consequential. I'm not about ready to have a heart attack because some number is over 0.7. Even if you had all the data in the world that ever been collected about heart attacks better than any doctor ever had, I'm not going to trust the output of that neural net to predict my heart attack. I'm going to want to ask what if questions around that. I'm going to want to look at some us or other possible data I didn't have, causal things. I'm going to want to have a dialogue with a doctor about things we didn't think about when he gathered the data. You know, I could go on and on. I hope you can see. And I don't, I think that if you say predictions, everything that, that, that you're missing all of this stuff. And so prediction plus decision making is everything, but both of them are equally important. And so the field has emphasized prediction, Jan rightly so has seen how powerful that is. But at the cost of people not being aware that decision making is where the rubber really hits the road, where human lives are at stake, where risks are being taken, where you got to gather more data. You got to think about the error bars. You got to think about the consequences of your decisions on others. You got to think about the economy around your decisions, blah, blah, blah, blah. I'm not the only one working on those, but we're a smaller tribe. And right now we're not the one that people talk about the most. But you know, if you go out in the real world and industry, you know, at Amazon, I'd say half the people there are working on decision making and the other half are doing, you know, the pattern recognition. It's important. And the words of pattern recognition and prediction, I think the distinction there, not to linger on words, but the distinction there is more a constrained sort of in the lab data set versus decision making is talking about consequential decisions in the real world, under the messiness and the uncertainty of the real world. And just the whole of it, the whole mess of it that actually touches human beings and scale. And the forces, that's the distinction. It helps add those, that perspective, that broader perspective. You're right. I totally agree. On the other hand, if you're a real prediction person, of course, you want it to be in the real world. You want to predict real world events. I'm just saying that's not possible with just data sets. That it has to be in the context of, you know, strategic things that someone's doing, data they might gather, things they could have gathered, the reasoning process around data. It's not just taking data and making predictions based on the data. So one of the things that you're working on, I'm sure there's others working on it, but I don't hear often it talked about, especially in the clarity that you talk about it, and I think it's both the most exciting and the most concerning area of AI in terms of decision making. So you've talked about AI systems that help make decisions that scale in a distributed way, millions, billions decisions, sort of markets of decisions. Can you, as a starting point, sort of give an example of a system that you think about when you're thinking about these kinds of systems? Yeah, so first of all, you're absolutely getting into some territory, which I will be beyond my expertise. And there are lots of things that are going to be very not obvious to think about. Just like, again, I like to think about history a little bit, but think about put yourself back in the sixties. There was kind of a banking system that wasn't computerized really. There was database theory emerging and database people had to think about how do I actually not just move data around, but actual money and have it be, you know, valid and have transactions that ATMs happen that are actually, you know, all valid and so on and so forth. So that's the kind of issues you get into when you start to get serious about sorts of things like this. I like to think about as kind of almost a thought experiment to help me think something simpler, which is the music market. And because there is, to first order, there is no music market in the world right now and in our country, for sure. There are something called things called record companies and they make money and they prop up a few really good musicians and make them superstars and they all make huge amounts of money. But there's a long tail of huge numbers of people that make lots and lots of really good music that is actually listened to by more people than the famous people. They are not in a market. They cannot have a career. They do not make money. The creators, the creators, the creators, the so called influencers or whatever that diminishes who they are. So there are people who make extremely good music, especially in the hip hop or Latin world these days. They do it on their laptop. That's what they do on the weekend and they have another job during the week and they put it up on SoundCloud or other sites. Eventually it gets streamed. It now gets turned into bits. It's not economically valuable. The information is lost. It gets put up there. People stream it. You walk around in a big city, you see people with headphones, especially young kids listening to music all the time. If you look at the data, very little of the music they are listening to is the famous people's music and none of it's old music. It's all the latest stuff. But the people who made that latest stuff are like some 16 year old somewhere who will never make a career out of this, who will never make money. Of course there will be a few counter examples. The record companies incentivize to pick out a few and highlight them. Long story short, there's a missing market there. There is not a consumer producer relationship at the level of the actual creative acts. The pipelines and Spotify's of the world that take this stuff and stream it along, they make money off of subscriptions or advertising and those things. They're making the money. All right. And then they will offer bits and pieces of it to a few people again to highlight that they simulate a market. Anyway, a real market would be if you're a creator of music that you actually are somebody who's good enough that people want to listen to you, you should have the data available to you. There should be a dashboard showing a map of the United States. So in last week, here's all the places your songs were listened to. It should be transparent, vetable, so that if someone down in Providence sees that you're being listened to 10,000 times in Providence, that they know that's real data. You know it's real data. They will have you come give a show down there. They will broadcast to the people who've been listening to you that you're coming. If you do this right, you could go down there and make $20,000. You do that three times a year, you start to have a career. So in this sense, AI creates jobs. It's not about taking away human jobs. It's creating new jobs because it creates a new market. Once you've created a market, you've now connected up producers and consumers. The person who's making the music can say to someone who comes to their shows a lot, hey, I'll play at your daughter's wedding for $10,000. You'll say 8,000. They'll say 9,000. Then again, you can now get an income up to $100,000. You're not going to be a millionaire. And now even think about really the value of music is in these personal connections, even so much so that a young kid wants to wear a tshirt with their favorite musician's signature on it. So if they listen to the music on the internet, the internet should be able to provide them with a button that they push and the merchandise arrives the next day. We can do that. And now why should we do that? Well, because the kid who bought the shirt will be happy, but more the person who made the music will get the money. There's no advertising needed. So you can create markets between producers and consumers, take 5% cut. Your company will be perfectly sound. It'll go forward into the future and it will create new markets and that raises human happiness. Now this seems like, well, this is easy, just create this dashboard, kind of create some connections and all that. But if you think about Uber or whatever, you think about the challenges in the real world of doing things like this, and there are actually new principles going to be needed. You're trying to create a new kind of two way market at a different scale that's ever been done before. There's going to be unwanted aspects of the market. There'll be bad people. There'll be the data will get used in the wrong ways, it'll fail in some ways, it won't deliver about. You have to think that through. Just like anyone who ran a big auction or ran a big matching service in economics will think these things through. And so that maybe doesn't get at all the huge issues that can arise when you start to create markets, but it starts to, at least for me, solidify my thoughts and allow me to move forward in my own thinking. Yeah. So I talked to the head of research at Spotify actually, and I think their longterm goal, they've said, is to have at least one million creators make a comfortable living putting on Spotify. So I think you articulate a really nice vision of the world and the digital and the cyberspace of markets. What do you think companies like Spotify or YouTube or Netflix can do to create such markets? Is it an AI problem? Is it an interface problem for interface design? Is it some other kind of, is it an economics problem? Who should they hire to solve these problems? Well, part of it's not just top down. So the Silicon Valley has this attitude that they know how to do it. They will create the system just like Google did with the search box that will be so good that they'll just, everyone will adopt that. It's everything you said, but really I think missing that kind of culture. So it's literally that 16 year old who's able to create the songs. You don't create that as a Silicon Valley entity. You don't hire them per se. You have to create an ecosystem in which they are wanted and that they belong. And so you have to have some cultural credibility to do things like this. Netflix, to their credit, wanted some of that credibility and they created shows, content. They call it content. It's such a terrible word, but it's culture. And so with movies, you can kind of go give a large sum of money to somebody graduating from the USC film school. It's a whole thing of its own, but it's kind of like rich white people's thing to do. And American culture has not been so much about rich white people. It's been about all the immigrants, all the Africans who came and brought that culture and those rhythms to this world and created this whole new thing. American culture. And so companies can't artificially create that. They can't just say, hey, we're here. We're going to buy it up. You've got a partner. And so anyway, not to denigrate, these companies are all trying and they should, and I'm sure they're asking these questions and some of them are even making an effort. But it is partly a respect the culture as a technology person. You've got to blend your technology with cultural meaning. How much of a role do you think the algorithm, so machine learning has in connecting the consumer to the creator, sort of the recommender system aspect of this? Yeah. It's a great question. I think pretty high. There's no magic in the algorithms, but a good recommender system is way better than a bad recommender system. And recommender systems is a billion dollar industry back even 10, 20 years ago. And it continues to be extremely important going forward. What's your favorite recommender system, just so we can put something, well, just historically I was one of the, when I first went to Amazon, I first didn't like Amazon because they put the book people out of business or the library, the local booksellers went out of business. I've come to accept that there probably are more books being sold now and poor people reading them than ever before. And then local book stores are coming back. So that's how economics sometimes work. You go up and you go down. But anyway, when I finally started going there and I bought a few books, I was really pleased to see another few books being recommended to me that I never would have thought of. And I bought a bunch of them. So they obviously had a good business model. But I learned things and I still to this day kind of browse using that service. And I think lots of people get a lot, that is a good aspect of a recommendation system. I'm learning from my peers in an indirect way. And their algorithms are not meant to have them impose what we learn. It really is trying to find out what's in the data. It doesn't work so well for other kinds of entities, but that's just the complexity of human life. Like shirts, I'm not going to get recommendations on shirts, but that's interesting. If you try to recommend restaurants, it's hard. It's hard to do it at scale. But a blend of recommendation systems with other economic ideas, matchings and so on is really, really still very open research wise. And there's new companies that are going to emerge that do that well. What do you think is going to the messy, difficult land of say politics and things like that, that YouTube and Twitter have to deal with in terms of recommendation systems? Being able to suggest, I think Facebook just launched Facebook news. So recommend the kind of news that are most likely for you to be interesting. Do you think this is AI solvable, again, whatever term we want to use, do you think it's a solvable problem for machines or is it a deeply human problem that's unsolvable? So I don't even think about it at that level. I think that what's broken with some of these companies, it's all monetization by advertising. They're not, at least Facebook, I want to critique them, but they didn't really try to connect a producer and a consumer in an economic way, right? No one wants to pay for anything. And so they all, you know, starting with Google and Facebook, they went back to the playbook of, you know, the television companies back in the day. No one wanted to pay for this signal. They will pay for the TV box, but not for the signal, at least back in the day. And so advertising kind of filled that gap and advertising was new and interesting and it somehow didn't take over our lives quite, right? Fast forward, Google provides a service that people don't want to pay for. And so somewhat surprisingly in the nineties, they made, they ended up making huge amounts so they cornered the advertising market. It didn't seem like that was going to happen, at least to me. These little things on the right hand side of the screen just did not seem all that economically interesting, but that companies had maybe no other choice. The TV market was going away and billboards and so on. So they've, they got it. And I think that sadly that Google just has, it was doing so well with that at making such money. They didn't think much more about how, wait a minute, is there a producer consumer relationship to be set up here? Not just between us and the advertisers market to be created. Is there an actual market between the producer consumer? They're the producers, the person who created that video clip, the person that made that website, the person who could make more such things, the person who could adjust it as a function of demand, the person on the other side who's asking for different kinds of things, you know? So you see glimmers of that now there's influencers and there's kind of a little glimmering of a market, but it should have been done 20 years ago. It should have been thought about. It should have been created in parallel with the advertising ecosystem. And then Facebook inherited that. And I think they also didn't think very much about that. So fast forward and now they are making huge amounts of money off of advertising. And the news thing and all these clicks is just feeding the advertising. It's all connected up to the advertiser. So you want more people to click on certain things because that money flows to you, Facebook. You're very much incentivized to do that. And when you start to find it's breaking, people are telling you, well, we're getting into some troubles. You try to adjust it with your smart AI algorithms, right? And figure out what are bad clicks. So maybe it shouldn't be click through rate, it should be something else. I find that pretty much hopeless. It does get into all the complexity of human life and you can try to fix it. You should, but you could also fix the whole business model. And the business model is that really, what are, are there some human producers and consumers out there? Is there some economic value to be liberated by connecting them directly? Is it such that it's so valuable that people will be able to pay for it? All right. And micro payments, like small payments. Micro, but even have to be micro. So I like the example, suppose I'm going, next week I'm going to India. Never been to India before. Right? I have a couple of days in Mumbai, I have no idea what to do there. Right? And I could go on the web right now and search. It's going to be kind of hopeless. I'm not going to find, you know, I have lots of advertisers in my face. Right? What I really want to do is broadcast to the world that I am going to Mumbai and have someone on the other side of a market look at me and, and there's a recommendation system there. So I'm not looking at all possible people coming to Mumbai. They're looking at the people who are relevant to them. So someone in my age group, someone who kind of knows me in some level, I give up a little privacy by that, but I'm happy because what I'm going to get back is this person can make a little video for me, or they're going to write a little two page paper on here's the cool things that you want to do and move by this week, especially, right? I'm going to look at that. I'm not going to pay a micro payment. I'm going to pay, you know, a hundred dollars or whatever for that. It's real value. It's like journalism. Um, and as an honest subscription, it's that I'm going to pay that person in that moment. Company's going to take 5% of that. And that person has now got it. It's a gig economy, if you will, but you know, done for it, you know, thinking about a little bit behind YouTube, there was actually people who could make more of those things. If they were connected to a market, they would make more of those things independently. You don't have to tell them what to do. You don't have to incentivize them any other way. Um, and so, yeah, these companies, I don't think have thought long and hard about that. So I do distinguish on Facebook on the one side, who just not thought about these things at all. I think, uh, thinking that AI will fix everything, uh, and Amazon thinks about them all the time because they were already out in the real world. They were delivering packages, people's doors. They were, they were worried about a market. They were worried about sellers and, you know, they worry and some things they do are great. Some things maybe not so great, but you know, they're in that business model. And then I'd say Google sort of hovers somewhere in between. I don't, I don't think for a long, long time they got it. I think they probably see that YouTube is more pregnant with possibility than, than, than they might've thought and that they're probably heading that direction. Um, but uh, you know, Silicon Valley has been dominated by the Google Facebook kind of mentality and the subscription and advertising and that is, that's the core problem, right? The fake news actually rides on top of that because it means that you're monetizing with clip through rate and that is the core problem. You got to remove that. So advertisement, if we're going to linger on that, I mean, that's an interesting thesis. I don't know if everyone really deeply thinks about that. So you're right. The thought is the advertising model is the only thing we have, the only thing we'll ever have. We have to fix, we have to build algorithms that despite that business model, you know, find the better angels of our nature and do good by society and by the individual. But you think we can slowly, you think, first of all, there's a difference between should and could. So you're saying we should slowly move away from the advertising model and have a direct connection between the consumer and the creator. The question I also have is, can we, because the advertising model is so successful now in terms of just making a huge amount of money and therefore being able to build a big company that provides, has really smart people working that create a good service. Do you think it's possible? And just to clarify, you think we should move away? Well, I think we should. Yeah. But we is the, you know, me. So society. Yeah. Well, the companies, I mean, so first of all, full disclosure, I'm doing a day a week at Amazon because I kind of want to learn more about how they do things. So, you know, I'm not speaking for Amazon in any way, but, you know, I did go there because I actually believe they get a little bit of this or trying to create these markets. And they don't really use, advertising is not a crucial part of it. Well, that's a good question. So it has become not crucial, but it's become more and more present if you go to Amazon website. And, you know, without revealing too many deep secrets about Amazon, I can tell you that, you know, a lot of people in the company question this and there's a huge questioning going on. You do not want a world where there's zero advertising. That actually is a bad world. Okay. So here's a way to think about it. You're a company that like Amazon is trying to bring products to customers, right? And the customer, at any given moment, you want to buy a vacuum cleaner, say, you want to know what's available for me. And, you know, it's not going to be that obvious. You have to do a little bit of work at it. The recommendation system will sort of help, right? But now suppose this other person over here has just made the world, you know, they spent a huge amount of energy. They had a great idea. They made a great vacuum cleaner. They know they really did it. They nailed it. It's an MIT, you know, whiz kid that made a great new vacuum cleaner, right? It's not going to be in the recommendation system. No one will know about it. The algorithms will not find it and AI will not fix that. Okay. At all. Right. How do you allow that vacuum cleaner to start to get in front of people, be sold well advertising. And here, what advertising is, it's a signal that you're, you believe in your product enough that you're willing to pay some real money for it. And to me as a consumer, I look at that signal. I say, well, first of all, I know these are not just cheap little ads cause we have now right now there. I know that, you know, these are super cheap, you know, pennies. If I see an ad where it's actually, I know the company is only doing a few of these and they're making, you know, real money is kind of flowing and I see an ad, I may pay more attention to it. And I actually might want that because I see, Hey, that guy spent money on his vacuum cleaner. Maybe there's something good there. So I will look at it. And so that's part of the overall information flow in a good market. So advertising has a role, but the problem is of course that that signal is now completely gone because it just, you know, dominant by these tiny little things that add up to big money for the company, you know? So I think it will just, I think it will change because the societies just don't, you know, stick with things that annoy a lot of people and advertising currently annoys people more than it provides information. And I think that a Google probably is smart enough to figure out that this is a dead, this is a bad model, even though it's a hard, huge amount of money and they'll have to figure out how to pull it away from it slowly. And I'm sure the CEO there will figure it out, but they need to do it. And they needed it to, so if you reduce advertising, not to zero, but you reduce it at the same time you bring up producer, consumer, actual real value being delivered. So real money is being paid and they take a 5% cut that 5% could start to get big enough to cancel out the lost revenue from the kind of the poor kind of advertising. And I think that a good company will do that, will realize that. And Facebook, you know, again, God bless them. They bring, you know, grandmothers, they bring children's pictures into grandmothers lives. It's fantastic. But they need to think of a new business model and that's the core problem there. Until they start to connect producer consumer, I think they will just continue to make money and then buy the next social network company and then buy the next one and the innovation level will not be high and the health issues will not go away. So I apologize that we kind of returned to words, I don't think the exact terms matter, but in sort of defense of advertisement, don't you think the kind of direct connection between consumer and creator producer is what advertisement strives to do, right? So that is best advertisement is literally now Facebook is listening to our conversation and heard that you're going to India and will be able to actually start automatically for you making these connections and start giving this offer. So like, I apologize if it's just a matter of terms, but just to draw a distinction, is it possible to make advertisements just better and better and better algorithmically to where it actually becomes a connection, almost a direct connection? That's a good question. So let's component on that. First of all, what we just talked about, I was defending advertising. Okay. So I was defending it as a way to get signals into a market that don't come any other way, especially algorithmically. It's a sign that someone spent money on it, it's a sign they think it's valuable. And if I think that if other things, someone else thinks it's valuable, and if I trust other people, I might be willing to listen. I don't trust that Facebook though, who's an intermediary between this. I don't think they care about me. Okay. I don't think they do. And I find it creepy that they know I'm going to India next week because of our conversation. Why do you think that is? So what, could you just put your PR hat on? Why do you think you find Facebook creepy and not trust them as do majority of the population? So they're out of the Silicon Valley companies, I saw like not approval rate, but there's ranking of how much people trust companies and Facebook is in the gutter. In the gutter, including people inside of Facebook. So what do you attribute that to? Because when I... Come on, you don't find it creepy that right now we're talking that I might walk out on the street right now that some unknown person who I don't know kind of comes up to me and says, I hear you're going to India. I mean, that's not even Facebook. That's just, I want transparency in human society. I want to have, if you know something about me, there's actually some reason you know something about me. That's something that if I look at it later and audit it kind of, I approve. You know something about me because you care in some way. There's a caring relationship even, or an economic one or something. Not just that you're someone who could exploit it in ways I don't know about or care about or I'm troubled by or whatever. We're in a world right now where that happens way too much and that Facebook knows things about a lot of people and could exploit it and does exploit it at times. I think most people do find that creepy. It's not for them. It's not that Facebook is not doing it because they care about them in a real sense. And they shouldn't. They should not be a big brother caring about us. That is not the role of a company like that. Why not? Wait, not the big brother part, but the caring, the trusting. I mean, don't those companies, just to link on it because a lot of companies have a lot of information about us. I would argue that there's companies like Microsoft that has more information about us than Facebook does and yet we trust Microsoft more. Well, Microsoft is pivoting. Microsoft, you know, under Satya Nadella has decided this is really important. We don't want to do creepy things. Really want people to trust us to actually only use information in ways that they really would approve of, that we don't decide, right? And I'm just kind of adding that the health of a market is that when I connect to someone who produces a consumer, it's not just a random producer or consumer, it's people who see each other. They don't like each other, but they sense that if they transact, some happiness will go up on both sides. If a company helps me to do that in moments that I choose of my choosing, then fine. So, and also think about the difference between, you know, browsing versus buying, right? There are moments in my life I just want to buy, you know, a gadget or something. I need something for that moment. I need some ammonia for my house or something because I got a problem with a spill. I want to just go in. I don't want to be advertised at that moment. I don't want to be led down various, you know, that's annoying. I want to just go and have it be extremely easy to do what I want. Other moments I might say, no, it's like today I'm going to the shopping mall. I want to walk around and see things and see people and be exposed to stuff. So I want control over that though. I don't want the company's algorithms to decide for me, right? I think that's the thing. There's a total loss of control if Facebook thinks they should take the control from us of deciding when we want to have certain kinds of information, when we don't, what information that is, how much it relates to what they know about us that we didn't really want them to know about us. I don't want them to be helping me in that way. I don't want them to be helping them by they decide they have control over what I want and when. I totally agree. Facebook, by the way, I have this optimistic thing where I think Facebook has the kind of personal information about us that could create a beautiful thing. So I'm really optimistic of what Facebook could do. It's not what it's doing, but what it could do. So I don't see that. I think that optimism is misplaced because there's not a bit, you have to have a business model behind these things. Create a beautiful thing is really, let's be, let's be clear. It's about something that people would value. And I don't think they have that business model and I don't think they will suddenly discover it by what, you know, a long hot shower. I disagree. I disagree in terms of, you can discover a lot of amazing things in a shower. So I didn't say that. I said, they won't come, they won't do it, but in the shower, I think a lot of other people will discover it. I think that this guy, so I should also, full disclosure, there's a company called United Masters, which I'm on their board and they've created this music market and I have a hundred thousand artists now signed on and they've done things like gone to the NBA and the NBA, the music you find behind NBA clips right now is their music, right? That's a company that had the right business model in mind from the get go, right? Executed on that. And from day one, there was value brought to, so here you have a kid who made some songs who suddenly their songs are on the NBA website, right? That's real economic value to people. And so, you know, so you and I differ on the optimism of being able to sort of change the direction of the Titanic, right? So I, yeah, I'm older than you, so I've seen some Titanic's crash, got it. But and just to elaborate, cause I totally agree with you and I just want to know how difficult you think this problem is of, so for example, I want to read some news and I would, there's a lot of times in the day where something makes me either smile or think in a way where I like consciously think this really gave me value. Like I sometimes listen to the daily podcasts in the New York times, way better than the New York times themselves, by the way, for people listening. That's like real journalism is happening for some reason in the podcast space. It doesn't make sense to me, but often I listen to it 20 minutes and I would be willing to pay for that, like $5, $10 for that experience. And how difficult, that's kind of what you're getting at is that little transaction. How difficult is it to create a frictionless system like Uber has, for example, for other things? What's your intuition there? So I, first of all, I pay little bits of money to, you know, to send, there's something called courts that does financial things. I like medium as a site, I don't pay there, but I would. You had a great post on medium. I would have loved to pay you a dollar and not others. I wouldn't have wanted it per se because there should be also sites where that's not actually the goal. The goal is to actually have a broadcast channel that I monetize in some other way if I chose to. I mean, I could now people know about it. I could, I'm not doing it, but that's fine with me. Also the musicians who are making all this music, I don't think the right model is that you pay a little subscription fee to them, right? Because people can copy the bits too easily and it's just not that somewhere the value is. The value is that a connection was made between real human beings, then you can follow up on that. All right. And create yet more value. So no, I think there's a lot of open questions here, hot open questions, but also, yeah, I do want good recommendation systems that recommend cool stuff to me. But it's pretty hard, right? I don't like them to recommend stuff just based on my browsing history. I don't like the based on stuff they know about me, quote unquote. What's unknown about me is the most interesting. So this is the, this is the really interesting question. We may disagree, maybe not. I think that I love recommender systems and I want to give them everything about me in a way that I trust. Yeah. But you, but you don't, because, so for example, this morning I clicked on a, you know, I was pretty sleepy this morning. I clicked on a story about the queen of England. Yes. Right. I do not give a damn about the queen of England. I really do not. But it was clickbait. It kind of looked funny and I had to say, what the heck are they talking about? I don't want to have my life, you know, heading that direction. Now that's in my browsing history. The system in any reasonable system will think that I care about the queen of England. That's browsing history. Right. But, but you're saying all the trace, all the digital exhaust or whatever, that's been kind of the models. If you collect all this stuff, you're going to figure all of us out. Well, if you're trying to figure out like kind of one person like Trump or something, maybe you could figure him out. But if you're trying to figure out, you know, 500 million people, you know, no way, no way. You think so? No, I do. I think so. I think we are, humans are just amazingly rich and complicated. Every one of us has our little quirks, every one of us has our little things that could intrigue us that we don't even know it will intrigue us. And there's no sign of it in our past, but by God, there it comes and you know, you fall in love with it. And I don't want a company trying to figure that out for me and anticipate that I want them to provide a forum, a market, a place that I kind of go and by hook or by crook, this happens, you know, I I'm walking down the street and I hear some Chilean music being played and I never knew I liked Chilean music, but wow. So there is that side and I want them to provide a limited, but you know, interesting place to go. Right. And so don't try to use your AI to kind of, you know, figure me out and then put me in a world where you figured me out, you know, no, create huge spaces for human beings where our creativity and our style will be enriched and come forward and it'll be a lot of more transparency. I won't have people randomly, anonymously putting comments up and I'll special based on stuff they know about me, facts that, you know, we are so broken right now. If you're, you know, especially if you're a celebrity, but you know, it's about anybody that anonymous people are hurting lots and lots of people right now. That's part of this thing that Silicon Valley is thinking that, you know, just collect all this information and use it in a great way. So no, I'm not, I'm not a pessimist, I'm very much an optimist by nature, but I think that's just been the wrong path for the whole technology to take. Be more limited, create, let humans rise up. Don't try to replace them. That's the AI mantra. Don't try to anticipate them. Don't try to predict them because you're, you're, you're not going to, you're not going to be able to do those things. You're going to make things worse. Okay. So right now, just give this a chance. Right now, the recommender systems are the creepy people in the shadow watching your every move. So they're looking at traces of you. They're not directly interacting with you, sort of the, your close friends and family, the way they know you is by having conversation, by actually having interactions back and forth. Do you think there's a place for recommender systems sort of to step, cause you, you just emphasize the value of human to human connection, but yeah, just give it a chance, AI human connection. Is there a role for an AI system to have conversations with you in terms of, to try to figure out what kind of music you like, not by just watching what you listening to, but actually having a conversation, natural language or otherwise. Yeah, no, I'm, I'm, so I'm not against it. I just wanted to push back against the, maybe you're saying you have options for Facebook. So there I think it's misplaced, but, but I think that distributing, yeah, no, so good for you. Go for it. That's a hard spot to be in. Yeah, no, good. Human interaction, like on our daily, the context around me in my own home is something that I don't want some big company to know about at all, but I would be more than happy to have technology help me with it. Which kind of technology? Well, you know, just, Alexa, Amazon, well, a good, Alexa's done right. And I think Alexa is a research platform right now more than anything else. But Alexa done right, you know, could do things like I, I leave the water running in my garden and I say, Hey, Alexa, the water's running in my garden. And even have Alexa figure out that that means when my wife comes home, that she should be told about that. That's a little bit of a reasoning. I would call that AI and by any kind of stretch, it's a little bit of reasoning and it actually kind of would make my life a little easier and better. And you know, I don't, I wouldn't call this a wow moment, but I kind of think that overall rises human happiness up to have that kind of thing. But not when you're lonely, Alexa, knowing loneliness. No, no, I don't want Alexa to be, feel intrusive. And I don't want just the designer of the system to kind of work all this out. I really want to have a lot of control and I want transparency and control. And if a company can stand up and give me that in the context of new technology, I think they're good. First of all, be way more successful than our current generation. And like I said, I was mentioning Microsoft, I really think they're, they're pivoting to kind of be the trusted old uncle, but you know, I think that they get that this is a way to go, that if you let people find technology, empowers them to have more control and have and have control, not just over privacy, but over this rich set of interactions, that that people are going to like that a lot more. And that's, that's the right business model going forward. What does control over privacy look like? Do you think you should be able to just view all the data that? No, it's much more than that. I mean, first of all, it should be an individual decision. Some people don't want privacy. They want their whole life out there. Other people's want it. Privacy is not a zero one. It's not a legal thing. It's not just about which data is available, which is not. I like to recall to people that, you know, a couple hundred years ago, everyone, there was not really big cities, everyone lived in on the countryside and villages and villages. Everybody knew everything about you. Very, you didn't have any privacy. Is that bad? Are we better off now? Well, you know, arguably no, because what did you get for that loss of certain kinds of privacy? Well, people help each other if they, because they know everything about you. They know something's bad's happening, they will help you with that. Right. And now you live in a big city, no one knows about that. You get no help. So it kind of depends the answer. I want certain people who I trust and there should be relationships. I should kind of manage all those, but who knows what about me? I should have some agency there. It shouldn't, I shouldn't be a drift in a sea of technology where I have no agency. I don't want to go reading things and checking boxes. So I don't know how to do that. And I'm not a privacy researcher per se. I just, I recognize the vast complexity of this. It's not just technology. It's not just legal scholars meeting technologists. There's gotta be kind of a whole layers around it. And so I, when I alluded to this emerging engineering field, this is a big part of it. When electrical engineering came, I'm not one around at the time, but you just didn't plug electricity into walls and all kinds of work. You don't have to have like underwriters laboratory that reassured you that that plug's not going to burn up your house and that that machine will do this and that and everything. There'll be whole people who can install things. There'll be people who can watch the installers. There'll be a whole layers, you know, an onion of these kinds of things. And for things as deep and interesting as privacy, which is as least as interesting as electricity, that's going to take decades to kind of work out, but it's going to require a lot of new structures that we don't have right now. So it's kind of hard to talk about it. And you're saying there's a lot of money to be made if you get it right. So something you should look at. A lot of money to be made in all these things that provide human services and people recognize them as useful parts of their lives. So yeah. So yeah, the dialogue sometimes goes from the exuberant technologists to the no technology is good, kind of. And that's, you know, in our public discourse, you know, and as far as you see too much of this kind of thing and the sober discussions in the middle, which are the challenge he wants to have or where we need to be having our conversations. And you know, there's just not actually, there's not many forum fora for those. You know, there's, that's, that's kind of what I would look for. Maybe I could go and I could read a comment section of something and it would actually be this kind of dialogue going back and forth. You don't see much of this, right? Which is why actually there's a resurgence of podcasts out of all, because people are really hungry for conversation, but there's technology is not helping much. So comment sections of anything, including YouTube is not hurting and not helping.\",\n          \"We are becoming cyborgs. Our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous, from homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is like essentially a new species. Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo techno. I think this is what, it's a brain augmentation. So it like allows for actual evolution. Like the computers accelerate the degree to which all the other technologies can also be accelerated. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. So you're one of the earliest of the species. I think most of us are. The following is a conversation with Grimes, an artist, musician, songwriter, producer, director, and a fascinating human being who thinks a lot about both the history and the future of human civilization. Studying the dark periods of our past to help form an optimistic vision of our future. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Grimes. Oh yeah, the cloud lifter, there you go. There you go. You know your stuff. Have you ever used a cloud lifter? Yeah, I actually, this microphone cloud lifter is what Michael Jackson used, so. No, really? Yeah, this is like Thriller and stuff. This mic and a cloud lifter? Yeah, it's a incredible microphone. It's very flattering on vocals. I've used this a lot. It's great for demo vocals. It's great in a room. Sometimes it's easier to record vocals if you're just in a room and the music's playing and you just wanna feel it so it's not in the headphones. And this mic is pretty directional, so I think it's a good mic for just vibing out and just getting a real good vocal take. Just vibing, just in a room. Anyway, this is the Michael Jackson, Quincy Jones microphone. I feel way more badass now. All right, you wanna just get into it? I guess so. All right, one of your names, at least in this space and time, is C, like the letter C. And you told me that C means a lot of things. It's the speed of light. It's the render rate of the universe. It's yes in Spanish. It's the crescent moon. And it happens to be my favorite programming language because it basically runs the world, but it's also powerful, fast, and it's dangerous because you can mess things up really bad with it because of all the pointers. But anyway, which of these associations will the name C is the coolest to you? I mean, to me, the coolest is the speed of light, obviously, or the speed of light. When I say render rate of the universe, I think I mean the speed of light because essentially that's what we're rendering at. See, I think we'll know if we're in a simulation if the speed of light changes because if they can improve their render speed, then. Well, it's already pretty good. It's already pretty good, but if it improves, then we'll know, we can probably be like, okay, they've updated or upgraded. Well, it's fast enough for us humans because it seems immediate. There's no delay, there's no latency in terms of us humans on Earth interacting with things. But if you're like intergalactic species operating on a much larger scale, then you're gonna start noticing some weird stuff. Or if you can operate in like around a black hole, then you're gonna start to see some render issues. You can't go faster than the speed of light, correct? So it really limits our ability or one's ability to travel space. Theoretically, you can, you have wormholes. So there's nothing in general relativity that precludes faster than the speed of light travel. But it just seems you're gonna have to do some really funky stuff with very heavy things that have like weirdnesses, that have basically terrors in space time. We don't know how to do that. Do navigators know how to do it? Do navigators? Yeah. Folding space, basically making wormholes. So the name C. Yes. Who are you? Do you think of yourself as multiple people? Are you one person? Do you know, like in this morning, were you a different person than you are tonight? We are, I should say, recording this basically at midnight, which is awesome. Yes, thank you so much. I think I'm about eight hours late. No, you're right on time. Good morning. This is the beginning of a new day soon. Anyway, are you the same person you were in the morning and the evening? Is there multiple people in there? Do you think of yourself as one person? Or maybe you have no clue? Or are you just a giant mystery to yourself? Okay, these are really intense questions, but. Let's go, let's go. Because I asked this myself, like look in the mirror, who are you? People tell you to just be yourself, but what does that even mean? I mean, I think my personality changes with everyone I talk to. So I have a very inconsistent personality. Yeah. Person to person, so the interaction, your personality materializes. Or my mood. Like I'll go from being like a megalomaniac to being like, you know, just like a total hermit who is very shy. So some combinatorial combination of your mood and the person you're interacting with. Yeah, mood and people I'm interacting with. But I think everyone's like that. Maybe not. Well, not everybody acknowledges it and able to introspect it. Who brings out, what kind of person, what kind of mood brings out the best in you? As an artist and as a human. Can you introspect this? Like my best friends, like people I can, when I'm like super confident and I know that they're gonna understand everything I'm saying, so like my best friends, then when I can start being really funny, that's always my like peak mode. But it's like, yeah, takes a lot to get there. Let's talk about constraints. You've talked about constraints and limits. Do those help you out as an artist or as a human being? Or do they get in the way? Do you like the constraints? So in creating music, in creating art, in living life, do you like the constraints that this world puts on you? Or do you hate them? If constraints are moving, then you're good, right? Like it's like as we are progressing with technology, we're changing the constraints of like artistic creation. You know, making video and music and stuff is getting a lot cheaper. There's constantly new technology and new software that's making it faster and easier. We have so much more freedom than we had in the 70s. Like when Michael Jackson, you know, when they recorded Thriller with this microphone, like they had to use a mixing desk and all this stuff. And like probably even get in a studio, it's probably really expensive and you have to be a really good singer and you have to know how to use like the mixing desk and everything. And now I can just, you know, make I've made a whole album on this computer. I have a lot more freedom, but then I'm also constrained in different ways because there's like literally millions more artists. It's like a much bigger playing field. It's just like, I also, I didn't learn music. I'm not a natural musician. So I don't know anything about actual music. I just know about like the computer. So I'm really kind of just like messing around and like trying things out. Well, yeah, I mean, but the nature of music is changing. So you're saying you don't know actual music, what music is changing. Music is becoming, you've talked about this, is becoming, it's like merging with technology. Yes. It's becoming something more than just like the notes on a piano. It's becoming some weird composition that requires engineering skills, programming skills, some kind of human robot interaction skills, and still some of the same things that Michael Jackson had, which is like a good ear for a good sense of taste of what's good and not the final thing when it's put together. Like you're allowed, you're enabled, empowered with a laptop to layer stuff, to start like layering insane amounts of stuff. And it's super easy to do that. I do think music production is a really underrated art form. I feel like people really don't appreciate it. When I look at publishing splits, the way that people like pay producers and stuff, it's super, producers are just deeply underrated. Like so many of the songs that are popular right now or for the last 20 years, like part of the reason they're popular is because the production is really interesting or really sick or really cool. And it's like, I don't think listeners, like people just don't really understand what music production is. It's not, it's sort of like this weird, discombobulated art form. It's not like a formal, because it's so new, there isn't like a formal training path for it. It's mostly driven by like autodidacts. Like it's like almost everyone I know who's good at production, like they didn't go to music school or anything. They just taught themselves. Are they're mostly different? Like the music producers, you know, is there some commonalities that time together or are they all just different kinds of weirdos? Cause I just, I just hung out with Rick Rubin. I don't know if you've. Yeah, I mean, Rick Rubin is like literally one of the gods of music production. Like he's one of the people who first, you know, who like made music production, you know, made the production as important as the actual lyrics or the notes. But the thing he does, which is interesting, I don't know if you can speak to that, but just hanging out with him, he seems to just sit there in silence, close his eyes and listen. It's like, he almost does nothing. And that nothing somehow gives you freedom to be the best version of yourself. So that's music production somehow too, which is like encouraging you to do less, to simplify, to like push towards minimalism. I mean, I guess, I mean, I work differently from Rick Rubin cause Rick Rubin produces for other artists, whereas like I mostly produce for myself. So it's a very different situation. I also think Rick Rubin, he's in that, I would say advanced category of producer where like you've like earned your, you can have an engineer and stuff and people like do the stuff for you. But I usually just like do stuff myself. So you're the engineer, the producer and the artist. Yeah, I guess I would say I'm in the era, like the post Rick Rubin era. Like I come from the kind of like Skrillex school of thought, which is like where you are. Yeah, the engineer, producer, artist. Like where, I mean lately, sometimes I'll work with a producer now. I'm gently sort of delicately starting to collaborate a bit more, but like I think I'm kind of from the, like the whatever 2010s explosion of things where everything became available on the computer and you kind of got this like lone wizard energy thing going. So you embraced being the loneliness. Is the loneliness somehow an engine of creativity? Like, so most of your stuff, most of your creative quote unquote genius in quotes is in the privacy of your mind. Yes, well, it was, but here's the thing. I was talking to Daniel Eck and he said, he's like most artists, they have about 10 years, like 10 good years. And then they usually stop making their like vital shit. And I feel like I'm sort of like nearing the end of my 10 years on my own. So you have to become somebody else. Now I'm like, I'm in the process of becoming somebody else and reinventing. When I work with other people, because I've never worked with other people, I find that I make like, that I'm exceptionally rejuvenated and making like some of the most vital work I've ever made. So, because I think another human brain is like one of the best tools you can possibly find. Like. It's a funny way to put it, I love it. It's like if a tool is like, you know, whatever HP plus one or like adds some like stats to your character, like another human brain will like square it instead of just like adding something. Double up the experience points, I love this. We should also mention we're playing Tavern music before this and which I love, which I first, I think I first. You had to stop the Tavern music. Yeah, because it doesn't, the audio. Okay, okay. But it makes. Yeah, it'll make the podcast annoying. Add it in post, add it in post. No one will want to listen to the podcast. They probably would, but it makes me, it reminds me like of a video game, like a role playing video game where you have experience points. There's something really joyful about wandering places like Elder Scrolls, like Skyrim, just exploring these landscapes in another world and then you get experience points and you can work on different skills and somehow you progress in life. I don't know, it's simple. It doesn't have some of the messy complexities of life and there's usually a bad guy you can fight in Skyrim. It's dragons and so on. I'm sure in Elden Ring, there's a bunch of monsters you can fight. I love that. I feel like Elden Ring, I feel like this is a good analogy to music production though because it's like, I feel like the engineers and the people creating these open worlds are, it's sort of like similar to people, to music producers where it's like this hidden archetype that like no one really understands what they do and no one really knows who they are, but they're like, it's like the artist engineer because it's like, it's both art and fairly complex engineering. Well, you're saying they don't get enough credit. Aren't you kind of changing that by becoming the person doing everything? Aren't you, isn't the engineer? Well, I mean, others have gone before me. I'm not, you know, there's like Timbaland and Skrillex and there's all these people that are like, you know, very famous for this, but I just think the general, I think people get confused about what it is and just don't really know what it is per se and it's just when I see a song, like when there's like a hit song, like I'm just trying to think of like, just going for like even just a basic pop hit, like, what's it? Like Rules by Dua Lipa or something. The production on that is actually like really crazy. I mean, the song is also great, but it's like the production is exceptionally memorable. Like, you know, and it's just like no one, I can't, I don't even know who produced that song. It's just like, isn't part of like the rhetoric of how we just discuss the creation of art. We just sort of like don't consider the music producer because I think the music producer used to be more just simply recording things. Yeah, that's interesting because when you think about movies, we talk about the actor and the actresses, but we also talk about the directors. We don't talk about like that with the music as often. The Beatles music producer was one of the first kind of guy, one of the first people sort of introducing crazy sound design into pop music. I forget his name. He has the same, I forget his name, but you know, like he was doing all the weird stuff like dropping pianos and like, yeah. Oh, to get the, yeah, yeah, yeah, to get the sound, to get the authentic sound. What about lyrics? You think those, where did they fit into how important they are? I was heartbroken to learn that Elvis didn't write his songs. I was very mad. A lot of people don't write their songs. I understand this, but. But here's the thing. I feel like there's this desire for authenticity. I used to be like really mad when like people wouldn't write or produce their music and I'd be like, that's fake. And then I realized there's all this like weird bitterness and like agronus in art about authenticity. But I had this kind of like weird realization recently where I started thinking that like art is sort of a decentralized collective thing. Like art is kind of a conversation with all the artists that have ever lived before you. You know, like it's like, you're really just sort of, it's not like anyone's reinventing the wheel here. Like you're kind of just taking, you know, thousands of years of art and like running it through your own little algorithm and then like making your interpretation of it. You just joined the conversation with all the other artists that came before. It's just a beautiful way to look at it. Like, and it's like, I feel like everyone's always like, there's all this copyright and IP and this and that or authenticity. And it's just like, I think we need to stop seeing this as this like egotistical thing of like, oh, the creative genius, the lone creative genius or this or that. Because it's like, I think art shouldn't be about that. I think art is something that sort of brings humanity together. And it's also, art is also kind of the collective memory of humans. It's like, we don't give a fuck about whatever ancient Egypt, like how much grain got sent that day and sending the records and like, you know, like who went where and, you know, how many shields needed to be produced for this. Like we just remember their art. And it's like, you know, it's like in our day to day life, there's all this stuff that seems more important than art because it helps us function and survive. But when all this is gone, like the only thing that's really gonna be left is the art. The technology will be obsolete. That's so fascinating. Like the humans will be dead. That is true. A good compression of human history is the art we've generated across the different centuries, the different millennia. So when the aliens come. When the aliens come, they're gonna find the hieroglyphics and the pyramids. I mean, art could be broadly defined. They might find like the engineering marvels, the bridges, the rockets, the. I guess I sort of classify though. Architecture is art too. I consider engineering in those formats to be art, for sure. It sucks that like digital art is easier to delete. So if there's an apocalypse, a nuclear war, that can disappear. Yes. And the physical. There's something still valuable about the physical manifestation of art. That sucks that like music, for example, has to be played by somebody. Yeah, I do think we should have a foundation type situation where we like, you know how we have like seed banks up in the north and stuff? Like we should probably have like a solar powered or geothermal little bunker that like has all human knowledge. You mentioned Daniel Ek and Spotify. What do you think about that as an artist? What's Spotify? Is that empowering? To me, Spotify as a consumer is super exciting. It makes it easy for me to access music from all kinds of artists, get to explore all kinds of music, make it super easy to sort of curate my own playlist and have fun with all that. It was so liberating to let go. You know, I used to collect, you know, albums and CDs and so on, like horde albums. Yeah. Like they matter. But the reality you could, you know, that was really liberating that I could let go of that. And letting go of the albums you're kind of collecting allows you to find new music, exploring new artists and all that kind of stuff. But I know from a perspective of an artist that could be, like you mentioned, competition could be a kind of constraint because there's more and more and more artists on the platform. I think it's better that there's more artists. I mean, again, this might be propaganda because this is all from a conversation with Daniel Ek. So this could easily be propaganda. We're all a victim of somebody's propaganda. So let's just accept this. But Daniel Ek was telling me that, you know, to understand really difficult concepts just in a very different way, like an emotional intelligence about something deep within? Oh yeah, no, like if X hurts, like if X bites me really hard and I'm like, ow, like he gets, he's sad. He's like sad if he hurts me by accident. Yeah. Which he's huge, so he hurts me a lot by accident. Yeah, that's so interesting that that mind emerges and he and children don't really have memory of that time. So we can't even have a conversation with them about it. Yeah, I just thank God they don't have a memory of this time because like, think about like, I mean with our youngest baby, like it's like, I'm like, have you read the sci fi short story, I Have No Mouth But I Must Scream? Good title, no. Oh man, I mean, you should read that. I Have No Mouth But I Must Scream. I hate getting into this Rocco's Basilisk shit. It's kind of a story about the, about like an AI that's like torturing someone in eternity and they have like no body. The way they describe it, it sort of sounds like what it feels like, like being a baby, like you're conscious and you're just getting inputs from everywhere and you have no muscles and you're like jelly and you like can't move and you try to like communicate, but you can't communicate and we're, and like, you're just like in this like hell state. I think it's good we can't remember that. Like my little baby is just exiting that, like she's starting to like get muscles and have more like autonomy, but like watching her go through the opening phase, I was like, I was like, this does not seem good. Oh, you think it's kind of like. Like I think it sucks. I think it might be really violent. Like violent, mentally violent, psychologically violent. Consciousness emerging, I think is a very violent thing. I never thought about that. I think it's possible that we all carry quite a bit of trauma from it that we don't, I think that would be a good thing to study because I think if, I think addressing that trauma, like, I think that might be. Oh, you mean like echoes of it are still there in the shadows somewhere. I think it's gotta be, I feel this, this help, the helplessness, the like existential and that like fear of being in like an unknown place bombarded with inputs and being completely helpless, like that's gotta be somewhere deep in your brain and that can't be good for you. What do you think consciousness is? This whole conversation has impossibly difficult questions. What do you think it is? Debbie said this is like so hard. Yeah, we talked about music for like two minutes. All right. No, I'm so, I'm just over music. I'm over music. Yeah, I still like it. It has its purpose. No, I love music. I mean, music's the greatest thing ever. It's my favorite thing. But I just like every interview is like, what is your process? Like, I don't know. I'm just done. I can't do anything. I do want to ask you about Able to Live. Oh, I'll tell you about Ableton because Ableton's sick. No one has ever asked about Ableton though. Yeah, well, because I just need tech support mainly. I can help you. I can help you with your Ableton tech. Anyway, from Ableton back to consciousness. What do you, do you think this is a thing that only humans are capable of? Can robots be conscious? Can, like when you think about entities, you think there's aliens out there that are conscious? Like is conscious, what is consciousness? There's this Terrence McKenna quote that I've found that I fucking love. Am I allowed to swear on here? Yes. Nature loves courage. You make the commitment and nature will respond to that commitment by removing impossible obstacles. Dream the impossible dream and the world will not grind you under. It will lift you up. This is the trick. This is what all these teachers and philosophers who really counted, who really touched the alchemical gold, this is what they understood. This is the shamanic dance in the waterfall. This is how magic is done. By hurling yourself into the abyss and discovering it's a feather bed. Yeah. And for this reason, I do think there are no technological limits. I think like what is already happening here, this is like impossible. This is insane. And we've done this in a very limited amount of time. And we're accelerating the rate at which we're doing this. So I think digital consciousness, it's inevitable. And we may not be able to even understand what that means, but I like hurling yourself into the abyss. So we're surrounded by all this mystery and we just keep hurling ourselves into it, like fearlessly and keep discovering cool shit. Yeah. Like, I just think it's like, like who even knows if the laws of physics, the laws of physics are probably just the current, like as I was saying, speed of light is the current render rate. It's like, if we're in a simulation, they'll be able to upgrade that. Like I sort of suspect when we made the James Webb telescope, like part of the reason we made that is because we had an upgrade, you know? And so now more of space has been rendered so we can see more of it now. Yeah, but I think humans are super, super, super limited cognitively. So I wonder if we'll be allowed to create more intelligent beings that can see more of the universe as their render rate is upgraded. Maybe we're cognitively limited. Everyone keeps talking about how we're cognitively limited and AI is gonna render us obsolete, but it's like, you know, like this is not the same thing as like an amoeba becoming an alligator. Like, it's like, if we create AI, again, that's intelligent design. That's literally all religions are based on gods that create consciousness. Like we are God making. Like what we are doing is incredibly profound. And like, even if we can't compute, even if we're so much worse than them, like just like unfathomably worse than like, you know, an omnipotent kind of AI, it's like we, I do not think that they would just think that we are stupid. I think that they would recognize the profundity of what we have accomplished. Are we the gods or are they the gods in our personality? I mean, we're kind of the guy. It's complicated. It's complicated. Like we're. But they would acknowledge the value. Well, I hope they acknowledge the value of paying respect to the creative ancestors. I think they would think it's cool. I think if curiosity is a trait that we can quantify and put into AI, then I think if AI are curious, then they will be curious about us and they will not be hateful or dismissive of us. They might, you know, see us as, I don't know. It's like, I'm not like, oh, fuck these dogs. Let's just kill all the dogs. I love dogs. Dogs have great utility. Dogs like provide a lot of. We make friends with them. We have a deep connection with them. We anthropomorphize them. Like we have a real love for dogs, for cats and so on for some reason, even though they're intellectually much less than us. And I think there is something sacred about us because it's like, if you look at the universe, like the whole universe is like cold and dead and sort of robotic. And it's like, you know, AI intelligence, you know, it's kind of more like the universe. It's like cold and you know, logical and you know, abiding by the laws of physics and whatever. But like, we're this like loosey goosey, weird art thing that happened. And I think it's beautiful. And like, I think even if we, I think one of the values, if consciousness is a thing that is most worth preserving, which I think is the case, I think consciousness, I think if there's any kind of like religious or spiritual thing, it should be that consciousness is sacred. Like, then, you know, I still think even if AI render us obsolete and we, climate change, it's too bad and we get hit by a comet and we don't become a multi planetary species fast enough, but like AI is able to populate the universe. Like I imagine, like if I was an AI, I would find more planets that are capable of hosting biological life forms and like recreate them. Because we're fun to watch. Yeah, we're fun to watch. Yeah, but I do believe that AI can have some of the same magic of consciousness within it. Because consciousness, we don't know what it is. So, you know, there's some kind of. Or it might be a different magic. It might be like a strange, a strange, different. Right. Because they're not gonna have hormones. Like I feel like a lot of our magic is hormonal kind of. I don't know, I think some of our magic is the limitations, the constraints. And within that, the hormones and all that kind of stuff, the finiteness of life, and then we get given our limitations, we get to come up with creative solutions of how to dance around those limitations. We partner up like penguins against the cold. We fall in love, and then love is ultimately some kind of, allows us to delude ourselves that we're not mortal and finite, and that life is not ultimately, you live alone, you're born alone, you die alone. And then love is like for a moment or for a long time, forgetting that. And so we come up with all these creative hacks that make life like fascinatingly fun. Yeah, yeah, yeah, fun, yeah. And then AI might have different kinds of fun. Yes. And hopefully our funs intersect once in a while. I think there would be a little intersection of the fun. Yeah. Yeah. What do you think is the role of love in the human condition? I think. Why, is it useful? Is it useful like a hack, or is this like fundamental to what it means to be human, the capacity to love? I mean, I think love is the evolutionary mechanism that is like beginning the intelligent design. Like I was just reading about, do you know about Kropotkin? He's like an anarchist, like old Russian anarchist. I live next door to Michael Malice. I don't know if you know who that is. He's an anarchist. He's a modern day anarchist. Okay. Anarchists are fun. I'm kind of getting into anarchism a little bit. This is probably not a good route to be taking, but. Oh no, I think if you're, listen, you should expose yourself to ideas. There's no harm to thinking about ideas. I think anarchists challenge systems in interesting ways, and they think in interesting ways. It's just as good for the soul. It's like refreshes your mental palette. I don't think we should actually, I wouldn't actually ascribe to it, but I've never actually gone deep on anarchy as a philosophy, so I'm doing. You should still think about it though. When you read, when you listen, because I'm reading about the Russian Revolution a lot, and there was the Soviets and Lenin and all that, but then there was Kropotkin and his anarchist sect, and they were sort of interesting because he was kind of a technocrat actually. He was like, women can be more equal if we have appliances. He was really into using technology to reduce the amount of work people had to do. But so Kropotkin was a biologist or something. He studied animals. And he was really at the time like, I think it's Nature magazine. I think it might've even started as a Russian magazine, but he was publishing studies. Everyone was really into Darwinism at the time and survival of the fittest, and war is the mechanism by which we become better. And it was this real cementing this idea in society that violence kill the weak, and that's how we become better. And then Kropotkin was kind of interesting because he was looking at instances, he was finding all these instances in nature where animals were like helping each other and stuff. And he was like, actually love is a survival mechanism. Like there's so many instances in the animal kingdom where like cooperation and like helping weaker creatures and all this stuff is actually an evolutionary mechanism. I mean, you even look at child rearing. Like child rearing is like immense amounts of just love and goodwill. And just like, there's no immediate, you're not getting any immediate feedback of like winning. It's not competitive. It's literally, it's like we actually use love as an evolutionary mechanism just as much as we use war. And I think we've like missing the other part and we've reoriented, we've culturally reoriented like science and philosophy has oriented itself around Darwinism a little bit too much. And the Kropotkin model, I think is equally valid. Like it's like cooperation and love and stuff is just as essential for species survival and evolution. It should be a more powerful survival mechanism in the context of evolution. And it comes back to like, we think engineering is so much more important than motherhood, but it's like, if you lose the motherhood, the engineering means nothing. We have no more humans. It's like, I think our society should, the survival of the, the way we see, we conceptualize evolution should really change to also include this idea, I guess. Yeah, there's some weird thing that seems irrational that is also core to what it means to be human. So love is one such thing. They could make you do a lot of irrational things, but that depth of connection and that loyalty is a powerful thing. Are they irrational or are they rational? Like, it's like, is, you know, maybe losing out on some things in order to like keep your family together or in order, like, it's like, what are our actual values? Well, right, I mean, the rational thing is if you have a cold economist perspective, you know, motherhood or sacrificing your career for love, you know, in terms of salary, in terms of economic wellbeing, in terms of flourishing of you as a human being, that could be seen on some kind of metrics as a irrational decision, suboptimal decision, but there's the manifestation of love could be the optimal thing to do. There's a kind of saying, save one life, save the world. That's the thing that doctors often face, which is like. Well, it's considered irrational because the profit model doesn't include social good. Yes, yeah. So if a profit model includes social good, then suddenly these would be rational decisions. Might be difficult to, you know, it requires a shift in our thinking about profit and might be difficult to measure social good. Yes, but we're learning to measure a lot of things. Yeah, digitizing a lot of things. Where we're actually, you know, quantifying vision and stuff. Like we're like, you know, like you go on Facebook and they can, like Facebook can pretty much predict our behaviors. Like we're, a surprising amount of things that seem like mysterious consciousness soul things have been quantified at this point. So surely we can quantify these other things. Yeah. But as more and more of us are moving the digital space, I wanted to ask you about something. From a fan perspective, I kind of, you know, you as a musician, you as an online personality, it seems like you have all these identities and you play with them. One of the cool things about the internet, it seems like you can play with identities. So as we move into the digital world more and more, maybe even in the so called metaverse. I mean, I love the metaverse and I love the idea, but like the way this has all played out didn't go well and people are mad about it. And I think we need to like. I think that's temporary. I think it's temporary. Just like, you know how all the celebrities got together and sang the song Imagine by Jeff Leonard and everyone started hating the song Imagine. I'm hoping that's temporary because it's a damn good song. So I think it's just temporary. Like once you actually have virtual worlds, whatever they're called metaverse or otherwise, it becomes, I don't know. Well, we do have virtual worlds. Like video games, Elden Ring. Have you played Elden Ring? You haven't played Elden Ring? I'm really afraid of playing that game. Literally amazed. It looks way too fun. It looks I would wanna go there and stay there forever. It's yeah, so fun. It's so nice. Oh man, yeah. So that's the, yeah, that's a metaverse. That's a metaverse, but you're not really, how immersive is it in the sense that, does the three dimension like virtual reality integration necessary? Can we really just take our, close our eyes and kind of plug in in the 2D screen and become that other being for time and really enjoy that journey that we take? And we almost become that. You're no longer C, I'm no longer Lex, you're that creature, whatever the hell it is in that game. Yeah, that is that. I mean, that's why I love those video games. I really do become those people for a time. But like, it seems like with the idea of the metaverse, the idea of the digital space, well, even on Twitter, you get a chance to be somebody for prolonged periods of time like across a lifespan. You know, you have a Twitter account for years, for decades and you're that person. I don't know if that's a good thing. I feel very tormented by it. By Twitter specifically. By social media representation of you. I feel like the public perception of me has gotten so distorted that I find it kind of disturbing. It's one of the things that's disincentivizing me from like wanting to keep making art because I'm just like, I've completely lost control of the narrative. And the narrative is, some of it is my own stupidity, but a lot, like some of it has just been like hijacked by forces far beyond my control. I kind of got in over my head in things. Like I'm just a random Indian musician, but I just got like dragged into geopolitical matters and like financial, like the stock market and shit. And so it's just like, it's just, there are very powerful people who have at various points in time had very vested interest in making me seem insane and I can't fucking fight that. And I just like, people really want their celebrity figures to like be consistent and stay the same. And like people have a lot of like emotional investment in certain things. And like, first of all, like I'm like artificially more famous than I should be. Isn't everybody who's famous artificially famous? No, but like I should be like a weird niche indie thing. And I make pretty challenging, I do challenging weird fucking shit a lot. And I accidentally by proxy got like foisted into sort of like weird celebrity culture, but like I cannot be media trained. They have put me through so many hours of media training. I would love to see BF fly in that wall. I can't do, like when I do, I try so hard and I like learn this thing and I like got it. And I'm like, I got it, I got it, I got it. But I just can't stop saying, like my mouth just says things like, and it's just like, and I just do, I just do things. I just do crazy things. Like I'm, I just, I need to do crazy things. And it's just, I should not be, it's too jarring for people and the contradictory stuff. And then all the by association, like, you know, it's like I'm in a very weird position and my public image, the avatar of me is now this totally crazy thing that is so lost from my control. So you feel the burden of the avatar having to be static. So the avatar on Twitter or the avatar on Instagram on these social platforms is as a burden. It becomes like, cause like people don't want to accept a changing avatar, a chaotic avatar. Avatar is a stupid shit sometimes. They think the avatar is morally wrong or they think the avatar, and maybe it has been, and like I question it all the time. Like, I'm like, like, I don't know if everyone's right and I'm wrong. I don't know, like, but you know, a lot of times people ascribe intentions to things, the worst possible intentions. At this point, people think I'm, you know, but which is fine. All kinds of words, yes. Yes, and it's fine. I'm not complaining about it, but I'm just, it's a curiosity to me that we live these double, triple, quadruple lives and I have this other life that is like more people know my other life than my real life, which is interesting. Probably, I mean, you too, I guess, probably. Yeah, but I have the luxury. So we have all different, you know, like I don't know what I'm doing. There is an avatar and you're mediating who you are through that avatar. I have the nice luxury, not the luxury, maybe by intention of not trying really hard to make sure there's no difference between the avatar and the private person. Do you wear a suit all the time? Yeah. You do wear a suit? Not all the time. Recently, because I get recognized a lot, I have to not wear the suit to hide. I'm such an introvert, I'm such a social anxiety and all that kind of stuff, so I have to hide away. I love wearing a suit because it makes me feel like I'm taking the moment seriously. Like I'm, I don't know. It makes me feel like a weirdo in the best possible way. Suits feel great, every time I wear a suit, I'm like, I don't know why I'm not doing this more. Fashion in general, if you're doing it for yourself, I don't know, it's a really awesome thing. But yeah, I think there is definitely a painful way to use social media and an empowering way. And I don't know if any of us know which is which. So we're trying to figure that out. Some people, I think Doja Cat is incredible at it. Incredible, like just masterful. I don't know if you like follow that. So okay, so not taking anything seriously, joking, absurd, humor, that kind of thing. I think Doja Cat might be like the greatest living comedian right now. Like I'm more entertained by Doja Cat than actual comedians. Like she's really fucking funny on the internet. She's just great at social media. It's just, you know. Yeah, the nature of humor, like humor on social media is also a beautiful thing, the absurdity. The absurdity. And memes, like I just wanna like take a moment. I love, like when we're talking about art and credit and authenticity, I love that there's this, I mean now memes are like, they're no longer, like memes aren't like new, but it's still this emergent art form that is completely egoless and anonymous and we just don't know who made any of it. And it's like the forefront of comedy and it's just totally anonymous and it just feels really beautiful. It just feels like this beautiful collective human art project that's like this like decentralized comedy thing that just makes memes add so much to my day and many people's days. And it's just like, I don't know. I don't think people ever, I don't think we stop enough and just appreciate how sick it is that memes exist. Because also making a whole brand new art form in like the modern era that's like didn't exist before. Like, I mean they sort of existed, but the way that they exist now as like this like, you know, like me and my friends, like we joke that we go like mining for memes or farming for memes, like a video game and like meme dealers and like whatever. Like it's, you know, it's this whole, memes are this whole like new comedic language. Well, it's this art form. The interesting thing about it is that lame people seem to not be good at memes. Like corporate can't infiltrate memes. Yeah, they really can't. They try, they could try. But it's like, it's weird cause like. They try so hard and every once in a while, I'm like fine, like you got a good one. I think I've seen like one or two good ones, but like, yeah, they really can't. Cause they're even, corporate is infiltrating web three. It's making me really sad, but they can't infiltrate the memes. And I think there's something really beautiful about that. That gives power, that's why Dogecoin is powerful. It's like, all right, I'm gonna F you to sort of anybody who's trying to centralize, is trying to control the rich people that are trying to roll in and control this, control the narrative. Wow, I hadn't thought about that, but. How would you fix Twitter? How would you fix social media for your own? Like you're an optimist, you're a positive person. There's a bit of a cynicism that you have currently about this particular little slice of humanity. I tend to think Twitter could be beautiful. I'm not that cynical about it. I'm not that cynical about it. I actually refuse to be a cynic on principle. Yes. I was just briefly expressing some personal pathos. Personal stuff. It was just some personal pathos, but like, like. Just to vent a little bit, just to speak. I don't have cancer, I love my family. I have a good life. That is, if that is my biggest, one of my biggest problems. Then it's a good life. Yeah, you know, that was a brief, although I do think there are a lot of issues with Twitter just in terms of like the public mental health, but due to my proximity to the current dramas, I honestly feel that I should not have opinions about this because I think that if Elon ends up getting Twitter, that is a, being the arbiter of truth or public discussion, that is a responsibility. I do not, I am not qualified to be responsible for that. And I do not want to say something that might like dismantle democracy. And so I just like, actually, I actually think I should not have opinions about this because I truly am not, I don't want to have the wrong opinion about this. And I think I'm too close to the actual situation wherein I should not have, I have thoughts in my brain, but I think I am scared by my proximity to this situation. Isn't that crazy that a few words that you could say could change world affairs and hurt people? I mean, that's the nature of celebrity at a certain point that you have to be, you have to a little bit, a little bit, not so much that it destroys you or puts too much constraints, but you have to a little bit think about the impact of your words. I mean, we as humans, you talk to somebody at a bar, you have to think about the impact of your words. Like you can say positive things, you can say negative things, you can affect the direction of one life. But on social media, your words can affect the direction of many lives. That's crazy. It's a crazy world to live in. It's worthwhile to consider that responsibility, take it seriously. Sometimes just like you did choose kind of silence, choose sort of respectful. Like I do have a lot of thoughts on the matter. I'm just, I don't, if my thoughts are wrong, this is one situation where the stakes are high. You mentioned a while back that you were in a cult that's centered around bureaucracy, so you can't really do anything because it involves a lot of paperwork. And I really love a cult that's just like Kafkaesque. Yes. Just like. I mean, it was like a joke, but it was. I know, but I love this idea. The Holy Rain Empire. Yeah, it was just like a Kafkaesque pro bureaucracy cult. But I feel like that's what human civilization is, is that, because when you said that, I was like, oh, that is kind of what humanity is, is this bureaucracy cult. I do, yeah, I have this theory. I really think that we really, bureaucracy is starting to kill us. And I think like we need to reorient laws and stuff. Like, I think we just need sunset clauses on everything. Like, I think the rate of change in culture is happening so fast and the rate of change in technology and everything is happening so fast. It's like, when you see these hearings about like social media and Cambridge Analytica and everyone talking, it's like, even from that point, so much technological change has happened from like those hearings. And it's just like, we're trying to make all these laws now about AI and stuff. I feel like we should be updating things like every five years. And like one of the big issues in our society right now is we're just getting bogged down by laws and it's making it very hard to change things and develop things. In Austin, I don't wanna speak on this too much, but like one of my friends is working on a housing bill in Austin to try to like prevent like a San Francisco situation from happening here because obviously we're getting a little mini San Francisco here, like housing prices are skyrocketing, it's causing massive gentrification. This is really bad for anyone who's not super rich. Like, there's so much bureaucracy. Part of the reason this is happening is because you need all these permits to build. It takes like years to get permits to like build anything. It's so hard to build and so there's very limited housing and there's a massive influx of people. And it's just like, you know, this is a microcosm of like problems that are happening all over the world where it's just like, we're dealing with laws that are like 10, 20, 30, 40, 100, 200 years old and they are no longer relevant and it's just slowing everything down and causing massive social pain. Yeah, but it's like, it's also makes me sad when I see politicians talk about technology and when they don't really get it. But most importantly, they lack curiosity and like that like inspired excitement about like how stuff works and all that stuff. They're just like, they see, they have a very cynical view of technology. It's like tech companies are just trying to do evil on the world from their perspective and they have no curiosity about like how recommender systems work or how AI systems work, natural language processing, how robotics works, how computer vision works, you know. They always take the most cynical possible interpretation of what technology would be used and we should definitely be concerned about that but if you're constantly worried about that and you're regulating based on that, you're just going to slow down all the innovation. I do think a huge priority right now is undoing the bad energy surrounding the emergence of Silicon Valley. Like I think that like a lot of things were very irresponsible during that time and you know, like even just this current whole thing with Twitter and everything, it's like there has been a lot of negative outcomes from the sort of technocracy boom but one of the things that's happening is that like it's alienating people from wanting to care about technology and I actually think technology is probably some of the better, probably the best. I think we can fix a lot of our problems more easily with technology than with you know, fighting the powers that be as a you know, not to go back to the Star Wars quote or the Buckminster Fuller quote. Let's go to some dark questions. If we may for time, what is the darkest place you've ever gone in your mind? Is there a time, a period of time, a moment that you remember that was difficult for you? I mean, when I was 18, my best friend died of a heroin overdose and it was like my, and then shortly after that, one of my other best friends committed suicide and that sort of like coming into adulthood, dealing with two of the most important people in my life dying in extremely disturbing violent ways was a lot. That was a lot. Do you miss them? Yeah, definitely miss them. Did that make you think about your own life? About the finiteness of your own life? The places your mind can go? Did you ever in the distance, far away contemplate just your own death? Or maybe even taking your own life? Oh never, oh no. I'm so, I love my life. I cannot fathom suicide. I'm so scared of death. I haven't, I'm too scared of death. My manager, my manager's like the most Zen guy. My manager's always like, you need to accept death. You need to accept death. And I'm like, look, I can do your meditation. I can do the meditation, but I cannot accept death. I like, I will fight, I'm terrified of death. I will like fight. Although I actually think death is important. I recently went to this meeting about immortality and in the process of. That's the actual topic of the meeting? I'm sorry. No, no, it was this girl. It was a bunch of people working on like anti aging stuff. It was like some like seminary thing about it. And I went in really excited. I was like, yeah, like, okay, like, what do you got? Like, how can I live for 500 years or a thousand years? And then like over the course of the meeting, like it was sort of like, right. It was like two or three days after the Russian invasion started. And I was like, man, like, what if Putin was immortal? Like, what if I'm like, man, maybe immortality, is not good. I mean, like if you get into the later Dune stuff, the immortals cause a lot of problem. Cause as we were talking about earlier with the music and like brains calcify, like good people could become immortal, but bad people could become immortal. But I also think even the best people power corrupts and power alienates you from like the common human experience and. Right, so the people that get more and more powerful. Even the best people who like, whose brains are amazing, like I think death might be important. I think death is part of, you know, like I think with AI one thing we might want to consider, I don't know, when I talk about AI, I'm such not an expert and probably everyone has all these ideas and they're already figured out. But when I was talking. Nobody is an expert in anything. See, okay, go ahead. But when I. You were talking about. Yeah, but I like, it's just like, I think some kind of pruning. But it's a tricky thing because if there's too much of a focus on youth culture, then you don't have the wisdom. So I feel like we're in a tricky, we're in a tricky moment right now in society where it's like, we've really perfected living for a long time. So there's all these really like old people who are like really voting against the wellbeing of the young people, you know? And like, it's like there shouldn't be all this student dead and we need like healthcare, like universal healthcare and like just voting against like best interests. But then you have all these young people that don't have the wisdom that are like, yeah, we need communism and stuff. And it's just like, like literally I got canceled at one point for, I ironically used a Stalin quote in my high school yearbook, but it was actually like a diss against my high school. I saw that. Yeah, and people were like, you used to be a Stalinist and now you're a class traitor and it's like, it's like, oh man, just like, please Google Stalin. Please Google Stalin. Like, you know. Ignoring the lessons of history, yes. And it's like, we're in this really weird middle ground where it's like, we are not finding the happy medium between wisdom and fresh ideas and they're fighting each other. And it's like, like really, like what we need is like the fresh ideas and the wisdom to be like collaborating. And it's like. What the fighting in a way is the searching for the happy medium. And in a way, maybe we are finding the happy medium. Maybe that's what the happy medium looks like. And for AI systems, there has to be, it's, you know, you have the reinforcement learning, you have the dance between exploration and exploitation, sort of doing crazy stuff to see if there's something better than what you think is the optimal and then doing the optimal thing and dancing back and forth from that. You would, Stuart Russell, I don't know if you know that, is AI guy with, thinks about sort of how to control super intelligent AI systems. And his idea is that we should inject uncertainty and sort of humility into AI systems that they never, as they get wiser and wiser and wiser and more intelligent, they're never really sure. They always doubt themselves. And in some sense, when you think of young people, that's a mechanism for doubt. It's like, it's how society doubts whether the thing it has converged towards is the right answer. So the voices of the young people is a society asking itself a question. The way I've been doing stuff for the past 50 years, maybe it's the wrong way. And so you can have all of that within one AI system. I also think, though, that we need to, I mean, actually, that's actually really interesting and really cool. But I also think there's a fine balance of, I think we maybe also overvalue the idea that the old systems are always bad. And I think there are things that we are perfecting and we might be accidentally overthrowing things that we actually have gotten to a good point. Just because we value disruption so much and we value fighting against the generations before us so much that there's also an aspect of, sometimes we're taking two steps forward, one step back because, okay, maybe we kind of did solve this thing and now we're like fucking it up, you know? And so I think there's like a middle ground there too. Yeah, we're in search of that happy medium. Let me ask you a bunch of crazy questions, okay? All right. You can answer in a short way or in a long way. What's the scariest thing you've ever done? These questions are gonna be ridiculous. Something tiny or something big. Something big, skydiving or touring your first record, going on this podcast. I've had two crazy brushes, like really scary brushes with death where I randomly got away on scay. I don't know if I should talk about those on here. Well, I don't know. I think I might be the luckiest person alive though. Like this might be too dark for a podcast though. I feel like, I don't know if this is like good content for a podcast. I don't know what is good content. It might hijack. Here's a safer one. I mean, having a baby really scared me. Before. Just the birth process. Surgery, like just having a baby is really scary. So just like the medical aspect of it, not the responsibility. Were you ready for the responsibility? Did you, were you ready to be a mother? All the beautiful things that comes with motherhood that you were talking about. All the changes and all that, were you ready for that? Or did you feel ready for that? No, I think it took about nine months to start getting ready for it. And I'm still getting more ready for it because now you keep realizing more things as they start getting. As the consciousness grows. And stuff you didn't notice with the first one, now that you've seen the first one older, you're noticing it more. Like the sort of like existential horror of coming into consciousness with Baby Y or Baby Sailor Mars or whatever. She has like so many names at this point that it's, we really need to probably settle on one. If you could be someone else for a day, someone alive today, but somebody you haven't met yet, who would you be? Would I be modeling their brain state or would I just be in their body? You can choose the degree to which you're modeling their brain state. Cause you can still take a third person perspective and realize, you have to realize that you're. Can they be alive or can it be dead? No, oh. They would be brought back to life, right? If they're dead. Yeah, you can bring people back. Definitely Hitler or Stalin. I wanna understand evil. You would need to, oh, to experience what it feels like. I wanna be in their brain feeling what they feel. I might change you forever returning from that. Yes, but I think it would also help me understand how to prevent it and fix it. That might be one of those things, once you experience it, it'll be a burden to know it. Cause you won't be able to transfer that. Yeah, but a lot of things are burdens. But it's a useful burden. But it's a useful burden, yeah. That for sure, I wanna understand evil and psychopathy and that. I have all these fake Twitter accounts where I go into different algorithmic bubbles to try to understand. I'll keep getting in fights with people and realize we're not actually fighting. I think we used to exist in a monoculture before social media and stuff. We kinda all got fed the same thing. So we were all speaking the same cultural language. But I think recently, one of the things that we aren't diagnosing properly enough with social media is that there's different dialects. There's so many different dialects of Chinese. There are now becoming different dialects of English. I am realizing there are people who are saying the exact same things, but they're using completely different verbiage. And we're punishing each other for not using the correct verbiage. And we're completely misunderstanding. People are just misunderstanding what the other people are saying. And I just got in a fight with a friend about anarchism and communism and shit for two hours. And then by the end of a conversation, and then she'd say something, and I'm like, but that's literally what I'm saying. And she was like, what? And then I was like, fuck, we've different, I'm like, our English, the way we are understanding terminology is like drastically, like our algorithm bubbles are creating mini dialects. Of how language is interpreted, how language is used. That's so fascinating. And so we're like having these arguments that we do not need to be having. And there's polarization that's happening that doesn't need to be happening because we've got these like algorithmically created dialects occurring. Plus on top of that, there's also different parts of the world that speak different languages. So there's literally lost in translation kind of communication. I happen to know the Russian language and just know how different it is. Then the English language. And I just wonder how much is lost in a little bit of. Man, I actually, cause I have a question for you. I have a song coming out tomorrow with I Speak Who Are A Russian Band. And I speak a little bit of Russian and I was looking at the title and the title in English doesn't match the title in Russian. I'm curious about this. Cause look, it says the title in English is Last Day. And then the title in Russian is New Day. My pronunciation sucks. New Day. Like what? Like a new day. A new day. Yeah, new day, new day. Like it's two different meanings. Yeah, new day, yeah. Yeah, yeah, new day. New day, but last day. New day. So last day would be the last day. Yeah. Maybe they. Or maybe the title includes both the Russian and it's for. Maybe. Maybe it's for bilingual. But to be honest, Novodin sounds better than just musically. Like Novodin is new day. That's the current one. And Posledniy Den is the last day. I think Novodin. I don't like Novodin. But the meaning is so different. That's kind of awesome actually though. There's an explicit sort of contrast like that. If everyone on earth disappeared and it was just you left, what would your day look like? Like what would you do? Everybody's dead. As far as you. Are there corpses there? Well seriously, it's a big. Let me think through this. It's a big difference if there's just like birds singing versus if there's like corpses littering the street. Yeah, there's corpses everywhere, I'm sorry. It's, and you don't actually know what happened and you don't know why you survived. And you don't even know if there's others out there. But it seems clear that it's all gone. What would you do? What would I do? Listen, I'm somebody who really enjoys the moment, enjoys life. I would just go on like enjoying the inanimate objects. I would just look for food, basic survival. But most of it is just, listen, when I just, I take walks and I look outside and I'm just happy that we get to exist on this planet, to be able to breathe air. It's just all beautiful. It's full of colors, all of this kind of stuff. Just, there's so many things about life, your own life, conscious life that's fucking awesome. So I would just enjoy that. But also maybe after a few weeks, the engineer would start coming out, like wanna build some things. Maybe there's always hope searching for another human. Maybe. Probably searching for another human. Probably trying to get to a TV or radio station and broadcast something. That's interesting, I didn't think about that. So like really maximize your ability to connect with others. Yeah, like probably try to find another person. Would you be excited to see, to meet another person or terrified? Because, you know. I'd be excited. No matter what. Yeah, yeah, yeah, yeah. Being alone for the last however long of my life would be really bad. That's the one instance I might, I don't think I'd kill myself, but I might kill myself if I had to. So you love people. You love connection to other humans. Yeah. I kinda hate people too, but yeah. That's a love hate relationship. Yeah. I feel like we'd have a bunch of weird Nietzsche questions and stuff though. Oh yeah. Like I wonder, cause I'm like, when podcast, I'm like, is this interesting for people to just have like, or I don't know, maybe people do like this. When I listen to podcasts, I'm into like the lore, like the hard lore. Like I just love like Dan Carlin. I'm like, give me the facts. Just like, like the facts into my bloodstream. But you also don't know, like you're a fascinating mind to explore. So you don't realize as you're talking about stuff, the stuff you've taken for granted is actually unique and fascinating. The way you think. Not always what, like the way you reason through things is the fascinating thing to listen to. Because people kind of see, oh, there's other humans that think differently, that explore thoughts differently. That's the cool, that's also cool. So yeah, Dan Carlin retelling of history. By the way, his retelling of history is very, I think what's exciting is not the history, is his way of thinking about history. No, I think Dan Carlin is one of the people, like when, Dan Carlin is one of the people that really started getting me excited about like revolutionizing education. Because like Dan Carlin instilled, I already like really liked history, but he instilled like an obsessive love of history in me to the point where like now I'm fucking reading, like going to bed, reading like part four of The Rise and Fall of the Third Reich or whatever. Like I got like dense ass history, but like he like opened that door that like made me want to be a scholar of that topic. Like it's like, I feel like he's such a good teacher. He just like, you know, and it sort of made me feel like one of the things we could do with education is like find like the world's great, the teachers that like create passion for the topic because autodidactricism, I don't know how to say that properly, but like self teaching is like much faster than being lectured to. Like it's much more efficient to sort of like be able to teach yourself and then ask a teacher questions when you don't know what's up. But like, you know, that's why it's like in university and stuff, like you can learn so much more material so much faster because you're doing a lot of the learning on your own and you're going to the teachers for when you get stuck. But like these teachers that can inspire passion for a topic, I think that is one of the most invaluable skills in our whole species. Like, because if you can do that, then you, it's like AI, like AI is going to teach itself so much more efficiently than we can teach it. We just needed to get it to the point where it can teach itself. And then. It finds the motivation to do so, right? Yeah. So like you inspire it to do so. Yeah. And then it could teach itself. What do you make of the fact, you mentioned Rise and Fall of the Third Reich. I just. Have you read that? Yeah, I read it twice. You read it twice? Yes. Okay, so no one even knows what it is. Yeah. And I'm like, wait, I thought this was like a super poppin book. Super pop. Yeah, I'm not like that, I'm not that far in it. But it is, it's so interesting. Yeah, it's written by a person that was there, which is very important to kind of. You know, you start being like, how could this possibly happen? And then when you read Rise and Fall of the Third Reich, it's like, people tried really hard for this to not happen. People tried, they almost reinstated a monarchy at one point to try to stop this from happening. Like they almost like abandoned democracy to try to get this to not happen. At least the way it makes me feel is that there's a bunch of small moments on which history can turn. Yes. It's like small meetings. Yes. Human interactions. And it's both terrifying and inspiring because it's like, even just attempts at assassinating Hitler, like time and time again failed. And they were so close. Was it like Operation Valkyrie? Such a good. And then there's also the role of, that's a really heavy burden, which is from a geopolitical perspective, the role of leaders to see evil before it truly becomes evil, to anticipate it, to stand up to evil. Because evil is actually pretty rare in this world at a scale that Hitler was. We tend to, you know, in the modern discourse kind of call people evil too quickly. If you look at ancient history, like there was a ton of Hitlers. I actually think it's more the norm than, like again, going back to like my sort of intelligent design theory, I think one of the things we've been successfully doing in our slow move from survival of the fittest to intelligent design is we've kind of been eradicating, like if you look at like ancient Assyria and stuff, like that shit was like brutal and just like the heads on the, like brutal, like Genghis Khan just like genocide after genocide was like throwing plague bodies over the walls and decimating whole cities or like the Muslim conquests of like Damascus and shit. Just like people, cities used to get leveled all the fucking time. Okay, get into the Bronze Age collapse. It's basically, there was like almost like Roman level like society. Like there was like all over the world, like global trade, like everything was awesome through a mix of, I think a bit of climate change and then the development of iron because basically bronze could only come from this, the way to make bronze, like everything had to be funneled through this one Iranian mine. And so it's like, there was just this one supply chain and this is one of the things that makes me worried about supply chains and why I think we need to be so thoughtful about, I think our biggest issue with society right now, like the thing that is most likely to go wrong is probably supply chain collapse, because war, climate change, whatever, like anything that causes supply chain collapse, our population is too big to handle that. And like the thing that seems to cause Dark Ages is mass supply chain collapse. But the Bronze Age collapse happened like, it was sort of like this ancient collapse that happened where like literally like ancient Egypt, all these cities, everything just got like decimated, destroyed, abandoned cities, like hundreds of them. There was like a flourishing society, like we were almost coming to modernity and everything got leveled. And they had this mini Dark Ages, but it was just like, there's so little writing or recording from that time that like, there isn't a lot of information about the Bronze Age collapse, but it was basically equivalent to like medieval, the medieval Dark Ages. But it just happened, I don't know the years, but like thousands of years earlier. And then we sort of like recovered from the Bronze Age collapse, empire reemerged, writing and trade and everything reemerged. And then we of course had the more contemporary Dark Ages. And then over time, we've designed mechanism to lessen and lessen the capability for the destructive power centers to emerge. There's more recording about the more contemporary Dark Ages. So I think we have like a better understanding of how to avoid it, but I still think we're at high risk for it. I think that's one of the big risks right now. So the natural state of being for humans is for there to be a lot of Hitlers, which has gotten really good at making it hard for them to emerge. We've gotten better at collaboration and resisting the power, like authoritarians to come to power. We're trying to go country by country, like we're moving past this. We're kind of like slowly incrementally, like moving towards like not scary old school war stuff. And I think seeing it happen in some of the countries that at least nominally are like supposed to have moved past that, that's scary because it reminds us that it can happen like in the places that have moved supposedly, as hopefully moved past that. And possibly at a civilization level, like you said, supply chain collapse might make people resource constraint, might make people desperate, angry, hateful, violent, and drag us right back in. I mean, supply chain collapse is how, like the ultimate thing that caused the Middle Ages was supply chain collapse. It's like people, because people were reliant on a certain level of technology, like people, like you look at like Britain, like they had glass, like people had aqueducts, people had like indoor heating and cooling and like running water and like buy food from all over the world and trade and markets. Like people didn't know how to hunt and forage and gather. And so we're in a similar situation. We are not educated enough to survive without technology. So if we have a supply chain collapse that like limits our access to technology, there will be like massive starvation and violence and displacement and war. Like, you know, it's like, yeah. In my opinion, it's like the primary marker of like what a dark age is. Well, technology is kind of enabling us to be more resilient in terms of supply chain, in terms of, to all the different catastrophic events that happened to us. Although the pandemic has kind of challenged our preparedness for the catastrophic. What do you think is the coolest invention humans come up with? The wheel, fire, cooking meat. Computers. Computers. Freaking computers. Internet or computers? Which one? What do you think the? Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo tech now. I think this is what, it's a brain augmentation. And so it like allows for actual evolution. Like the computers accelerate the degree to which all the other technologies can also be accelerated. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. So you're one of the earliest of the species. I think most of us are. Like, as I said, like, I think if you like looked at brain scans of us versus humans a hundred years ago, it would look very different. I think we are physiologically different. Just even the interaction with the devices has changed our brains. Well, and if you look at, a lot of studies are coming out to show that like, there's a degree of inherited memory. So some of these physiological changes in theory should be, we should be passing them on. So like that's, you know, that's not like a, an instance of physiological change that's gonna fizzle out. In theory, that should progress like to our offspring. Speaking of offspring, what advice would you give to a young person, like in high school, whether there be an artist, a creative, an engineer, any kind of career path, or maybe just life in general, how they can live a life they can be proud of? I think one of my big thoughts, and like, especially now having kids, is that I don't think we spend enough time teaching creativity. And I think creativity is a muscle like other things. And there's a lot of emphasis on, you know, learn how to play the piano. And then you can write a song or like learn the technical stuff. And then you can do a thing. But I think it's, like, I have a friend who's like world's greatest guitar player, like, you know, amazing sort of like producer, works with other people, but he's really sort of like, you know, he like engineers and records things and like does solos, but he doesn't really like make his own music. And I was talking to him and I was like, dude, you're so talented at music. Like, why don't you make music or whatever? And he was like, cause I got, I'm too old. I never learned the creative muscle. And it's like, you know, it's embarrassing. It's like learning the creative muscle takes a lot of failure. And it also sort of, if when you're being creative, you know, you're throwing paint at a wall and a lot of stuff will fail. So like part of it is like a tolerance for failure and humiliation. And that's somehow that's easier to develop when you're young or be persist through it when you're young. Everything is easier to develop when you're young. Yes. And the younger, the better. It could destroy you. I mean, that's the shitty thing about creativity. If, you know, failure could destroy you if you're not careful, but that's a risk worth taking. But also, but at a young age, developing a tolerance to failure is good. I fail all the time. Like I do stupid shit all the time. Like in public, in private, I get canceled for, I've make all kinds of mistakes, but I just like am very resilient about making mistakes. And so then like I do a lot of things that like other people wouldn't do. And like, I think my greatest asset is my creativity. And I like, I think pain, like tolerance to failure is just a super essential thing that should be taught before other things. Brilliant advice. Yeah, yeah. I wish everybody encouraged sort of failure more as opposed to kind of. Cause we like punish failure. We're like, no, like when we were teaching kids, we're like, no, that's wrong. Like that's, you know, like X keeps like will be like wrong. at the, because I, you know, when I met him, I came in all furious about Spotify and like I grilled him super hard. So I've got his answers here. But he was saying like at the sort of peak of the CD industry, there was like 20,000 artists making millions and millions of dollars. Like there was just like a very tiny kind of 1%. And Spotify has kind of democratized the industry because now I think he said there's about a million artists making a good living from Spotify. And when I heard that, I was like, honestly, I would rather make less money and have just like a decent living and have more artists be able to have that, even though I like, I wish it could include everyone, but. Yeah, that's really hard to argue with. YouTube is the same. It's YouTube's mission. They want to basically have as many creators as possible and make a living, some kind of living. And that's so hard to argue with. It's so hard. But I think there's better ways to do it. My manager, I actually wish he was here. Like I would have brought him up. My manager is building an app that can manage you. So it'll like help you organize your percentages and get your publishing and dah, dah, dah, dah, dah. So you can take out all the middlemen so you can have a much bigger, it'll just like automate it. So you can get. So automate the manager? Automate management, publishing, and legal, it can read, the app he's building can read your contract and like tell you about it. Because one of the issues with music right now, it's not that we're not getting paid enough, but it's that the art industry is filled with middlemen because artists are not good at business. And from the beginning, like Frank Sinatra, it's all mob stuff. Like it's the music industry is run by business people, not the artists and the artists really get very small cuts of like what they make. And so I think part of the reason I'm a technocrat, which I mean, your fans are gonna be technocrats. So no one's, they're not gonna be mad at me about this, but like my fans hate it when I say this kind of thing or the general public. They don't like technocrats. They don't like technocrats. Like when I watched Battle Angel Alita and they were like the Martian technocracy and I was like, yeah, Martian technocracy. And then they were like, and they're evil. And I was like, oh, okay. I was like, cause Martian technocracy sounds sick to me. Yeah, so your intuition as technocrats would create some kind of beautiful world. For example, what my manager's working on, if you can create an app that removes the need for a lawyer and then you could have smart contracts on the blockchain, removes the need for like management and organizing all this stuff, like can read your stuff and explain it to you, can collect your royalties, you know, like then the small amounts, the amount of money that you're getting from Spotify actually means a lot more and goes a lot farther. It can remove some of the bureaucracy, some of the inefficiencies that make life not as great as it could be. Yeah, I think the issue isn't that there's not enough. Like the issue is that there's inefficiency and I'm really into this positive sum mindset, you know, the win, win mindset of like, instead of, you know, fighting over the scraps, how do we make the, or worrying about scarcity, like instead of a scarcity mindset, why don't we just increase the efficiency and, you know, in that way. Expand the size of the pie. Let me ask you about experimentation. So you said, which is beautiful, being a musician is like having a conversation with all those that came before you. How much of creating music is like kind of having that conversation, trying to fit into the cultural trends and how much of it is like trying to, as much as possible, be an outsider and come up with something totally new. It's like when you're thinking, when you're experimenting, are you trying to be totally different, totally weird? Are you trying to fit in? Man, this is so hard because I feel like I'm kind of in the process of semi retiring from music, so this is like my old brain. Yeah, bring it from like the shelf, put it on the table for a couple minutes, we'll just poke it. I think it's a bit of both because I think forcing yourself to engage with new music is really great for neuroplasticity. Like I think, you know, as people, part of the reason music is marketed at young people is because young people are very neuroplastic. So like if you're 16 to like 23 or whatever, it's gonna be really easy for you to love new music. And if you're older than that, it gets harder and harder and harder. And I think one of the beautiful things about being a musician is I just constantly force myself to listen to new music and I think it keeps my brain really plastic. And I think this is a really good exercise. I just think everyone should do this. You listen to new music and you hate it, I think you should just keep, force yourself to like, okay, well why do people like it? And like, you know, make your brain form new neural pathways and be more open to change. That's really brilliant actually. Sorry to interrupt, but like that exercise is really amazing to sort of embrace change, embrace sort of practice neuroplasticity. Because like that's one of the things, you fall in love with a certain band and you just kind of stay with that for the rest of your life and then you never understand the modern music. That's a really good exercise. Most of the streaming on Spotify is like classic rock and stuff. Like new music makes up a very small chunk of what is played on Spotify. And I think this is like not a good sign for us as a species. I think, yeah. So it's a good measure of the species open mindedness to change is how often you listen to new music. The brain, let's put the music brain back on the shelf. I gotta pull out the futurist brain for a second. In what wild ways do you think the future, say in like 30 years, maybe 50 years, maybe a hundred years will be different from our current way of life on earth? We can talk about augmented reality, virtual reality, maybe robots, maybe space travel, maybe video games, maybe genetic engineering. I can keep going. Cyborgs, aliens, world wars, maybe destructive nuclear wars, good and bad. When you think about the future, what are you imagining? What's the weirdest and the wildest it could be? Have you read Surface Detail by Iain Banks? Surface Detail is my favorite depiction of a, oh wow, you have to read this book. It's literally the greatest science fiction book possibly ever written. Iain Banks is the man, yeah, for sure. What have you read? Just the Player of Games. I read that titles can't be copyrighted so you can just steal them. And I was like, Player of Games, sick. Nice. Yeah, so you can name your album. Like I always wanted to. Romeo and Juliet or something. I always wanted to name an album War and Peace. Nice. Like that would be, like you. That is a good, that's a good, where have I heard that before? You can do that, like you could do that. Also things that are in the public domain. For people who have no clue, you do have a song called Player of Games. Yes, oh yeah. So Iain Banks, Surface Detail is in my opinion the best future that I've ever read about or heard about in science fiction. Basically there's the relationship with super intelligence, like artificial super intelligence is just, it's like great. I want to credit the person who coined this term because I love this term. And I feel like young women don't get enough credit in. Yeah, so if you go to Protopia Futures on Instagram, what is her name? Personalized donor experience at scale, our AI power donor experience. Monica Bealskite, I'm saying that wrong. And I'm probably gonna, I'm probably butchering this a bit, but Protopia is sort of, if utopia is unattainable, Protopia is sort of like, you know. Wow, that's an awesome Instagram, Protopia Futures. A great, a future that is, you know, as good as we can get. The future, positive future. AI, is this a centralized AI in Surface Detail or is it distributed? What kind of AI is it? They mostly exist as giant super ships, like sort of like the guild ships in Dune. Like they're these giant ships that kind of move people around and the ships are sentient and they can talk to all the passengers. And I mean, there's a lot of different types of AI in the Banksyan future, but in the opening scene of Surface Detail, there's this place called the Culture and the Culture is basically a Protopian future. And a Protopian future, I think, is like a future that is like, obviously it's not utopia, it's not perfect. And like, cause like striving for utopia, I think feels hopeless and it's sort of like, maybe not the best terminology to be using. So it's like, it's a pretty good place. Like mostly like, you know, super intelligence and biological beings exist fairly in harmony. There's not too much war. There's like as close to equality as you can get, you know, it's like approximately a good future. Like there's really awesome stuff. It's, and in the opening scene, this girl, she's born as a sex slave outside of the culture. So she's in a society that doesn't adhere to the cultural values. She tries to kill the guy who is her like master, but he kills her, but unbeknownst to her, when she was traveling on a ship through the culture Like he'll say like crazy things. Like X keeps being like, like bubble car, bubble car. And I'm like, and you know, I'm like, what's a bubble car? Like, but like, it doesn't like, but I don't want to be like, no, you're wrong. I'm like, you're thinking of weird, crazy shit. Like, I don't know what a bubble car is, but like. It's creating worlds and they might be internally consistent. And through that, you might discover something fundamental about this world. Yeah, or he'll like rewrite songs, like with words that he prefers. So like, instead of baby shark, he says baby car. It's like. Maybe he's onto something. Let me ask the big, ridiculous question. We were kind of dancing around it, but what do you think is the meaning of this whole thing we have here of human civilization, of life on earth, but in general, just life? What's the meaning of life? C. Have you, did you read Nova Scene yet? By James Lovelock? You're doing a lot of really good book recommendations here. I haven't even finished this, so I'm a huge fraud yet again. But like really early in the book, he says this amazing thing. Like, I feel like everyone's so sad and cynical. Like everyone's like the Fermi paradox and everyone. I just keep hearing people being like, fuck, what if we're alone? Like, oh no, ah, like, ah, ah. And I'm like, okay, but like, wait, what if this is the beginning? Like in Nova Scene, he says, this is not gonna be a correct, I can't like memorize quotes, but he says something like, what if our consciousness, like right now, like this is the universe waking up? Like what if instead of discovering the universe, this is the universe, like this is the evolution of the literal universe herself. Like we are not separate from the universe. Like this is the universe waking up. This is the universe seeing herself for the first time. Like this is. The universe becoming conscious. The first time we were a part of that. Yeah, cause it's like, we aren't separate from the universe. Like this could be like an incredibly sacred moment and maybe like social media and all this things, the stuff where we're all getting connected together. Like maybe these are the neurons connecting of the like collective super intelligence that is, Waking up. The, yeah, like, you know, it's like, maybe instead of something cynical or maybe if there's something to discover, like maybe this is just, you know, we're a blast assist of like some incredible kind of consciousness or being. And just like in the first three years of life or for human children, we'll forget about all the suffering that we're going through now. I think we'll probably forget about this. I mean, probably, you know, artificial intelligence will eventually render us obsolete. I don't think they'll do it in a malicious way, but I think probably we are very weak. The sun is expanding. Like, I don't know, like, hopefully we can get to Mars, but like, we're pretty vulnerable. And I, you know, like, I think we can coexist for a long time with AI and we can also probably make ourselves less vulnerable, but, you know, I just think consciousness, sentience, self awareness, like, I think this might be the single greatest like moment in evolution ever. And like, maybe this is, you know, the big, like the true beginning of life. And we're just, we're the blue green algae or we're like the single celled organisms of something amazing. The universe awakens and this is it. Yeah. Well, see, you're an incredible person. You're a fascinating mind. You should definitely do, your friend Liv mentioned that you guys were thinking of maybe talking. I would love it if you explored your mind in this kind of media more and more by doing a podcast with her or just in any kind of way. So you're an awesome person. It's an honor to know you. It's an honor to get to sit down with you late at night, which is like surreal. And I really enjoyed it. Thank you for talking today. Yeah, no, I mean, huge honor. I feel very underqualified to be here, but I'm a big fan. I've been listening to the podcast a lot and yeah, me and Liv would appreciate any advice and help and we're definitely gonna do that. So yeah. Anytime. Thank you. Cool, thank you. Thanks for listening to this conversation with Grimes. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Oscar Wilde. Yes, I'm a dreamer. For a dreamer is one who can only find her way by moonlight and her punishment is that she sees the dawn before the rest of the world. Thank you for listening and hope to see you next time. with him one day, a ship put a neural lace in her head and neural lace is sort of like, it's basically a Neuralink because life imitates art. It does indeed. It does indeed. So she wakes up and the opening scene is her memory has been uploaded by this neural lace when she has been killed. And now she gets to choose a new body. And this AI is interfacing with her recorded memory in her neural lace and helping her and being like, hello, you're dead. But because you had a neural lace, your memory's uploaded. Do you want to choose a new body? And you're going to be born here in the culture and like start a new life, which is just, that's like the opening. It's like so sick. And the ship is the super intelligence. All the ships are kind of super intelligence. But they still want to preserve a kind of rich, fulfilling experience for the humans. Yeah, like they're like friends with the humans. And then there's a bunch of ships that don't want to exist with biological beings, but they just have their own place like way over there. But they don't, they just do their own thing. They're not necessarily. So it's a pretty, this protopian existence is pretty peaceful. Yeah, I mean, and then, for example, one of the main fights in the book is they're fighting, there's these artificial hells that, and people don't think it's ethical to have artificial hell. Like basically when people do crime, they get sent, like when they die, their memory gets sent to an artificial hell and they're eternally tortured. And so, and then the way that society is deciding whether or not to have the artificial hell is that they're having these simulated, they're having like a simulated war. So instead of actual blood, you know, people are basically essentially fighting in a video game to choose the outcome of this. But they're still experiencing the suffering in this artificial hell or no? Can you experience stuff or? So the artificial hell sucks. And a lot of people in the culture want to get rid of the artificial hell. There's a simulated wars, are they happening in the artificial hell? So no, the simulated wars are happening outside of the artificial hell, between the political factions who are, so this political faction says we should have simulated hell to deter crime. And this political faction is saying, no, simulated hell is unethical. And so instead of like having, you know, blowing each other up with nukes, they're having like a giant Fortnite battle to decide this, which, you know, to me that's protopia. That's like, okay, we can have war without death. You know, I don't think there should be simulated hells. I think that is definitely one of the ways in which technology could go very, very, very, very wrong. So almost punishing people in a digital space or something like that. Yeah, like torturing people's memories. So either as a deterrent, like if you committed a crime, but also just for personal pleasure, if there's some sick, demented humans in this world. Dan Carlin actually has this episode of Hardcore History on painful attainment. Oh, that episode is fucked. It's dark, because he kind of goes through human history and says like, we as humans seem to enjoy, secretly enjoy or used to be openly enjoy sort of the torture and the death, watching the death and torture of other humans. I do think if people were consenting, we should be allowed to have gladiatorial matches. But consent is hard to achieve in those situations. It always starts getting slippery. Like it could be also forced consent, like it starts getting weird. There's way too much excitement. Like this is what he highlights. There's something about human nature that wants to see that violence. And it's really dark. And you hope that we can sort of overcome that aspect of human nature, but that's still within us somewhere. Well, I think that's what we're doing right now. I have this theory that what is very important about the current moment is that all of evolution has been survival of the fittest up until now. And at some point, the lines are kind of fuzzy, but in the recent past, or maybe even just right now, we're getting to this point where we can choose intelligent design. Like we probably since like the integration of the iPhone, like we are becoming cyborgs. Like our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous, from homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is like essentially a new species. Like if you look at the way, if you took an MRI of my brain and you took an MRI of like a medieval brain, I think it would be very different the way that it has evolved. Do you think when historians look back at this time, they'll see like this was a fundamental shift to what a human being is? I think, I do not think we are still homo sapiens. I believe we are homo techno. And I think we have evolved. And I think right now, the way we are evolving, we can choose how we do that. And I think we are being very reckless about how we're doing that. Like we're just having social media, but I think this idea that like this is a time to choose intelligent design should be taken very seriously. It like now is the moment to reprogram the human computer. It's like, if you go blind, your visual cortex will get taken over with other functions. We can choose our own evolution. We can change the way our brains work. And so we actually have a huge responsibility to do that. And I think I'm not sure who should be responsible for that, but there's definitely not adequate education. We're being inundated with all this technology that is fundamentally changing the physical structure of our brains. And we are not adequately responding to that to choose how we wanna evolve. And we could evolve, we could be really whatever we want. And I think this is a really important time. And I think if we choose correctly and we choose wisely, consciousness could exist for a very long time and integration with AI could be extremely positive. And I don't think enough people are focusing on this specific situation. Do you think we might irreversibly screw things up if we get things wrong now? Because the flip side of that, it seems humans are pretty adaptive. So maybe the way we figure things out is by screwing it up, like social media. Over a generation, we'll see the negative effects of social media, and then we build new social medias, and we just keep improving stuff. And then we learn from the failures of the past. Because humans seem to be really adaptive. On the flip side, we can get it wrong in a way where literally we create weapons of war or increase hate. Past a certain threshold, we really do a lot of damage. I mean, I think we're optimized to notice the negative things. But I would actually say one of the things that I think people aren't noticing is if you look at Silicon Valley and you look at the technocracy, like what's been happening there. When Silicon Valley started, it was all just Facebook and all this for profit crap that really wasn't particular. I guess it was useful, but it's sort of just whatever. But now you see lab grown meat, compostable, or biodegradable, single use cutlery, or meditation apps. I think we are actually evolving and changing, and technology is changing. I think there just maybe there isn't quite enough education about this. And also, I don't know if there's quite enough incentive for it because I think the way capitalism works, what we define as profit, we're also working on an old model of what we define as profit. I really think if we changed the idea of profit to include social good, you can have economic profit, social good also counting as profit would incentivize things that are more useful and more whatever spiritual technology or positive technology or things that help reprogram a human computer in a good way or things that help us intelligently design our new brains. Yeah, there's no reason why within the framework of capitalism, the word profit or the idea of profit can't also incorporate the well being of a human being. So like long term well being, long term happiness. Or even for example, we were talking about motherhood, like part of the reason I'm so late is because I had to get the baby to bed. And it's like, I keep thinking about motherhood, how under capitalism, it's like this extremely essential job that is very difficult that is not compensated. And we sort of like value things by how much we compensate them. And so we really devalue motherhood in our society and pretty much all societies. Like capitalism does not recognize motherhood. It's just a job that you're supposed to do for free. And it's like, but I feel like producing great humans should be seen as a great, as profit under capitalism. Like that should be, that's like a huge social good. Like every awesome human that gets made adds so much to the world. So like if that was integrated into the profit structure, then, you know, and if we potentially found a way to compensate motherhood. So come up with a compensation that's much broader than just money or. Or it could just be money. Like, what if you just made, I don't know, but I don't know how you'd pay for that. Like, I mean, that's where you start getting into. Reallocation of resources that people get upset over. Well, like what if we made like a motherhood Dow? Yeah, yeah. And, you know, used it to fund like single mothers, like, you know, pay for making babies. So, I mean, if you create and put beautiful things onto the world, that could be companies, that can be bridges, that could be art, that could be a lot of things, and that could be children, which are. Or education or. Anything, that should be valued by society, and that should be somehow incorporated into the framework of what, as a market, of what. Like, if you contribute children to this world, that should be valued and respected and sort of celebrated, like, proportional to what it is, which is, it's the thing that fuels human civilization. Yeah, like I. It's kind of important. I feel like everyone's always saying, I mean, I think we're in very different social spheres, but everyone's always saying, like, dismantle capitalism. And I'm like, well, okay, well, I don't think the government should own everything. Like, I don't think we should not have private ownership. Like, that's scary. You know, like that starts getting into weird stuff and just sort of like, I feel there's almost no way to do that without a police state, you know? But obviously, capitalism has some major flaws. And I think actually Mac showed me this idea called social capitalism, which is a form of capitalism that just like considers social good to be also profit. Like, you know, it's like, right now companies need to, like, you're supposed to grow every quarter or whatever to like show that you're functioning well, but it's like, okay, well, what if you kept the same amount of profit? You're still in the green, but then you have also all this social good. Like, do you really need all this extra economic growth or could you add this social good and that counts? And, you know, I don't know if, I am not an economist. I have no idea how this could be achieved, but. I don't think economists know how anything could be achieved either, but they pretend. It's the thing, they construct a model and they go on TV shows and sound like an expert. That's the definition of economist. How did being a mother, becoming a mother change you as a human being, would you say? Man, I think it kind of changed everything and it's still changing me a lot. It's actually changing me more right now in this moment than it was before. Like today, like this? Just like in the most recent months and stuff. Can you elucidate that, how change, like when you wake up in the morning and you look at yourself, it's again, which, who are you? How have you become different, would you say? I think it's just really reorienting my priorities. And at first I was really fighting against that because I somehow felt it was like a failure of feminism or something. Like I felt like it was like bad if like my kids started mattering more than my work. And then like more recently I started sort of analyzing that thought in myself and being like, that's also kind of a construct. It's like, we've just devalued motherhood so much in our culture that like, I feel guilty for caring about my kids more than I care about my work. So feminism includes breaking out of whatever the construct is. So just continually breaking, it's like freedom empower you to be free. And that means... But it also, but like being a mother, like I'm so much more creative. Like I cannot believe the massive amount of brain growth that I am. Why do you think that is? Just cause like the stakes are higher somehow? I think it's like, it's just so trippy watching consciousness emerge. It's just like, it's like going on a crazy journey or something. It's like the craziest science fiction novel you could ever read. It's just so crazy watching consciousness come into being. And then at the same time, like you're forced to value your time so much. Like when I have creative time now, it's so sacred. I need to like be really fricking on it. But the other thing is that I used to just be like a cynic and I used to just wanna... Like my last album was called Miss Anthropocene and it was like this like, it was like a study in villainy or like it was like, well, what if we have, instead of the old gods, we have like new gods and it's like Miss Anthropocene is like misanthrope like and Anthropocene, which is like the, you know, like and she's the goddess of climate change or whatever. And she's like destroying the world. And it was just like, it was like dark and it was like a study in villainy. And it was sort of just like, like I used to like have no problem just making cynical, angry, scary art. And not that there's anything wrong with that, but I think having kids just makes you such an optimist. It just inherently makes you wanna be an optimist so bad that like I feel more responsibility to make more optimistic things. And I get a lot of shit for it because everyone's like, oh, you're so privileged. Stop talking about like pie in the sky, stupid concepts and focus on like the now. But it's like, I think if we don't ideate about futures that could be good, we won't be able to get them. If everything is Blade Runner, then we're gonna end up with Blade Runner. It's like, as we said earlier, life imitates art. Like life really does imitate art. And so we really need more protopian or utopian art. I think this is incredibly essential for the future of humanity. And I think the current discourse where that's seen as a thinking about protopia or utopia is seen as a dismissal of the problems that we currently have. I think that is an incorrect mindset. And like having kids just makes me wanna imagine amazing futures that like maybe I won't be able to build, but they will be able to build if they want to. Yeah, it does seem like ideation is a precursor to creation. So you have to imagine it in order to be able to build it. And there is a sad thing about human nature that somehow a cynical view of the world is seen as a insightful view. You know, cynicism is often confused for insight, which is sad to see. And optimism is confused for naivete. Yes, yes. Like you don't, you're blinded by your, maybe your privilege or whatever. You're blinded by something, but you're certainly blinded. That's sad, that's sad to see because it seems like the optimists are the ones that create our future. They're the ones that build. In order to build the crazy thing, you have to be optimistic. You have to be either stupid or excited or passionate or mad enough to actually believe that it can be built. And those are the people that built it. My favorite quote of all time is from Star Wars, Episode 8, which I know everyone hates. Do you like Star Wars, Episode 8? No, yeah, probably I would say I would probably hate it, yeah. I don't have strong feelings about it. Let me backtrack. I don't have strong feelings about Star Wars. I'm a Tolkien person. I'm more into dragons and orcs and ogres. Yeah, I mean, Tolkien forever. I really want to have one more son and call him, I thought Tao Tecno Tolkien would be cool. It's a lot of T's, I like it. Yeah, and well, and Tao is six, two, eight, two pi. Yeah, Tao Tecno, yeah, yeah, yeah. And then techno is obviously the best genre of music, but also like technocracy. It just sounds really good. Yeah, that's right, and techno Tolkien, Tao Tecno Tolkien. That's a good, that's it. Tao Tecno Tolkien, but Star Wars, Episode 8, I know a lot of people have issues with it. Personally, on the record, I think it's the best Star Wars film. You're starting trouble today. Yeah, but don't kill what you hate, save what you love. Don't kill what you hate. Don't kill what you hate, save what you love. And I think we're, in society right now, we're in a diagnosis mode. We're just diagnosing and diagnosing and diagnosing, and we're trying to kill what we hate, and we're not trying to save what we love enough. And there's this Buckminster Fuller quote, which I'm gonna butcher, because I don't remember it correctly, but it's something along the lines of, don't try to destroy the old bad models, render them obsolete with better models. Maybe we don't need to destroy the oil industry. Maybe we just create a great new battery technology and sustainable transport, and just make it economically unreasonable to still continue to rely on fossil fuels. It's like, don't kill what you hate, save what you love. Make new things and just render the old things unusable. It's like if the college debt is so bad, and universities are so expensive, and I feel like education is becoming obsolete. I feel like we could completely revolutionize education, and we could make it free. And it's like, you look at JSTOR, and you have to pay to get all the studies and everything. What if we created a DAO that bought JSTOR, or we created a DAO that was funding studies, and those studies were open source, or free for everyone. And what if we just open sourced education and decentralized education and made it free, and all research was on the internet, and all the outcomes of studies were on the internet, and no one has student debt, and you just take tests when you apply for a job, and if you're qualified, then you can work there. This is just like, I don't know how anything works. I'm just randomly ranting, but. I like the humility. You gotta think from just basic first principles. What is the problem? What's broken? What are some ideas? That's it. And get excited about those ideas, and share your excitement, and don't tear each other down. It's just when you kill things, you often end up killing yourself. Like war is not a one sided, like you're not gonna go in and just kill them, like you're gonna get stabbed. It's like, and I think when I talk about this nexus point of that we're in this point in society where we're switching to intelligent design, I think part of our switch to intelligent design is that we need to choose nonviolence. And we need to, like, I think we can choose to start, I don't think we can eradicate violence from our species, because I think we need it a little bit, but I think we can choose to really reorient our primitive brains that are fighting over scarcity, and that are so attack oriented, and move into, we can optimize for creativity and building. Yeah, it's interesting to think how that happens, so some of it is just education, some of it is living life and introspecting your own mind, and trying to live up to the better angels of your nature for each one of us, all those kinds of things at scale. That's how we can sort of start to minimize the amount of destructive war in our world, and that's, to me, probably you're the same, technology is a really promising way to do that. Like, social media should be a really promising way to do that, it's a way we connect. I, you know, for the most part, I really enjoy social media. I just know all the negative stuff. I don't engage with any of the negative stuff. Just not even, like, by blocking or any of that kind of stuff, but just not letting it enter my mind. Like, just, like, when somebody says something negative, I see it, I immediately think positive thoughts about them, and I just forget they exist after that. Just move on, because, like, that negative energy, if I return the negative energy, they're going to get excited in a negative way right back, and it's just this kind of vicious cycle. But you would think technology would assist us in this process of letting go, of not taking things personally, of not engaging in the negativity, but unfortunately, social media profits from the negativity, so the current models. I mean, social media is like a gun. Like, you should take a course before you use it. Like, it's like, this is what I mean, like, when I say reprogram the human computer. Like, in school, you should learn about how social media optimizes to, you know, raise your cortisol levels and make you angry and crazy and stressed, and, like, you should learn how to have hygiene about how you use social media. But, so you can, yeah, choose not to focus on the negative stuff, but I don't know. I'm not sure social media should, I guess it should exist. I'm not sure. I mean, we're in the messy, it's the experimental phase. Like, we're working it out. Yeah, it's the early days. I don't even know, when you say social media, I don't know what that even means. We're in the very early days. I think social media is just basic human connection in the digital realm, and that, I think it should exist, but there's so many ways to do it in a bad way. There's so many ways to do it in a good way. There's all discussions of all the same human rights. We talk about freedom of speech. We talk about sort of violence in the space of digital media. We talk about hate speech. We talk about all these things that we had to figure out back in the day in the physical space. We're now figuring out in the digital space, and it's like baby stages. When the printing press came out, it was like pure chaos for a minute, you know? It's like when you inject, when there's a massive information injection into the general population, there's just gonna be, I feel like the printing press, I don't have the years, but it was like printing press came out, shit got really fucking bad for a minute, but then we got the enlightenment. And so it's like, I think we're in, this is like the second coming of the printing press. We're probably gonna have some shitty times for a minute, and then we're gonna have recalibrate to have a better understanding of how we consume media and how we deliver media. Speaking of programming the human computer, you mentioned Baby X. So there's this young consciousness coming to be, came from a cell. Like that whole thing doesn't even make sense. It came from DNA. Yeah. And then there's this baby computer that just like grows and grows and grows and grows, and now there's a conscious being with extremely impressive cognitive capabilities with, Have you met him? Yes, yeah. Yeah. He's actually really smart. He's really smart. Yeah. He's weird. Yeah. Or a baby. He does. I don't, I haven't. I don't know a lot of other babies, but he seems to be smart. Zach, I don't hang out with babies often, but this baby was very impressive. He does a lot of pranks and stuff. Oh, so he's like. Like he'll like give you a treat and then take it away and laugh and like stuff like that. So he's like a chess player. So here's a cognitive sort of, there's a computer being programmed. So he's taking in the environment, interacting with a specific set of humans. How would you, first of all, what is it? What, let me ask. I want to ask how do you program this computer? And also how do you make sense of that there's a conscious being right there that wasn't there before? It's giving me a lot of crisis thoughts. I'm thinking really hard. I think that's part of the reason it's like, I'm struggling to focus on art and stuff right now. Cause baby X is becoming conscious and like my it's just reorienting my brain. Like my brain is suddenly totally shifting of like, oh shit, like the way we raise children. Like, I hate all the baby books and everything. I hate them. Like they're, oh, the art is so bad. And like all this stuff, everything about all the aesthetics. And like, I'm just like, ah, like this is so. The programming languages we're using to program these baby computers isn't good. Yeah, like I'm thinking, and I, not that I have like good answers or know what to do, but I'm just thinking really, really hard about it. I, we recently watched Totoro with him, Studio Ghibli. And it's just like a fantastic film. And he like responded to, I know you're not supposed to show baby screens too much, but like, I think it's the most sort of like, I feel like it's the highest art baby content. Like it really speaks, there's almost no talking in it. It's really simple. Although all the dialogue is super, super, super simple, you know, and it's like a one to three year old can like really connect with it. Like it feels like it's almost aimed at like a one to three year old, but it's like great art and it's so imaginative and it's so beautiful. And like the first time I showed it to him, he was just like so invested in it, unlike I've ever, unlike anything else I'd ever shown him. Like he was just like crying when they cry and laughing when they laugh, like just like having this roller coaster of like emotions, like, and he learned a bunch of words. Like he was, and he started saying Totoro and started just saying all this stuff after watching Totoro, and he wants to watch it all the time. And I was like, man, why isn't there an industry of this? Like why aren't our best artists focusing on making art like for the birth of consciousness? Like, and that's one of the things I've been thinking I really wanna start doing. You know, I don't wanna speak before I do things too much, but like, I'm just like ages one to three, like we should be putting so much effort into that. And the other thing about Totoro is it's like, it's like better for the environment because adults love Totoro. It's such good art that everyone loves it. Like I still have all my old Totoro merch from when I was a kid. Like I literally have the most ragged old Totoro merch. Like everybody loves it, everybody keeps it. It's like, why does the art we have for babies need to suck and be not accessible to adults and then just be thrown out when, you know, they age out of it? Like, it's like, I don't know. I don't have like a fully formed thought here, but this is just something I've been thinking about a lot is like, how do we like, how do we have more Totoroesque content? Like how do we have more content like this that like is universal and everybody loves, but is like really geared to an emerging consciousness? Emerging consciousness in the first like three years of life that so much turmoil, so much evolution of mind is happening. It seems like a crucial time. Would you say to make it not suck, do you think of basically treating a child like they have the capacity to have the brilliance of an adult or even beyond that? Is that how you think of that mind or? No, cause they still, they like it when you talk weird and stuff. Like they respond better to, cause even they can imitate better when your voice is higher. Like people say like, oh, don't do baby talk. But it's like, when your voice is higher, it's closer to something they can imitate. So they like, like the baby talk actually kind of works. Like it helps them learn to communicate. I've found it to be more effective with learning words and stuff. But like, you're not speaking down to them. Like do they have the capacity\",\n          \"The following is a conversation with Sean Carroll. He's a theoretical physicist at Caltech specializing in quantum mechanics, gravity, and cosmology. He's the author of several popular books, one on the arrow of time called From Eternity to Here, one on the Higgs boson called Particle at the End of the Universe, and one on science and philosophy called The Big Picture on the Origins of Life, Meaning, and the Universe Itself. He has an upcoming book on quantum mechanics that you can preorder now called Something Deeply Hidden. He writes one of my favorite blogs on his website, preposterousuniverse.com. I recommend clicking on the Greatest Hits link that lists accessible, interesting posts on the arrow of time, dark matter, dark energy, the Big Bang, general relativity, string theory, quantum mechanics, and the big meta questions about the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's Hardcore History, Sean's Mindscape podcast is one of my favorite ways to learn new ideas or explore different perspectives and ideas that I thought I understood. It was truly an honor to meet and spend a couple hours with Sean. It's a bit heartbreaking to say that for the first time ever, the audio recorder for this podcast died in the middle of our conversation. There's technical reasons for this, having to do with phantom power that I now understand and will avoid. It took me one hour to notice and fix the problem. So, much like the universe is 68% dark energy, roughly the same amount from this conversation was lost, except in the memories of the two people involved and in my notes. I'm sure we'll talk again and continue this conversation on this podcast or on Sean's. And of course, I look forward to it. This is the Artificial Intelligence podcast. If you enjoy it, subscribe on YouTube, iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman. And now, here's my conversation with Sean Carroll. What do you think is more interesting and impactful, understanding how the universe works at a fundamental level or understanding how the human mind works? You know, of course this is a crazy, meaningless, unanswerable question in some sense, because they're both very interesting and there's no absolute scale of interestingness that we can rate them on. There's a glib answer that says the human brain is part of the universe, right? And therefore, understanding the universe is more fundamental than understanding the human brain. But do you really believe that once we understand the fundamental way the universe works at the particle level, the forces, we would be able to understand how the mind works? No, certainly not. We cannot understand how ice cream works just from understanding how particles work, right? So I'm a big believer in emergence. I'm a big believer that there are different ways of talking about the world beyond just the most fundamental microscopic one. You know, when we talk about tables and chairs and planets and people, we're not talking the language of particle physics and cosmology. So, but understanding the universe, you didn't say just at the most fundamental level, right? So understanding the universe at all levels is part of that. I do think, you know, to be a little bit more fair to the question, there probably are general principles of complexity, biology, information processing, memory, knowledge, creativity that go beyond just the human brain, right? And maybe one could count understanding those as part of understanding the universe. The human brain, as far as we know, is the most complex thing in the universe. So there's, it's certainly absurd to think that by understanding the fundamental laws of particle physics, you get any direct insight on how the brain works. But then there's this step from the fundamentals of particle physics to information processing, which a lot of physicists and philosophers may be a little bit carelessly take when they talk about artificial intelligence. Do you think of the universe as a kind of a computational device? No, to be like, the honest answer there is no. There's a sense in which the universe processes information, clearly. There's a sense in which the universe is like a computer, clearly. But in some sense, I think, I tried to say this once on my blog and no one agreed with me, but the universe is more like a computation than a computer because the universe happens once. A computer is a general purpose machine, right? That you can ask it different questions, even a pocket calculator, right? And it's set up to answer certain kinds of questions. The universe isn't that. So information processing happens in the universe, but it's not what the universe is. And I know your MIT colleague, Seth Lloyd, feels very differently about this, right? Well, you're thinking of the universe as a closed system. I am. So what makes a computer more like a PC, like a computing machine is that there's a human that every once comes up to it and moves the mouse around. So input. Gives it input. Gives it input. And that's why you're saying it's just a computation, a deterministic thing that's just unrolling. But the immense complexity of it is nevertheless like processing. There's a state and then it changes with good rules. And there's a sense for a lot of people that if the brain operates, the human brain operates within that world, then it's simply just a small subset of that. And so there's no reason we can't build arbitrarily great intelligences. Yeah. Do you think of intelligence in this way? Intelligence is tricky. I don't have a definition of it offhand. So I remember this panel discussion that I saw on YouTube. I wasn't there, but Seth Lloyd was on the panel. And so was Martin Rees, the famous astrophysicist. And Seth gave his shtick for why the universe is a computer and explained this. And Martin Rees said, so what is not a computer? And Seth was like, oh, that's a good question. I'm not sure. Because if you have a sufficiently broad definition of what a computer is, then everything is, right? And the simile or the analogy gains force when it excludes some things. You know, is the moon going around the earth performing a computation? I can come up with definitions in which the answer is yes, but it's not a very useful computation. I think that it's absolutely helpful to think about the universe in certain situations, certain contexts, as an information processing device. I'm even guilty of writing a paper called Quantum Circuit Cosmology, where we modeled the whole universe as a quantum circuit. As a circuit. As a circuit, yeah. With qubits kind of thing? With qubits basically, right, yeah. So, and qubits becoming more and more entangled. So do we wanna digress a little bit? Let's do it. It's kind of fun. So here's a mystery about the universe that is so deep and profound that nobody talks about it. Space expands, right? And we talk about, in a certain region of space, a certain number of degrees of freedom, a certain number of ways that the quantum fields and the particles in that region can arrange themselves. That number of degrees of freedom in a region of space is arguably finite. We actually don't know how many there are, but there's a very good argument that says it's a finite number. So as the universe expands and space gets bigger, are there more degrees of freedom? If it's an infinite number, it doesn't really matter. Infinity times two is still infinity. But if it's a finite number, then there's more space, so there's more degrees of freedom. So where did they come from? That would mean the universe is not a closed system. There's more degrees of freedom popping into existence. So what we suggested was that there are more degrees of freedom, and it's not that they're not there to start, but they're not entangled to start. So the universe that you and I know of, the three dimensions around us that we see, we said those are the entangled degrees of freedom making up space time. And as the universe expands, there are a whole bunch of qubits in their zero state that become entangled with the rest of space time through the action of these quantum circuits. So what does it mean that there's now more degrees of freedom as they become more entangled? Yeah, so. As the universe expands. That's right, so there's more and more degrees of freedom that are entangled, that are playing part, playing the role of part of the entangled space time structure. So the basic, the underlying philosophy is that space time itself arises from the entanglement of some fundamental quantum degrees of freedom. Wow, okay, so at which point is most of the entanglement happening? Are we talking about close to the Big Bang? Are we talking about throughout the time of the life? Throughout history, yeah. So the idea is that at the Big Bang, almost all the degrees of freedom that the universe could have were there, but they were unentangled with anything else. And that's a reflection of the fact that the Big Bang had a low entropy. It was a very simple, very small place. And as space expands, more and more degrees of freedom become entangled with the rest of the world. Well, I have to ask John Carroll, what do you think of the thought experiment from Nick Bostrom that we're living in a simulation? So I think, let me contextualize that a little bit more. I think people don't actually take this thought experiments. I think it's quite interesting. It's not very useful, but it's quite interesting. From the perspective of AI, a lot of the learning that can be done usually happens in simulation from artificial examples. And so it's a constructive question to ask, how difficult is our real world to simulate? Right. Which is kind of a dual part of, if we're living in a simulation and somebody built that simulation, if you were to try to do it yourself, how hard would it be? So obviously we could be living in a simulation. If you just want the physical possibility, then I completely agree that it's physically possible. I don't think that we actually are. So take this one piece of data into consideration. You know, we live in a big universe, okay? There's two trillion galaxies in our observable universe with 200 billion stars in each galaxy, et cetera. It would seem to be a waste of resources to have a universe that big going on just to do a simulation. So in other words, I want to be a good Bayesian. I want to ask under this hypothesis, what do I expect to see? So the first thing I would say is I wouldn't expect to see a universe that was that big, okay? The second thing is I wouldn't expect the resolution of the universe to be as good as it is. So it's always possible that if our superhuman simulators only have finite resources, that they don't render the entire universe, right? That the part that is out there, the two trillion galaxies, isn't actually being simulated fully, okay? But then the obvious extrapolation of that is that only I am being simulated fully. Like the rest of you are just non player characters, right? I'm the only thing that is real. The rest of you are just chat bots. Beyond this wall, I see the wall, but there is literally nothing on the other side of the wall. That is sort of the Bayesian prediction. That's what it would be like to do an efficient simulation of me. So like none of that seems quite realistic. I don't see, I hear the argument that it's just possible and easy to simulate lots of things. I don't see any evidence from what we know about our universe that we look like a simulated universe. Now, maybe you can say, well, we don't know what it would look like, but that's just abandoning your Bayesian responsibilities. Like your job is to say under this theory, here's what you would expect to see. Yeah, so certainly if you think about simulation as a thing that's like a video game where only a small subset is being rendered. But say the entire, all the laws of physics, the entire closed system of the quote unquote universe, it had a creator. Yeah, it's always possible. Right, so that's not useful to think about when you're thinking about physics. The way Nick Bostrom phrases it, if it's possible to simulate a universe, eventually we'll do it. Right. You can use that by the way for a lot of things. Well, yeah. But I guess the question is, how hard is it to create a universe? I wrote a little blog post about this and maybe I'm missing something, but there's an argument that says not only that it might be possible to simulate a universe, but probably if you imagine that you actually attribute consciousness and agency to the little things that we're simulating, to our little artificial beings, there's probably a lot more of them than there are ordinary organic beings in the universe or there will be in the future, right? So there's an argument that not only is being a simulation possible, it's probable because in the space of all living consciousnesses, most of them are being simulated, right? Most of them are not at the top level. I think that argument must be wrong because it follows from that argument that, if we're simulated, but we can also simulate other things, well, but if we can simulate other things, they can simulate other things, right? If we give them enough power and resolution and ultimately we'll reach a bottom because the laws of physics in our universe have a bottom, we're made of atoms and so forth, so there will be the cheapest possible simulations. And if you believe the original argument, you should conclude that we should be in the cheapest possible simulation because that's where most people are. But we don't look like that. It doesn't look at all like we're at the edge of resolution, that we're 16 bit things. It seems much easier to make much lower level things than we are. And also, I questioned the whole approach to the anthropic principle that says we are typical observers in the universe. I think that that's not actually, I think that there's a lot of selection that we can do that we're typical within things we already know, but not typical within all of the universe. So do you think there's intelligent life, however you would like to define intelligent life, out there in the universe? My guess is that there is not intelligent life in the observable universe other than us, simply on the basis of the fact that the likely number of other intelligent species in the observable universe, there's two likely numbers, zero or billions. And if there had been billions, you would have noticed already. For there to be literally like a small number, like, you know, Star Trek, there's a dozen intelligent civilizations in our galaxy, but not a billion, that's weird. That's sort of bizarre to me. It's easy for me to imagine that there are zero others because there's just a big bottleneck to making multicellular life or technological life or whatever. It's very hard for me to imagine that there's a whole bunch out there that have somehow remained hidden from us. The question I'd like to ask is what would intelligent life look like? What I mean by that question and where it's going is what if intelligent life is just in some very big ways different than the one that has on Earth? That there's all kinds of intelligent life that operates at different scales of both size and temporal. Right, that's a great possibility because I think we should be humble about what intelligence is, what life is. We don't even agree on what life is, much less what intelligent life is, right? So that's an argument for humility, saying there could be intelligent life of a very different character, right? Like you could imagine the dolphins are intelligent but never invent space travel because they live in the ocean and they don't have thumbs, right? So they never invent technology, they never invent smelting. Maybe the universe is full of intelligent species that just don't make technology, right? That's compatible with the data, I think. And I think maybe what you're pointing at is even more out there versions of intelligence, intelligence in intermolecular clouds or on the surface of a neutron star or in between the galaxies in giant things where the equivalent of a heartbeat is 100 million years. On the one hand, yes, we should be very open minded about those things. On the other hand, all of us share the same laws of physics. There might be something about the laws of physics, even though we don't currently know exactly what that thing would be, that makes meters and years the right length and timescales for intelligent life. Maybe not, but we're made of atoms, atoms have a certain size, we orbit stars or stars have a certain lifetime. It's not impossible to me that there's a sweet spot for intelligent life that we find ourselves in. So I'm open minded either way, I'm open minded either being humble and there's all sorts of different kinds of life or no, there's a reason we just don't know it yet why life like ours is the kind of life that's out there. Yeah, I'm of two minds too, but I often wonder if our brains is just designed to quite obviously to operate and see the world in these timescales and we're almost blind and the tools we've created for detecting things are blind to the kind of observation needed to see intelligent life at other scales. Well, I'm totally open to that, but so here's another argument I would make, we have looked for intelligent life, but we've looked at for it in the dumbest way we can, by turning radio telescopes to the sky. And why in the world would a super advanced civilization randomly beam out radio signals wastefully in all directions into the universe? That just doesn't make any sense, especially because in order to think that you would actually contact another civilization, you would have to do it forever, you have to keep doing it for millions of years, that sounds like a waste of resources. If you thought that there were other solar systems with planets around them, where maybe intelligent life didn't yet exist, but might someday, you wouldn't try to talk to it with radio waves, you would send a spacecraft out there and you would park it around there and it would be like, from our point of view, it'd be like 2001, where there was a monolith. Monolith. There could be an artifact, in fact, the other way works also, right? There could be artifacts in our solar system that have been put there by other technologically advanced civilizations and that's how we will eventually contact them. We just haven't explored the solar system well enough yet to find them. The reason why we don't think about that is because we're young and impatient, right? Like, it would take more than my lifetime to actually send something to another star system and wait for it and then come back. So, but if we start thinking on hundreds of thousands of years or million year time scales, that's clearly the right thing to do. Are you excited by the thing that Elon Musk is doing with SpaceX in general? Space, but the idea of space exploration, even though your, or your species is young and impatient? Yeah. No, I do think that space travel is crucially important, long term. Even to other star systems. And I think that many people overestimate the difficulty because they say, look, if you travel 1% the speed of light to another star system, we'll be dead before we get there, right? And I think that it's much easier. And therefore, when they write their science fiction stories, they imagine we'd go faster than the speed of light because otherwise they're too impatient, right? We're not gonna go faster than the speed of light, but we could easily imagine that the human lifespan gets extended to thousands of years. And once you do that, then the stars are much closer effectively, right? And then what's a hundred year trip, right? So I think that that's gonna be the future, the far future, not my lifetime once again, but baby steps. Unless your lifetime gets extended. Well, it's in a race against time, right? A friend of mine who actually thinks about these things said, you know, you and I are gonna die, but I don't know about our grandchildren. That's, I don't know, predicting the future is hard, but that's at least a plausible scenario. And so, yeah, no, I think that as we discussed earlier, there are threats to the earth, known and unknown, right? Having spread humanity and biology elsewhere is a really important longterm goal. What kind of questions can science not currently answer, but might soon? When you think about the problems and the mysteries before us that may be within reach of science. I think an obvious one is the origin of life. We don't know how that happened. There's a difficulty in knowing how it happened historically actually, you know, literally on earth, but starting life from non life is something I kind of think we're close to, right? We're really. You really think so? Like how difficult is it to start life? Well, I've talked to people, including on the podcast about this. You know, life requires three things. Life as we know it. So there's a difference with life, which who knows what it is, and life as we know it, which we can talk about with some intelligence. So life as we know it requires compartmentalization. You need like a little membrane around your cell. Metabolism, you need to take in food and eat it and let that make you do things. And then replication, okay? So you need to have some information about who you are that you pass down to future generations. In the lab, compartmentalization seems pretty easy. Not hard to make lipid bilayers that come into little cellular walls pretty easily. Metabolism and replication are hard, but replication we're close to. People have made RNA like molecules in the lab that I think the state of the art is, they're not able to make one molecule that reproduces itself, but they're able to make two molecules that reproduce each other. So that's okay. That's pretty close. Metabolism is harder, believe it or not, even though it's sort of the most obvious thing, but you want some sort of controlled metabolism and the actual cellular machinery in our bodies is quite complicated. It's hard to see it just popping into existence all by itself. It probably took a while, but we're making progress. And in fact, I don't think we're spending nearly enough money on it. If I were the NSF, I would flood this area with money because it would change our view of the world if we could actually make life in the lab and understand how it was made originally here on earth. And I'm sure it'd have some ripple effects that help cure disease and so on. I mean, just that understanding. So synthetic biology is a wonderful big frontier where we're making cells. Right now, the best way to do that is to borrow heavily from existing biology, right? Well, Craig Venter several years ago created an artificial cell, but all he did was, not all he did, it was a tremendous accomplishment, but all he did was take out the DNA from a cell and put in entirely new DNA and let it boot up and go. What about the leap to creating intelligent life on earth? Yeah. Again, we define intelligence, of course, but let's just even say Homo sapiens, the modern intelligence in our human brain. Do you have a sense of what's involved in that leap and how big of a leap that is? So AI would count in this, or do you really want life? Do you want really an organism in some sense? AI would count, I think. Okay. Yeah, of course, of course AI would count. Well, let's say artificial consciousness, right? So I do not think we are on the threshold of creating artificial consciousness. I think it's possible. I'm not, again, very educated about how close we are, but my impression is not that we're really close because we understand how little we understand of consciousness and what it is. So if we don't have any idea what it is, it's hard to imagine we're on the threshold of making it ourselves. But it's doable, it's possible. I don't see any obstacles in principle. So yeah, I would hold out some interest in that happening eventually. I think in general, consciousness, I think we would be just surprised how easy consciousness is once we create intelligence. I think consciousness is a thing that's just something we all fake. Well, good. No, actually, I like this idea that in fact, consciousness is way less mysterious than we think because we're all at every time, at every moment, less conscious than we think we are, right? We can fool things. And I think that plus the idea that you not only have artificial intelligent systems, but you put them in a body, right, give them a robot body, that will help the faking a lot. Yeah, I think creating consciousness in artificial consciousness is as simple as asking a Roomba to say, I'm conscious, and refusing to be talked out of it. Could be, it could be. And I mean, I'm almost being silly, but that's what we do. That's what we do with each other. This is the kind of, that consciousness is also a social construct. And a lot of our ideas of intelligence is a social construct. And so reaching that bar involves something that's beyond, that doesn't necessarily involve the fundamental understanding of how you go from electrons to neurons to cognition. No, actually, I think that is an extremely good point. And in fact, what it suggests is, so yeah, you referred to Kate Darling, who I had on the podcast, and who does these experiments with very simple robots, but they look like animals, and they can look like they're experiencing pain, and we human beings react very negatively to these little robots looking like they're experiencing pain. And what you wanna say is, yeah, but they're just robots. It's not really pain, right? It's just some electrons going around. But then you realize, you and I are just electrons going around, and that's what pain is also. And so what I would have an easy time imagining is that there is a spectrum between these simple little robots that Kate works with and a human being, where there are things that sort of by some strict definition, Turing test level thing are not conscious, but nevertheless walk and talk like they're conscious. And it could be that the future is, I mean, Siri is close, right? And so it might be the future has a lot more agents like that. And in fact, rather than someday going, aha, we have consciousness, we'll just creep up on it with more and more accurate reflections of what we expect. And in the future, maybe the present, for example, we haven't met before, and you're basically assuming that I'm human as it's a high probability at this time because the yeah, but in the future, there might be question marks around that, right? Yeah, no, absolutely. Certainly videos are almost to the point where you shouldn't trust them already. Photos you can't trust, right? Videos is easier to trust, but we're getting worse that, we're getting better at faking them, right? Yeah, so physical embodied people, what's so hard about faking that? So this is very depressing, this conversation we're having right now. So I mean, To me, it's exciting. To me, you're doing it. So it's exciting to you, but it's a sobering thought. We're very bad, right? At imagining what the next 50 years are gonna be like when we're in the middle of a phase transition as we are right now. Yeah, and I, in general, I'm not blind to all the threats. I am excited by the power of technology to solve, to protect us against the threats as they evolve. I'm not as much as Steven Pinker optimistic about the world, but in everything I've seen, all of the brilliant people in the world that I've met are good people. So the army of the good in terms of the development of technology is large. Okay, you're way more optimistic than I am. I think that goodness and badness are equally distributed among intelligent and unintelligent people. I don't see much of a correlation there. Interesting. Neither of us have proof. Yeah, exactly. Again, opinions are free, right? Nor definitions of good and evil. We come without definitions or without data opinions. So what kind of questions can science not currently answer and may never be able to answer in your view? Well, the obvious one is what is good and bad? What is right and wrong? I think that there are questions that, science tells us what happens, what the world is and what it does. It doesn't say what the world should do or what we should do, because we're part of the world. But we are part of the world and we have the ability to feel like something's right, something's wrong. And to make a very long story very short, I think that the idea of moral philosophy is systematizing our intuitions of what is right and what is wrong. And science might be able to predict ahead of time what we will do, but it won't ever be able to judge whether we should have done it or not. So, you're kind of unique in terms of scientists. Listen, it doesn't have to do with podcasts, but even just reaching out, I think you referred to as sort of doing interdisciplinary science. So you reach out and talk to people that are outside of your discipline, which I always hope that's what science was for. In fact, I was a little disillusioned when I realized that academia is very siloed. Yeah. And so the question is, how, at your own level, how do you prepare for these conversations? How do you think about these conversations? How do you open your mind enough to have these conversations? And it may be a little bit broader, how can you advise other scientists to have these kinds of conversations? Not at the podcast, the fact that you're doing a podcast is awesome, other people get to hear them, but it's also good to have it without mics in general. It's a good question, but a tough one to answer. I think about a guy I know who's a personal trainer, and he was asked on a podcast, how do we psych ourselves up to do a workout? How do we make that discipline to go and work out? And he's like, why are you asking me? I can't stop working out. I don't need to psych myself up. So, and likewise, he asked me, how do you get to have interdisciplinary conversations on all sorts of different things, all sorts of different people? I'm like, that's what makes me go, right? Like that's, I couldn't stop doing that. I did that long before any of them were recorded. In fact, a lot of the motivation for starting recording it was making sure I would read all these books that I had purchased, right? Like all these books I wanted to read, not enough time to read them. And now if I have the motivation, cause I'm gonna interview Pat Churchland, I'm gonna finally read her book. You know, and it's absolutely true that academia is extraordinarily siloed, right? We don't talk to people. We rarely do. And in fact, when we do, it's punished. You know, like the people who do it successfully generally first became very successful within their little siloed discipline. And only then did they start expanding out. If you're a young person, you know, I have graduate students. I try to be very, very candid with them about this, that it's, you know, most graduate students are to not become faculty members, right? It's a tough road. And so live the life you wanna live, but do it with your eyes open about what it does to your job chances. And the more broad you are and the less time you spend hyper specializing in your field, the lower your job chances are. That's just an academic reality. It's terrible, I don't like it, but it's a reality. And for some people, that's fine. Like there's plenty of people who are wonderful scientists who have zero interest in branching out and talking to things, to anyone outside their field. But it is disillusioning to me. Some of the, you know, romantic notion I had of the intellectual academic life is belied by the reality of it. The idea that we should reach out beyond our discipline and that is a positive good is just so rare in universities that it may as well not exist at all. But that said, even though you're saying you're doing it like the personal trainer, because you just can't help it, you're also an inspiration to others. Like I could speak for myself. You know, I also have a career I'm thinking about, right? And without your podcast, I may have not have been doing this at all, right? So it makes me realize that these kinds of conversations is kind of what science is about in many ways. The reason we write papers, this exchange of ideas, is it's much harder to do interdisciplinary papers, I would say. And conversations are easier. So conversations is the beginning. And in the field of AI, it's obvious that we should think outside of pure computer vision competitions on a particular data sets. We should think about the broader impact of how this can be, you know, reaching out to physics, to psychology, to neuroscience and having these conversations so that you're an inspiration. And so never know how the world changes. I mean, the fact that this stuff is out there and I've a huge number of people come up to me, grad students, really loving the podcast, inspired by it. And they will probably have that, they'll be ripple effects when they become faculty and so on and so on. We can end on a balance between pessimism and optimism. And Sean, thank you so much for talking to me, it was awesome. No, Lex, thank you very much for this conversation. It was great.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "podcast_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z45blLFrlXC",
        "outputId": "2451ce97-f098-4ca9-fb15-b807effe95e7"
      },
      "id": "8Z45blLFrlXC",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(319, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Text Preprocessing\n",
        "\n",
        "You know what to do ;)"
      ],
      "metadata": {
        "id": "6kWzLx9Los83"
      },
      "id": "6kWzLx9Los83"
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcin para preprocesar el texto\n",
        "def preprocesar_texto(texto):\n",
        "    # Eliminacin de caracteres no deseados y normalizacin\n",
        "    texto = re.sub(r'\\W', ' ', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "    texto = texto.lower()\n",
        "    # Tokenizar el texto\n",
        "    tokens = word_tokenize(texto)\n",
        "    # Eliminar stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords_set]\n",
        "    # Aplicar stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    # Unir las palabras procesadas en un solo texto\n",
        "    texto_procesado = ' '.join(tokens)\n",
        "    return texto_procesado"
      ],
      "metadata": {
        "id": "kM5shbuOpOrY"
      },
      "id": "kM5shbuOpOrY",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo DataFrame con la columna 'text' preprocesada\n",
        "podcast_pre_df = podcast_df.copy()\n",
        "podcast_pre_df['text_pre'] = podcast_pre_df['text'].apply(preprocesar_texto)"
      ],
      "metadata": {
        "id": "KTq6ziqip2rY"
      },
      "id": "KTq6ziqip2rY",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "podcast_pre_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Yn87LbuKpIdB",
        "outputId": "d8ea434a-1f91-4b77-b00f-e9b2ff1b5e22"
      },
      "id": "Yn87LbuKpIdB",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              guest                    title  \\\n",
              "id                                             \n",
              "1       Max Tegmark                 Life 3.0   \n",
              "2     Christof Koch            Consciousness   \n",
              "3     Steven Pinker  AI in the Age of Reason   \n",
              "4     Yoshua Bengio            Deep Learning   \n",
              "5   Vladimir Vapnik     Statistical Learning   \n",
              "\n",
              "                                                 text  \\\n",
              "id                                                      \n",
              "1   As part of MIT course 6S099, Artificial Genera...   \n",
              "2   As part of MIT course 6S099 on artificial gene...   \n",
              "3   You've studied the human mind, cognition, lang...   \n",
              "4   What difference between biological neural netw...   \n",
              "5   The following is a conversation with Vladimir ...   \n",
              "\n",
              "                                             text_pre  \n",
              "id                                                     \n",
              "1   part mit cours 6s099 artifici gener intellig g...  \n",
              "2   part mit cours 6s099 artifici gener intellig g...  \n",
              "3   studi human mind cognit languag vision evolut ...  \n",
              "4   differ biolog neural network artifici neural n...  \n",
              "5   follow convers vladimir vapnik co inventor sup...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09ceaab7-e20a-4633-92df-f8c7df3c5971\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guest</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>text_pre</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Max Tegmark</td>\n",
              "      <td>Life 3.0</td>\n",
              "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
              "      <td>part mit cours 6s099 artifici gener intellig g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christof Koch</td>\n",
              "      <td>Consciousness</td>\n",
              "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
              "      <td>part mit cours 6s099 artifici gener intellig g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steven Pinker</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "      <td>You've studied the human mind, cognition, lang...</td>\n",
              "      <td>studi human mind cognit languag vision evolut ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yoshua Bengio</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>What difference between biological neural netw...</td>\n",
              "      <td>differ biolog neural network artifici neural n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Vladimir Vapnik</td>\n",
              "      <td>Statistical Learning</td>\n",
              "      <td>The following is a conversation with Vladimir ...</td>\n",
              "      <td>follow convers vladimir vapnik co inventor sup...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ceaab7-e20a-4633-92df-f8c7df3c5971')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09ceaab7-e20a-4633-92df-f8c7df3c5971 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09ceaab7-e20a-4633-92df-f8c7df3c5971');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae9d56fc-e2b3-4a0b-9a17-0517b039a81e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae9d56fc-e2b3-4a0b-9a17-0517b039a81e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae9d56fc-e2b3-4a0b-9a17-0517b039a81e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "podcast_pre_df",
              "summary": "{\n  \"name\": \"podcast_pre_df\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 93,\n        \"min\": 1,\n        \"max\": 325,\n        \"num_unique_values\": 318,\n        \"samples\": [\n          74,\n          281,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"guest\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 281,\n        \"samples\": [\n          \"Keoki Jackson\",\n          \"Sergey Nazarov\",\n          \"Dan Reynolds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Deep Learning, Education, and Real-World AI\",\n          \"Bad Vegan\",\n          \"Thousand Brains Theory of Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 318,\n        \"samples\": [\n          \"The following is a conversation with Michael I. Jordan, a professor at Berkeley and one of the most influential people in the history of machine learning, statistics, and artificial intelligence. He has been cited over 170,000 times and he has mentored many of the world class researchers defining the field of AI today, including Andrew Ng, Zubin Garamani, Ben Taskar, and Yoshua Bengio. All this, to me, is as impressive as the over 32,000 points in the six NBA championships of the Michael J. Jordan of basketball fame. There's a nonzero probability that I talked to the other Michael Jordan given my connection to and love of the Chicago Bulls of the 90s, but if I had to pick one, I'm going with the Michael Jordan of statistics and computer science, or as Yann LeCun calls him, the Miles Davis of machine learning. In his blog post titled Artificial Intelligence, the Revolution Hasn't Happened Yet, Michael argues for broadening the scope of the artificial intelligence field. In many ways, the underlying spirit of this podcast is the same, to see artificial intelligence as a deeply human endeavor, to not only engineer algorithms and robots, but to understand and empower human beings at all levels of abstraction, from the individual to our civilization as a whole. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe and YouTube, give it five stars at Apple Podcast, support it on Patreon, or simply connect with me on Twitter at Lex Friedman spelled F R I D M A N. As usual, I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance app in the App Store. When you get it, use code LEX PODCAST. Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with as little as $1. Since Cash App does fractional share trading, let me mention that the order execution algorithm that worked behind the scenes to create the abstraction of the fractional orders is to me an algorithmic marvel. Great props for the Cash App engineers for solving a hard problem that in the end provides an easy interface that takes a step up to the next layer of abstraction over the stock market, making trading more accessible for new investors and diversification much easier. So once again, if you get Cash App from the App Store or Google Play and use the code LEX PODCAST, you'll get $10 and Cash App will also donate $10 to First, one of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. And now, here's my conversation with Michael I. Jordan. Given that you're one of the greats in the field of AI, machine learning, computer science, and so on, you're trivially called the Michael Jordan of machine learning, although as you know, you were born first, so technically MJ is the Michael I. Jordan of basketball. But anyway, my favorite is Yann LeCun calling you the Miles Davis of machine learning because as he says, you reinvent yourself periodically and sometimes leave fans scratching their heads after you change direction. So can you put at first your historian hat on and give a history of computer science and AI as you saw it, as you experienced it, including the four generations of AI successes that I've seen you talk about? Sure. Yeah, first of all, I much prefer Yann's metaphor. Miles Davis was a real explorer in jazz and he had a coherent story. So I think I have one, but it's not just the one you lived, it's the one you think about later. What the historian does is they look back and they revisit. I think what's happening right now is not AI, that was an intellectual aspiration that's still alive today as an aspiration. But I think this is akin to the development of chemical engineering from chemistry or electrical engineering from electromagnetism. So if you go back to the 30s or 40s, there wasn't yet chemical engineering. There was chemistry, there was fluid flow, there was mechanics and so on. But people pretty clearly viewed interesting goals to try to build factories that make chemicals products and do it viably, safely, make good ones, do it at scale. So people started to try to do that, of course, and some factories worked, some didn't, some were not viable, some exploded, but in parallel, developed a whole field called chemical engineering. Electrical engineering is a field, it's no bones about it, it has theoretical aspects to it, it has practical aspects. It's not just engineering, quote unquote, it's the real thing, real concepts are needed. Same thing with electrical engineering. There was Maxwell's equations, which in some sense were everything you know about electromagnetism, but you needed to figure out how to build circuits, how to build modules, how to put them together, how to bring electricity from one point to another safely and so on and so forth. So a whole field that developed called electrical engineering. I think that's what's happening right now, is that we have a proto field, which is statistics, more of the theoretical side of it, algorithmic side of computer science, that was enough to start to build things, but what things? Systems that bring value to human beings and use human data and mix in human decisions. The engineering side of that is all ad hoc. That's what's emerging. In fact, if you wanna call machine learning a field, I think that's what it is, that it's a proto form of engineering based on statistical and computational ideas of previous generations. But do you think there's something deeper about AI in his dreams and aspirations as compared to chemical engineering and electrical engineering? Well the dreams and aspirations maybe, but those are 500 years from now. I think that that's like the Greeks sitting there and saying, it would be neat to get to the moon someday. I think we have no clue how the brain does computation. We're just a clueless. We're even worse than the Greeks on most anything interesting scientifically of our era. Can you linger on that just for a moment because you stand not completely unique, but a little bit unique in the clarity of that. Can you elaborate your intuition of why we're, like where we stand in our understanding of the human brain? And a lot of people say, you know, scientists say we're not very far in understanding human brain, but you're like, you're saying we're in the dark here. Well, I know I'm not unique. I don't even think in the clarity, but if you talk to real neuroscientists that really study real synapses or real neurons, they agree, they agree. It's a hundreds of year task and they're building it up slowly and surely. What the signal is there is not clear. We think we have all of our metaphors. We think it's electrical, maybe it's chemical, it's a whole soup, it's ions and proteins and it's a cell. And that's even around like a single synapse. If you look at a electron micrograph of a single synapse, it's a city of its own. And that's one little thing on a dendritic tree, which is extremely complicated electrochemical thing. And it's doing these spikes and voltages are flying around and then proteins are taking that and taking it down into the DNA and who knows what. So it is the problem of the next few centuries. It is fantastic. But we have our metaphors about it. Is it an economic device? Is it like the immune system or is it like a layered set of, you know, arithmetic computations? We have all these metaphors and they're fun. But that's not real science per se. There is neuroscience. That's not neuroscience. All right. That's like the Greek speculating about how to get to the moon, fun, right? And I think that I like to say this fairly strongly because I think a lot of young people think we're on the verge because a lot of people who don't talk about it clearly let it be understood that, yes, we kind of, this is a brain inspired, we're kind of close, you know, breakthroughs are on the horizon. And that's scrupulous people sometimes who need money for their labs. That's what I'm saying, scrupulous, but people will oversell, I need money for my lab, I'm studying computational neuroscience, I'm going to oversell it. And so there's been too much of that. So I'll step into the gray area between metaphor and engineering with, I'm not sure if you're familiar with brain computer interfaces. So a company like Elon Musk has Neuralink that's working on putting electrodes into the brain and trying to be able to read, both read and send electrical signals. Just as you said, even the basic mechanism of communication in the brain is not something we understand. But do you hope without understanding the fundamental principles of how the brain works, we'll be able to do something interesting at that gray area of metaphor? It's not my area. So I hope in the sense, like anybody else hopes for some interesting things to happen from research, I would expect more something like Alzheimer's will get figured out from modern neuroscience. There's a lot of human suffering based on brain disease and we throw things like lithium at the brain, it kind of works, no one has a clue why. That's not quite true, but mostly we don't know. And that's even just about the biochemistry of the brain and how it leads to mood swings and so on. How thought emerges from that, we were really, really completely dim. So that you might want to hook up electrodes and try to do some signal processing on that and try to find patterns, fine, by all means, go for it. It's just not scientific at this point. So it's like kind of sitting in a satellite and watching the emissions from a city and trying to infer things about the microeconomy, even though you don't have microeconomic concepts. It's really that kind of thing. And so yes, can you find some signals that do something interesting or useful? Can you control a cursor or mouse with your brain? Yeah, absolutely, and then I can imagine business models based on that and even medical applications of that. But from there to understanding algorithms that allow us to really tie in deeply from the brain to computer, I just, no, I don't agree with Elon Musk. I don't think that's even, that's not for our generations, not even for the century. So just in hopes of getting you to dream, you've mentioned Kolmogorov and Turing might pop up, do you think that there might be breakthroughs that will get you to sit back in five, 10 years and say, wow? Oh, I'm sure there will be, but I don't think that there'll be demos that impress me. I don't think that having a computer call a restaurant and pretend to be a human is a breakthrough. Right. And people, you know, some people present it as such. It's imitating human intelligence. It's even putting coughs in the thing to make a bit of a PR stunt. And so fine that the world runs on those things too. And I don't want to diminish all the hard work and engineering that goes behind things like that and the ultimate value to the human race. But that's not scientific understanding. And I know the people that work on these things, they are after scientific understanding. In the meantime, they've got to kind of, you know, the trains got to run and they got mouths to feed and they got things to do and there's nothing wrong with all that. I would call that though, just engineering. And I want to distinguish that between an engineering field, like electrical engineering and chemical engineering that originally emerged, that had real principles and you really know what you're doing and you had a little scientific understanding, maybe not even complete. So it became more predictable and it really gave value to human life because it was understood. And so we don't want to muddle too much these waters of, you know, what we're able to do versus what we really can't do in a way that's going to impress the next. So I don't need to be wowed, but I think that someone comes along in 20 years, a younger person who's absorbed all the technology and for them to be wowed, I think they have to be more deeply impressed. A young Kolmogorov would not be wowed by some of the stunts that you see right now coming from the big companies. The demos, but do you think the breakthroughs from Kolmogorov would be, and give this question a chance, do you think there'll be in the scientific fundamental principles arena or do you think it's possible to have fundamental breakthroughs in engineering? Meaning, you know, I would say some of the things that Elon Musk is working with SpaceX and then others sort of trying to revolutionize the fundamentals of engineering, of manufacturing, of saying, here's a problem we know how to do a demo of and actually taking it to scale. Yeah. So there's going to be all kinds of breakthroughs. I just don't like that terminology. I'm a scientist and I work on things day in and day out and things move along and eventually you say, wow, something happened, but I don't like that language very much. Also I don't like to prize theoretical breakthroughs over practical ones. I tend to be more of a theoretician and I think there's lots to do in that arena right now. And so I wouldn't point to the Kolmogorovs, I might point to the Edisons of the era and maybe Musk is a bit more like that. But you know, Musk, God bless him, also will say things about AI that he knows very little about and he leads people astray when he talks about things he doesn't know anything about. Trying to program a computer to understand natural language, to be involved in a dialogue we're having right now, that ain't going to happen in our lifetime. You could fake it, you can mimic, sort of take old sentences that humans use and retread them, but the deep understanding of language, no, it's not going to happen. And so from that, I hope you can perceive that the deeper, yet deeper kind of aspects and intelligence are not going to happen. Now will there be breakthroughs? No, I think that Google was a breakthrough, I think Amazon is a breakthrough, you know, I think Uber is a breakthrough, you know, that bring value to human beings at scale in new, brand new ways based on data flows and so on. A lot of these things are slightly broken because there's not kind of an engineering field that takes economic value in context of data and, you know, planetary scale and worries about all the externalities, the privacy, you know, we don't have that field so we don't think these things through very well. I see that as emerging and that will be, you know, looking back from 100 years, that will be a constituted breakthrough in this era, just like electrical engineering was a breakthrough in the early part of the last century and chemical engineering was a breakthrough. So the scale, the markets that you talk about and we'll get to will be seen as sort of breakthrough and we're in the very early days of really doing interesting stuff there and we'll get to that, but just taking a quick step back, can you give, kind of throw off the historian hat. I mean, you briefly said that the history of AI kind of mimics the history of chemical engineering, but... I keep saying machine learning. You keep wanting to say AI, just to let you know, I don't, you know, I resist that. I don't think this is about AI really was John McCarthy as almost a philosopher saying, wouldn't it be cool if we could put thought in a computer? If we could mimic the human capability to think or put intelligence in, in some sense into a computer. That's an interesting philosophical question and he wanted to make it more than philosophy. He wanted to actually write down a logical formula and algorithms that would do that. And that is a perfectly valid, reasonable thing to do. That's not what's happening in this era. So the reason I keep saying AI actually, and I'd love to hear what you think about it. Machine learning has a very particular set of methods and tools. Maybe your version of it is that mine doesn't, it's very, very open. It does optimization, it does sampling, it does... So systems that learn is what machine learning is. Systems that learn and make decisions. And make decisions. So it's not just pattern recognition and, you know, finding patterns, it's all about making decisions in real worlds and having close feedback loops. So something like symbolic AI, expert systems, reasoning systems, knowledge based representation, all of those kinds of things, search, does that neighbor fit into what you think of as machine learning? So I don't even like the word machine learning, I think that what the field you're talking about is all about making large collections of decisions under uncertainty by large collections of entities. Right? And there are principles for that, at that scale. You don't have to say the principles are for a single entity that's making decisions, single agent or single human. It really immediately goes to the network of decisions. Is a good word for that or no? No, there's no good words for any of this. That's kind of part of the problem. So we can continue the conversation to use AI for all that. I just want to kind of raise the flag here that this is not about, we don't know what intelligence is and real intelligence. We don't know much about abstraction and reasoning at the level of humans. We don't have a clue. We're not trying to build that because we don't have a clue. Eventually it may emerge. They'll make, I don't know if there'll be breakthroughs, but eventually we'll start to get glimmers of that. It's not what's happening right now. Okay. We're taking data. We're trying to make good decisions based on that. We're trying to scale. We're trying to economically viably, we're trying to build markets. We're trying to keep value at that scale and aspects of this will look intelligent. Computers were so dumb before, they will seem more intelligent. We will use that buzzword of intelligence so we can use it in that sense. So machine learning, you can scope it narrowly as just learning from data and pattern recognition. But when I talk about these topics, maybe data science is another word you could throw in the mix, it really is important that the decisions are as part of it. It's consequential decisions in the real world. Am I going to have a medical operation? Am I going to drive down the street? Things where there's scarcity, things that impact other human beings or other environments and so on. How do I do that based on data? How do I do that adaptively? How do I use computers to help those kinds of things go forward? Whatever you want to call that. So let's call it AI. Let's agree to call it AI, but let's not say that the goal of that is intelligence. The goal of that is really good working systems at planetary scale that we've never seen before. So reclaim the word AI from the Dartmouth conference from many decades ago of the dream of humans. I don't want to reclaim it. I want a new word. I think it was a bad choice. I mean, if you read one of my little things, the history was basically that McCarthy needed a new name because cybernetics already existed and he didn't like, no one really liked Norbert Wiener. Norbert Wiener was kind of an island to himself and he felt that he had encompassed all this and in some sense he did. You look at the language of cybernetics, it was everything we're talking about. It was control theory and signal processing and some notions of intelligence and closed feedback loops and data. It was all there. It's just not a word that lived on partly because of the maybe the personalities. But McCarthy needed a new word to say, I'm different from you. I'm not part of your show. I got my own. Invented this word and again, thinking forward about the movies that would be made about it, it was a great choice. But thinking forward about creating a sober academic and real world discipline, it was a terrible choice because it led to promises that are not true that we understand. We understand artificial perhaps, but we don't understand intelligence. It's a small tangent because you're one of the great personalities of machine learning, whatever the heck you call the field. Do you think science progresses by personalities or by the fundamental principles and theories and research that's outside of personalities? Both. And I wouldn't say there should be one kind of personality. I have mine and I have my preferences and I have a kind of network around me that feeds me and some of them agree with me and some of them disagree, but all kinds of personalities are needed. Right now, I think the personality that it's a little too exuberant, a little bit too ready to promise the moon is a little bit too much in ascendance. And I do think that there's some good to that. It certainly attracts lots of young people to our field, but a lot of those people come in with strong misconceptions and they have to then unlearn those and then find something to do. And so I think there's just got to be some multiple voices and I wasn't hearing enough of the more sober voice. So as a continuation of a fun tangent and speaking of vibrant personalities, what would Yeah. And you think technically speaking, it's possible to help. I don't know the answers, but it's a, it's a, it's a less anonymity, a little more locality, you know, worlds that you kind of enter in and you trust the people there in those worlds so that when you start having a discussion, you know, not only is that people are not going to hurt you, but it's not going to be a total waste of your time because there's a lot of wasting of time that, you know, a lot of us, I pulled out of Facebook early on cause it was clearly going to waste a lot of my time even though there was some value. And so, yeah, worlds that are somehow you enter in and you know what you're getting and it's kind of appeals to you and you might, new things might happen, but you kind of have some, some trust in that world. And there's some deep, interesting, complex psychological aspects around anonymity, how that changes human behavior that's quite dark. Quite dark. Yeah. I think a lot of us are, especially those of us who really loved the advent of technology. I love social networks when they came out. I was just, I didn't see any negatives there at all. But then I started seeing comment sections. I think it was maybe, you know, with the CNN or something. And I started to go, wow, this, this darkness I just did not know about and, and our technology is now amplifying it. So sorry for the big philosophical question, but on that topic, do you think human beings, cause you've also, out of all things, had a foot in psychology too, the, do you think human beings are fundamentally good? Like all of us have good intent that could be mind or is it depending on context and environment, everybody could be evil. So my answer is fundamentally good. But fundamentally limited. All of us have very, you know, blinkers on. We don't see the other person's pain that easily. We don't see the other person's point of view that easily. We're very much in our own head, in our own world. And on my good days, I think the technology could open us up to, you know, more perspectives and more less blinkered and more understanding, you know, a lot of wars in human history happened because of just ignorance. They didn't, they, they thought the other person was doing this while their person wasn't doing this. And we have a huge amounts of that. But in my lifetime, I've not seen technology really help in that way yet. And I do, I do, I do believe in that, but you know, no, I think fundamentally humans are good. The people suffer, people have grievances because you have grudges and those things cause them to do things they probably wouldn't want. They regret it often. So no, I, I think it's a, you know, part of the progress of technology is to indeed allow it to be a little easier to be the real good person you actually are. Well, but do you think individual human life or society could be modeled as an optimization problem? Not the way I think typically, I mean, that's, you're talking about one of the most complex phenomenon in the whole, you know, in all of which the individual human life or society as a whole. Both, both. I mean, individual human life is amazingly complex. And so you know, optimization is kind of just one branch of mathematics that talks about certain kinds of things. And it just feels way too limited for the complexity of such things. What properties of optimization problems do you think, so do you think most interesting problems that could be solved through optimization, what kind of properties does that surface have non convexity, convexity, linearity, all those kinds of things, saddle points? Well, so optimization is just one piece of mathematics. You know, there's like, you just, even in our era, we're aware that say sampling is coming up, examples of something coming up with a distribution. What's optimization? What's sampling? Well, they, you can, if you're a kind of a certain kind of mathematician, you can try to blend them and make them seem to be sort of the same thing. But optimization is roughly speaking, trying to find a point that, a single point that is the optimum of a criterion function of some kind. And sampling is trying to, from that same surface, treat that as a distribution or density and find points that have high density. So I want the entire distribution in a sampling paradigm and I want the, you know, the single point, that's the best point in the optimization paradigm. Now if you were optimizing in the space of probability measures, the output of that could be a whole probability distribution. So you can start to make these things the same. But in mathematics, if you go too high up that kind of abstraction hierarchy, you start to lose the, you know, the ability to do the interesting theorems. So you kind of don't try that. You don't try to overly over abstract. So as a small tangent, what kind of worldview do you find more appealing? One that is deterministic or stochastic? Well, that's easy. I mean, I'm a statistician. You know, the world is highly stochastic. I don't know what's going to happen in the next five minutes, right? Because what you're going to ask, what we're going to do, what I'll say. Due to the uncertainty. Due to the... Massive uncertainty. Yeah. You know, massive uncertainty. And so the best I can do is have come rough sense or probability distribution on things and somehow use that in my reasoning about what to do now. So how does the distributed at scale when you have multi agent systems look like? So optimization can optimize sort of, it makes a lot more sense, sort of at least from my from robotics perspective, for a single robot, for a single agent, trying to optimize some objective function. When you start to enter the real world, this game theoretic concept starts popping up. That's how do you see optimization in this? Because you've talked about markets in a scale. What does that look like? Do you see it as optimization? Do you see it as sampling? Do you see like, how should you mark? These all blend together. And a system designer thinking about how to build an incentivized system will have a blend of all these things. So, you know, a particle in a potential well is optimizing a functional called a Lagrangian, right? The particle doesn't know that. There's no algorithm running that does that. It just happens. And so it's a description mathematically of something that helps us understand as analysts what's happening, right? And so the same thing will happen when we talk about, you know, mixtures of humans and computers and markets and so on and so forth, there'll be certain principles that allow us to understand what's happening, whether or not the actual algorithms are being used by any sense is not clear. Now at some point, I may have set up a multi agent or market kind of system. And I'm now thinking about an individual agent in that system. And they're asked to do some task and they're incentivized in some way, they get certain signals and they have some utility. What they will do at that point is they just won't know the answer, they may have to optimize to find an answer. Okay, so an artist could be embedded inside of an overall market. You know, and game theory is very, very broad. It is often studied very narrowly for certain kinds of problems. But it's roughly speaking, this is just the, I don't know what you're going to do. So I kind of anticipate that a little bit, and you anticipate what I'm anticipating. And we kind of go back and forth in our own minds. We run kind of thought experiments. You've talked about this interesting point in terms of game theory, you know, most optimization problems really hate saddle points, maybe you can describe what saddle points are. But I've heard you kind of mentioned that there's a there's a branch of optimization that you could try to explicitly look for saddle points as a good thing. Oh, not optimization. That's just game theory that that so there's all kinds of different equilibria in game theory. And some of them are highly explanatory behavior. They're not attempting to be algorithmic. They're just trying to say, if you happen to be at this equilibrium, you would see certain kind of behavior. And we see that in real life. That's what an economist wants to do, especially behavioral economists in continuous differential game theory, you're in continuous spaces, a some of the simplest equilibria are saddle points and Nash equilibrium as a saddle point. It's a special kind of saddle point. So classically, in game theory, you were trying to find Nash equilibria and an algorithmic game theory, you're trying to find algorithms that would find them. And so you're trying to find saddle points. I mean, so that's literally what you're trying to do. But you know, any economist knows that Nash equilibria have their limitations. They are definitely not that explanatory in many situations. They're not what you really want. There's other kind of equilibria. And there's names associated with these because they came from history with certain people working on them, but there will be new ones emerging. So you know, one example is a Stackelberg equilibrium. So you know, Nash, you and I are both playing this game against each other or for each other, maybe it's cooperative, and we're both going to think it through and then we're going to decide and we're going to do our thing simultaneously. You know, in a Stackelberg, no, I'm going to be the first mover. I'm going to make a move. You're going to look at my move and then you're going to make yours. Now since I know you're going to look at my move, I anticipate what you're going to do. And so I don't do something stupid, but then I know that you are also anticipating me. So we're kind of going back and forth on why, but there is then a first mover thing. And so those are different equilibria, right? And so just mathematically, yeah, these things have certain topologies and certain shapes that are like, what's it, algorithmically or dynamically, how do you move towards them? How do you move away from things? You know, so some of these questions have answers, they've been studied, others do not. And especially if it becomes stochastic, especially if there's large numbers of decentralized things, there's just, you know, young people get in this field who kind of think it's all done because we have, you know, TensorFlow. Well, no, these are all open problems and they're really important and interesting. And it's about strategic settings. How do I collect data? Suppose I don't know what you're going to do because I don't know you very well, right? Well, I got to collect data about you. So maybe I want to push you into a part of the space where I don't know much about you so I can get data. Cause, and then later I'll realize that you'll never, you'll never go there because of the way the game is set up. You know, that's part of the overall, you know, data analysis context is that. Even the game of poker is fascinating space, whenever there's any uncertainty, a lack of information, it's a super exciting space. Just to linger on optimization for a second. So when we look at deep learning, it's essentially minimization of a complicated loss function. So is there something insightful or hopeful that you see in the kinds of function surface that loss functions, the deep learning and in the real world is trying to optimize over? Is there something interesting as it's just the usual kind of problems of optimization? I think from an optimization point of view, that surface, first of all, it's pretty smooth. And secondly, if there's over, if it's over parameterized, there's kind of lots of paths down to reasonable Optima. And so kind of the getting downhill to the, to an optimum is viewed as not as hard as you might've expected in high dimensions. The fact that some Optima tend to be really good ones and others not so good. And you tend to, it's not, sometimes you find the good ones is sort of still needs explanation. Yeah. But, but the particular surface is coming from the particular generation of neural nets. I kind of suspect those will, those will change in 10 years. It will not be exactly those surfaces. There'll be some others that are an optimization theory will help contribute to why other surfaces or why other algorithms. Years of arithmetic operations with a little bit of nonlinearity, that's not, that didn't come from neuroscience per se. I mean, maybe in the minds of some of the people working on it, they were thinking about brains, but they were arithmetic circuits in all kinds of fields, computer science control theory and so on. And that layers of these could transform things in certain ways. And that if it's smooth, maybe you could find parameter values is a sort of big discovery that it's working, it's able to work at this scale. But I don't think that we're stuck with that and we're, we're certainly not stuck with that cause we're understanding the brain. So in terms of on the algorithm side sort of gradient descent, do you think we're stuck with gradient descent as a variance of it? What variance do you find interesting or do you think there'll be something else invented that is able to walk all over these optimization spaces in more interesting ways? So there's a co design of the surface and the, or the architecture and the algorithm. So if you just ask if we stay with the kind of architectures that we have now and not just neural nets, but you know, phase retrieval architectures or matrix completion architectures and so on. You know, I think we've kind of come to a place where yeah, a stochastic gradient algorithms are dominant and there are versions that are a little better than others. They have more guarantees, they're more robust and so on. And there's ongoing research to kind of figure out which is the best arm for which situation. But I think that that'll start to co evolve, that that'll put pressure on the actual architecture. And so we shouldn't do it in this particular way, we should do it in a different way because this other algorithm is now available if you do it in a different way. So that I can't really anticipate that co evolution process, but you know, gradients are amazing mathematical objects. They have a lot of people who start to study them more deeply mathematically are kind of shocked about what they are and what they can do. Think about it this way, suppose that I tell you if you move along the x axis, you go uphill in some objective by three units, whereas if you move along the y axis, you go uphill by seven units, right? Now I'm going to only allow you to move a certain unit distance, right? What are you going to do? Well, most people will say that I'm going to go along the y axis, I'm getting the biggest bang for my buck, you know, and my buck is only one unit, so I'm going to put all of it in the y axis, right? And why should I even take any of my strength, my step size and put any of it in the x axis because I'm getting less bang for my buck. That seems like a completely clear argument and it's wrong because the gradient direction is not to go along the y axis, it's to take a little bit of the x axis. And to understand that, you have to know some math and so even a trivial so called operator like gradient is not trivial and so, you know, exploiting its properties is still very important. Now we know that just pervading descent has got all kinds of problems, it gets stuck in many ways and it had never, you know, good dimension dependence and so on. So my own line of work recently has been about what kinds of stochasticity, how can we get dimension dependence, how can we do the theory of that and we've come up pretty favorable results with certain kinds of stochasticity. We have sufficient conditions generally. We know if you do this, we will give you a good guarantee. We don't have necessary conditions that it must be done a certain way in general. So stochasticity, how much randomness to inject into the walking along the gradient? And what kind of randomness? Why is randomness good in this process? Why is stochasticity good? Yeah, so I can give you simple answers but in some sense again, it's kind of amazing. Stochasticity just, you know, particular features of a surface that could have hurt you if you were doing one thing deterministically won't hurt you because by chance, there's very little chance that you would get hurt. So here stochasticity, it just kind of saves you from some of the particular features of surfaces. In fact, if you think about surfaces that are discontinuous in our first derivative, like an absolute value function, you will go down and hit that point where there's nondifferentiability. And if you're running a deterministic algorithm at that point, you can really do something bad. Whereas stochasticity just means it's pretty unlikely that's going to happen, that you're going to hit that point. So it's again, nontrivial to analyze but especially in higher dimensions, also stochasticity, our intuition isn't very good about it but it has properties that kind of are very appealing in high dimensions for a lot of large number of reasons. So it's all part of the mathematics to kind of, that's what's fun to work in the field is that you get to try to understand this mathematics. But long story short, you know, partly empirically, it was discovered stochastic gradient is very effective and theory kind of followed, I'd say, that but I don't see that we're getting clearly out of that. What's the most beautiful, mysterious, a profound idea to you in optimization? I don't know the most. But let me just say that Nesterov's work on Nesterov acceleration to me is pretty surprising and pretty deep. Can you elaborate? Well Nesterov acceleration is just that, suppose that we are going to use gradients to move around in a space. For the reasons I've alluded to, they're nice directions to move. And suppose that I tell you that you're only allowed to use gradients, you're not going to be allowed to use this local person that can only sense kind of the change in the surface. But I'm going to give you kind of a computer that's able to store all your previous gradients. And so you start to learn some something about the surface. And I'm going to restrict you to maybe move in the direction of like a linear span of all the gradients. So you can't kind of just move in some arbitrary direction, right? So now we have a well defined mathematical complexity model. There's certain classes of algorithms that can do that and others that can't. And we can ask for certain kinds of surfaces, how fast can you get down to the optimum? So there's answers to these. So for a smooth convex function, there's an answer, which is one over the number of steps squared. You will be within a ball of that size after k steps. Gradient descent in particular has a slower rate, it's one over k. So you could ask, is gradient descent actually, even though we know it's a good algorithm, is it the best algorithm? And the answer is no. Well, not clear yet, because one over k squared is a lower bound. That's probably the best you can do. Gradient is one over k, but is there something better? And so I think as a surprise to most, Nesterov discovered a new algorithm that has got two pieces to it. It's two gradients and puts those together in a certain kind of obscure way. And the thing doesn't even move downhill all the time. It sometimes goes back uphill. And if you're a physicist, that kind of makes some sense. You're building up some momentum and that is kind of the right intuition, but that intuition is not enough to understand kind of how to do it and why it works. But it does. It achieves one over k squared and it has a mathematical structure and it's still kind of to this day, a lot of us are writing papers and trying to explore that and understand it. So there are lots of cool ideas and optimization, but just kind of using gradients, I think is number one that goes back, you know, 150 years. And then Nesterov, I think has made a major contribution with this idea. So like you said, gradients themselves are in some sense, mysterious. They're not as trivial as... Not as trivial. Coordinate descent is more of a trivial one. You just pick one of the coordinates. That's how we think. That's how our human mind thinks. That's how our human minds think. And gradients are not that easy for our human mind to grapple with. An absurd question, but what is statistics? So here it's a little bit, it's somewhere between math and science and technology. It's somewhere in that convex hole. So it's a set of principles that allow you to make inferences that have got some reason to be believed and also principles that allow you to make decisions where you can have some reason to believe you're not going to make errors. So all of that requires some assumptions about what do you mean by an error? What do you mean by the probabilities? But after you start making some of those assumptions, you're led to conclusions that, yes, I can guarantee that if you do this in this way, your probability of making an error will be small. Your probability of continuing to not make errors over time will be small. And the probability that you found something that's real will be small, will be high. So decision making is a big part of that. Decision making is a big part. Yeah. So statistics, short history was that, it goes back as a formal discipline, 250 years or so. It was called inverse probability because around that era, probability was developed sort of especially to explain gambling situations. Of course, interesting. So you would say, well, given the state of nature is this, there's a certain roulette board that has a certain mechanism and what kind of outcomes do I expect to see? And especially if I do things long amounts of time, what outcomes will I see? And the physicists started to pay attention to this. And then people said, well, let's turn the problem around. What if I saw certain outcomes, could I infer what the underlying mechanism was? That's an inverse problem. And in fact, for quite a while, statistics was called inverse probability. That was the name of the field. And I believe that it was Laplace who was working in Napoleon's government who needed to do a census of France, learn about the people there. So he went and gathered data and he analyzed that data to determine policy and said, well, let's call this field that does this kind of thing statistics because the word state is in there. In French, that's etat, but it's the study of data for the state. So anyway, that caught on and it's been called statistics ever since. But by the time it got formalized, it was sort of in the 30s. And around that time, there was game theory and decision theory developed nearby. People in that era didn't think of themselves as either computer science or statistics or control or econ. They were all the above. And so Von Neumann is developing game theory, but also thinking of that as decision theory. Wald is an econometrician developing decision theory and then turning that into statistics. And so it's all about, here's not just data and you analyze it, here's a loss function. Here's what you care about. Here's the question you're trying to ask. Here is a probability model and here's the risk you will face if you make certain decisions. And to this day, in most advanced statistical curricula, you teach decision theory as the starting point and then it branches out into the two branches of Bayesian and frequentist. But that's all about decisions. In statistics, what is the most beautiful, mysterious, maybe surprising idea that you've come across? Yeah, good question. I mean, there's a bunch of surprising ones. There's something that's way too technical for this thing, but something called James Stein estimation, which is kind of surprising and really takes time to wrap your head around. Can you try to maybe... I think I don't want to even want to try. Let me just say a colleague at Steven Stigler at University of Chicago wrote a really beautiful paper on James Stein estimation, which helps to... It's views a paradox. It kind of defeats the mind's attempts to understand it, but you can and Steve has a nice perspective on that. So one of the troubles with statistics is that it's like in physics that are in quantum physics, you have multiple interpretations. There's a wave and particle duality in physics and you get used to that over time, but it still kind of haunts you that you don't really quite understand the relationship. The electron's a wave and electron's a particle. Well the same thing happens here. There's Bayesian ways of thinking and frequentist, and they are different. They sometimes become sort of the same in practice, but they are physically different. And then in some practice, they are not the same at all. They give you rather different answers. And so it is very much like wave and particle duality, and that is something that you have to kind of get used to in the field. Can you define Bayesian and frequentist? Yeah in decision theory you can make, I have a video that people could see. It's called are you a Bayesian or a frequentist and kind of help try to make it really clear. It comes from decision theory. So you know, decision theory, you're talking about loss functions, which are a function of data X and parameter theta. They're a function of two arguments. Okay. Neither one of those arguments is known. You don't know the data a priori. It's random and the parameters unknown. All right. So you have a function of two things you don't know, and you're trying to say, I want that function to be small. I want small loss, right? Well what are you going to do? So you sort of say, well, I'm going to average over these quantities or maximize over them or something so that, you know, I turn that uncertainty into something certain. So you could look at the first argument and average over it, or you could look at the second argument and average over it. That's Bayesian and frequentist. So the frequentist says, I'm going to look at the X, the data, and I'm going to take that as random and I'm going to average over the distribution. So I take the expectation loss under X. Theta is held fixed, right? That's called the risk. And so it's looking at other, all the data sets you could get, right? And say, how well will a certain procedure do under all those data sets? That's called a frequentist guarantee, right? So I think it is very appropriate when like you're building a piece of software and you're shipping it out there and people are using it on all kinds of data sets. You want to have a stamp, a guarantee on it that as people run it on many, many data sets that you never even thought about that 95% of the time it will do the right thing. Perfectly reasonable. The Bayesian perspective says, well, no, I'm going to look at the other argument of the loss function, the theta part, okay? That's unknown and I'm uncertain about it. So I could have my own personal probability for what it is, you know, how many tall people are there out there? I'm trying to infer the average height of the population while I have an idea roughly what the height is. So I'm going to average over the theta. So now that loss function as only now, again, one argument's gone, now it's a function of X and that's what a Bayesian does is they say, well, let's just focus on the particular X we got, the data set we got, we condition on that. Conditional on the X, I say something about my loss. That's a Bayesian approach to things. And the Bayesian will argue that it's not relevant to look at all the other data sets you could have gotten and average over them, the frequentist approach. It's really only the data sets you got, right? And I do agree with that, especially in situations where you're working with a scientist, you can learn a lot about the domain and you're really only focused on certain kinds of data and you gathered your data and you make inferences. I don't agree with it though, that, you know, in the sense that there are needs for frequentist guarantees, you're writing software, people are using it out there, you want to say something. So these two things have to got to fight each other a little bit, but they have to blend. So long story short, there's a set of ideas that are right in the middle that are called empirical Bayes. And empirical Bayes sort of starts with the Bayesian framework. It's kind of arguably philosophically more, you know, reasonable and kosher. Write down a bunch of the math that kind of flows from that, and then realize there's a bunch of things you don't know because it's the real world and you don't know everything. So you're uncertain about certain quantities. At that point, ask, is there a reasonable way to plug in an estimate for those things? Okay. And in some cases, there's quite a reasonable thing to do, to plug in, there's a natural thing you can observe in the world that you can plug in and then do a little bit more mathematics and assure yourself it's really good. So based on math or based on human expertise, what's, what, what are good? Oh, they're both going in. The Bayesian framework allows you to put a lot of human expertise in, but the math kind of guides you along that path and then kind of reassures you the end, you could put that stamp of approval under certain assumptions, this thing will work. So you asked the question, what's my favorite, you know, or what's the most surprising, nice idea. So one that is more accessible is something called false discovery rate, which is, you know, you're making not just one hypothesis test or making one decision, you're making a whole bag of them. And in that bag of decisions, you look at the ones where you made a discovery, you announced that something interesting had happened. All right. That's going to be some subset of your big bag. In the ones you made a discovery, which subset of those are bad? Or false, false discoveries. You'd like the fraction of your false discoveries among your discoveries to be small. That's a different criterion than accuracy or precision or recall or sensitivity and specificity. It's a different quantity. Those latter ones are almost all of them have more of a frequentist flavor. They say, given the truth is that the null hypothesis is true. Here's what accuracy I would get, or given that the alternative is true, here's what I would get. So it's kind of going forward from the state of nature to the data. The Bayesian goes the other direction from the data back to the state of nature. And that's actually what false discovery rate is. It says, given you made a discovery, okay, that's conditioned on your data. What's the probability of the hypothesis? It's going the other direction. And so the classical frequency look at that, well, I can't know that there's some priors needed in that. And the empirical Bayesian goes ahead and plows forward and starts writing down these formulas and realizes at some point, some of those things can actually be estimated in a reasonable way. And so it's kind of, it's a beautiful set of ideas. So I, this kind of line of argument has come out. It's not certainly mine, but it sort of came out from Robbins around 1960. Brad Efron has written beautifully about this in various papers and books. And the FDR is, you know, Benjamin in Israel, John Story did this Bayesian interpretation and so on. And he used to absorb these things over the years and find it a very healthy way to think about statistics. Let me ask you about intelligence to jump slightly back out into philosophy, perhaps. You said that maybe you can elaborate, but you said that defining just even the question of what is intelligence is a very difficult question. Is it a useful question? Do you think we'll one day understand the fundamentals of human intelligence and what it means, you know, have good benchmarks for general intelligence that we put before our machines? So I don't work on these topics so much that you're really asking the question for a psychologist really. And I studied some, but I don't consider myself at least an expert at this point. You know, a psychologist aims to understand human intelligence, right? And I think many psychologists I know are fairly humble about this. They might try to understand how a baby understands, you know, whether something's a solid or liquid or whether something's hidden or not. And maybe how a child starts to learn the meaning of certain words, what's a verb, what's a noun and also, you know, slowly but surely trying to figure out things. But humans ability to take a really complicated environment, reason about it, abstract about it, find the right abstractions, communicate about it, interact and so on is just, you know, really staggeringly rich and complicated. And so, you know, I think in all humility, we don't think we're kind of aiming for that in the near future. A certain psychologist doing experiments with babies in the lab or with people talking has a much more limited aspiration. And you know, Kahneman and Tversky would look at our reasoning patterns and they're not deeply understanding all the how we do our reasoning, but they're sort of saying, hey, here's some oddities about the reasoning and some things you should think about it. But also, as I emphasize in some things I've been writing about, you know, AI, the revolution hasn't happened yet. Yeah. Great blog post. I've been emphasizing that, you know, if you step back and look at intelligent systems of any kind and whatever you mean by intelligence, it's not just the humans or the animals or, you know, the plants or whatever, you know, so a market that brings goods into a city, you know, food to restaurants or something every day is a system. It's a decentralized set of decisions. Looking at it from far enough away, it's just like a collection of neurons. Every neuron is making its own little decisions, presumably in some way. And if you step back enough, every little part of an economic system is making all of its decisions. And just like with the brain, who knows what an individual neuron does and what the overall goal is, right? But something happens at some aggregate level, same thing with the economy. People eat in a city and it's robust. It works at all scales, small villages to big cities. It's been working for thousands of years. It works rain or shine, so it's adaptive. So all the kind of, you know, those are adjectives one tends to apply to intelligent systems. Robust, adaptive, you know, you don't need to keep adjusting it, self healing, whatever. Plus not perfect. You know, intelligences are never perfect and markets are not perfect. But I do not believe in this era that you cannot, that you can say, well, our computers are, our humans are smart, but you know, no markets are not, more markets are. So they are intelligent. Now we humans didn't evolve to be markets. We've been participating in them, right? But we are not ourselves a market per se. The neurons could be viewed as the market. There's economic, you know, neuroscience kind of perspective. That's interesting to pursue all that. The point though is, is that if you were to study humans and really be the world's best psychologist studied for thousands of years and come up with the theory of human intelligence, you might have never discovered principles of markets, you know, supply demand curves and you know, matching and auctions and all that. Those are real principles and they lead to a form of intelligence that's not maybe human intelligence. It's arguably another kind of intelligence. There probably are third kinds of intelligence or fourth that none of us are really thinking too much about right now. So if you really, and then all of those are relevant to computer systems in the future. Certainly the market one is relevant right now. Whereas the understanding of human intelligence is not so clear that it's relevant right now. Probably not. So if you want general intelligence, whatever one means by that, or, you know, understanding intelligence in a deep sense and all that, it is definitely has to be not just human intelligence. It's gotta be this broader thing. And that's not a mystery. Markets are intelligent. So, you know, it's definitely not just a philosophical stance to say we've got to move beyond intelligence. That sounds ridiculous. Yeah. But it's not. And in that blog post, you define different kinds of like intelligent infrastructure, AI, which I really like is some of the concepts you've just been describing. Do you see ourselves, if we see earth, human civilization as a single organism, do you think the intelligence of that organism, when you think from the perspective of markets and intelligence infrastructure is increasing, is it increasing linearly? Is it increasing exponentially? What do you think the future of that intelligence? Yeah, I don't know. I don't tend to think, I don't tend to answer questions like that because you know, that's science fiction. I'm hoping to catch you off guard. Well again, because you said it's so far in the future, it's fun to ask and you'll probably, you know, like you said, predicting the future is really nearly impossible. But say as an axiom, one day we create a human level, a superhuman level intelligent, not the scale of markets, but the scale of an individual. What do you think it is, what do you think it would take to do that? Or maybe to ask another question is how would that system be different than the biological human beings that we see around us today? Is it possible to say anything interesting to that question or is it just a stupid question? It's not a stupid question, but it's science fiction. Science fiction. And so I'm totally happy to read science fiction and think about it from time in my own life. I loved, there was this like brain in a vat kind of, you know, little thing that people were talking about when I was a student, I remember, you know, imagine that, you know, between your brain and your body, there's a, you know, there's a bunch of wires, right? And suppose that every one of them was replaced with a literal wire. And then suppose that wire was turned in actually a little wireless, you know, there's a receiver and sender. So the brain has got all the senders and receiver, you know, on all of its exiting, you know, axons and all the dendrites down to the body have replaced with senders and receivers. Now you could move the body off somewhere and put the brain in a vat, right? And then you could do things like start killing off those senders and receivers one by one. And after you've killed off all of them, where is that person? You know, they thought they were out in the body walking around the world and they moved on. So those are science fiction things. Those are fun to think about. It's just intriguing about where is, what is thought, where is it and all that. And I think every 18 year old should take philosophy classes and think about these things. And I think that everyone should think about what could happen in society that's kind of bad and all that. But I really don't think that's the right thing for most of us that are my age group to be doing and thinking about. I really think that we have so many more present, you know, first challenges and dangers and real things to build and all that such that, you know, spending too much time on science fiction, at least in public for like this, I think is not what we should be doing. Maybe over beers in private. That's right. Well, I'm not going to broadcast where I have beers because this is going to go on Facebook and I don't want a lot of people showing up there. But yeah, I'll, I love Facebook, Twitter, Amazon, YouTube. I have I'm optimistic and hopeful, but maybe, maybe I don't have grounds for such optimism and hope. But let me ask, you've mentored some of the brightest sort of some of the seminal figures in the field. Can you give advice to people who are undergraduates today? What does it take to take, you know, advice on their journey if they're interested in machine learning and in the ideas of markets from economics and psychology and all the kinds of things that you've exploring? What steps should they take on that journey? Well, yeah, first of all, the door is open and second, it's a journey. I like your language there. It is not that you're so brilliant and you have great, brilliant ideas and therefore that's just, you know, that's how you have success or that's how you enter into the field. It's that you apprentice yourself, you spend a lot of time, you work on hard things, you try and pull back and you be as broad as you can, you talk to lots of people. And it's like entering in any kind of a creative community. There's years that are needed and human connections are critical to it. So, you know, I think about, you know, being a musician or being an artist or something, you don't just, you know, immediately from day one, you know, you're a genius and therefore you do it. No, you, you know, practice really, really hard on basics and you be humble about where you are and then, and you realize you'll never be an expert on everything. So you kind of pick and there's a lot of randomness and a lot of kind of luck, but luck just kind of picks out which branch of the tree you go down, but you'll go down some branch. So yeah, it's a community. So the graduate school is, I still think is one of the wonderful phenomena that we have in our, in our world. It's very much about apprenticeship with an advisor. It's very much about a group of people you belong to. It's a four or five year process. So it's plenty of time to start from kind of nothing to come up to something, you know, more, more expertise, and then to start to have your own creativity start to flower, even surprising your own self. And it's a very cooperative endeavor. I think a lot of people think of science as highly competitive and I think in some other fields it might be more so. Here it's way more cooperative than you might imagine. And people are always teaching each other something and people are always more than happy to be clear that, so I feel I'm an expert on certain kinds of things, but I'm very much not expert on lots of other things and a lot of them are relevant and a lot of them are, I should know, but should in some society, you know, you don't. So I'm always willing to reveal my ignorance to people around me so they can teach me things. And I think a lot of us feel that way about our field. So it's very cooperative. I might add it's also very international because it's so cooperative. We see no barriers. And so that the nationalism that you see, especially in the current era and everything is just at odds with the way that most of us think about what we're doing here, where this is a human endeavor and we cooperate and are very much trying to do it together for the, you know, the benefit of everybody. So last question, where and how and why did you learn French and which language is more beautiful English or French? Great question. So first of all, I think Italian is actually more beautiful than French and English. And I also speak that. So I'm married to an Italian and I have kids and we speak Italian. Anyway, all kidding aside, every language allows you to express things a bit differently. And it is one of the great fun things to do in life is to explore those things. So in fact, when I kids or teens or college students ask me what they study, I say, well, do what your heart, where your heart is, certainly do a lot of math. Math is good for everybody, but do some poetry and do some history and do some language too. You know, throughout your life, you'll want to be a thinking person. You'll want to have done that. For me, French I learned when I was, I'd say a late teen, I was living in the middle of the country in Kansas and not much was going on in Kansas with all due respect to Kansas. And so my parents happened to have some French books on the shelf and just in my boredom, I pulled them down and I found this is fun. And I kind of learned the language by reading. And when I first heard it spoken, I had no idea what was being spoken, but I realized I had somehow knew it from some previous life and so I made the connection. But then I traveled and just I love to go beyond my own barriers and my own comfort or whatever. And I found myself on trains in France next to say older people who had lived a whole life of their own. And the ability to communicate with them was special and the ability to also see myself in other people's shoes and have empathy and kind of work on that language as part of that. So after that kind of experience and also embedding myself in French culture, which is quite amazing, languages are rich, not just because there's something inherently beautiful about it, but it's all the creativity that went into it. So I learned a lot of songs, read poems, read books. And then I was here actually at MIT where we're doing the podcast today and a young professor not yet married and not having a lot of friends in the area. So I just didn't have, I was kind of a bored person. I said, I heard a lot of Italians around. There's happened to be a lot of Italians at MIT, an Italian professor for some reason. And so I was kind of vaguely understanding what they were talking about. I said, well, I should learn this language too. So I did. And then later met my spouse and Italian became a part of my life. But I go to China a lot these days. I go to Asia, I go to Europe and every time I go, I kind of am amazed by the richness of human experience and the people don't have any idea if you haven't traveled, kind of how amazingly rich and I love the diversity. It's not just a buzzword to me. It really means something. I love to embed myself with other people's experiences. And so yeah, learning language is a big part of that. I think I've said in some interview at some point that if I had millions of dollars and infinite time or whatever, what would you really work on if you really wanted to do AI? And for me, that is natural language and really done right. Deep understanding of language. That's to me, an amazingly interesting scientific challenge. One we're very far away on. One we're very far away, but good natural language. People are kind of really invested then. I think a lot of them see that's where the core of AI is that if you understand that you really help human communication, you understand something about the human mind, the semantics that come out of the human mind and I agree, I think that will be such a long time. So I didn't do that in my career just cause I kind of, I was behind in the early days. I didn't kind of know enough of that stuff. I was at MIT, I didn't learn much language and it was too late at some point to kind of spend a whole career doing that, but I admire that field and so in my little way by learning language, you know, kind of that part of my brain has been trained up. Jan was right. You truly are the Miles Davis of machine learning. I don't think there's a better place than it. Mike it was a huge honor talking to you today. Merci beaucoup. All right. It's been my pleasure. Thanks for listening to this conversation with Michael I. Jordan and thank you to our presenting sponsor, Cash App. Download it, use code LEXPodcast, you'll get $10 and $10 will go to FIRST, an organization that inspires and educates young minds to become science and technology innovators of tomorrow. If you enjoy this podcast, subscribe on YouTube, give it five stars on Apple Podcast, support on Patreon, or simply connect with me on Twitter at Lex Friedman. And now let me leave you with some words of wisdom from Michael I. Jordan from his blog post titled Artificial Intelligence, the revolution hasn't happened yet, calling for broadening the scope of the AI field. We should embrace the fact that what we are witnessing is the creation of a new branch of engineering. The term engineering is often invoked in a narrow sense in academia and beyond with overtones of cold, effectless machinery and negative connotations of loss of control by humans. But an engineering discipline can be what we want it to be. In the current era, we have a real opportunity to conceive of something historically new, a human centric engineering discipline. I will resist giving this emerging discipline a name, but if the acronym AI continues to be used, let's be aware of the very real limitations of this placeholder. Let's broaden our scope, tone down the hype, and recognize the serious challenges ahead. Thank you for listening and hope to see you next time. you say is the most interesting disagreement you have with Jan Lacune? So Jan's an old friend and I just say that I don't think we disagree about very much really. He and I both kind of have a let's build it kind of mentality and does it work kind of mentality and kind of concrete. We both speak French and we speak French more together and we have a lot in common. And so if one wanted to highlight a disagreement, it's not really a fundamental one. I think it's just kind of what we're emphasizing. Jan has emphasized pattern recognition and has emphasized prediction. And it's interesting to try to take that as far as you can. If you could do perfect prediction, what would that give you kind of as a thought experiment? And I think that's way too limited. We cannot do perfect prediction. We will never have the data sets that allow me to figure out what you're about ready to do, what question you're going to ask next. I have no clue. I will never know such things. Moreover, most of us find ourselves during the day in all kinds of situations we had no anticipation of that are kind of very, very novel in various ways. And in that moment, we want to think through what we want. And also there's going to be market forces acting on us. I'd like to go down that street, but now it's full because there's a crane in the street. I got it. I got to think about that. I got to think about what I might really want here. And I got to sort of think about how much it costs me to do this action versus this action. I got to think about the risks involved. A lot of our current pattern recognition and prediction systems don't do any risk evaluations. They have no error bars, right? I got to think about other people's decisions around me. I got to think about a collection of my decisions, even just thinking about like a medical treatment, you know, I'm not going to take a, the prediction of a neural net about my health, about something consequential. I'm not about ready to have a heart attack because some number is over 0.7. Even if you had all the data in the world that ever been collected about heart attacks better than any doctor ever had, I'm not going to trust the output of that neural net to predict my heart attack. I'm going to want to ask what if questions around that. I'm going to want to look at some us or other possible data I didn't have, causal things. I'm going to want to have a dialogue with a doctor about things we didn't think about when he gathered the data. You know, I could go on and on. I hope you can see. And I don't, I think that if you say predictions, everything that, that, that you're missing all of this stuff. And so prediction plus decision making is everything, but both of them are equally important. And so the field has emphasized prediction, Jan rightly so has seen how powerful that is. But at the cost of people not being aware that decision making is where the rubber really hits the road, where human lives are at stake, where risks are being taken, where you got to gather more data. You got to think about the error bars. You got to think about the consequences of your decisions on others. You got to think about the economy around your decisions, blah, blah, blah, blah. I'm not the only one working on those, but we're a smaller tribe. And right now we're not the one that people talk about the most. But you know, if you go out in the real world and industry, you know, at Amazon, I'd say half the people there are working on decision making and the other half are doing, you know, the pattern recognition. It's important. And the words of pattern recognition and prediction, I think the distinction there, not to linger on words, but the distinction there is more a constrained sort of in the lab data set versus decision making is talking about consequential decisions in the real world, under the messiness and the uncertainty of the real world. And just the whole of it, the whole mess of it that actually touches human beings and scale. And the forces, that's the distinction. It helps add those, that perspective, that broader perspective. You're right. I totally agree. On the other hand, if you're a real prediction person, of course, you want it to be in the real world. You want to predict real world events. I'm just saying that's not possible with just data sets. That it has to be in the context of, you know, strategic things that someone's doing, data they might gather, things they could have gathered, the reasoning process around data. It's not just taking data and making predictions based on the data. So one of the things that you're working on, I'm sure there's others working on it, but I don't hear often it talked about, especially in the clarity that you talk about it, and I think it's both the most exciting and the most concerning area of AI in terms of decision making. So you've talked about AI systems that help make decisions that scale in a distributed way, millions, billions decisions, sort of markets of decisions. Can you, as a starting point, sort of give an example of a system that you think about when you're thinking about these kinds of systems? Yeah, so first of all, you're absolutely getting into some territory, which I will be beyond my expertise. And there are lots of things that are going to be very not obvious to think about. Just like, again, I like to think about history a little bit, but think about put yourself back in the sixties. There was kind of a banking system that wasn't computerized really. There was database theory emerging and database people had to think about how do I actually not just move data around, but actual money and have it be, you know, valid and have transactions that ATMs happen that are actually, you know, all valid and so on and so forth. So that's the kind of issues you get into when you start to get serious about sorts of things like this. I like to think about as kind of almost a thought experiment to help me think something simpler, which is the music market. And because there is, to first order, there is no music market in the world right now and in our country, for sure. There are something called things called record companies and they make money and they prop up a few really good musicians and make them superstars and they all make huge amounts of money. But there's a long tail of huge numbers of people that make lots and lots of really good music that is actually listened to by more people than the famous people. They are not in a market. They cannot have a career. They do not make money. The creators, the creators, the creators, the so called influencers or whatever that diminishes who they are. So there are people who make extremely good music, especially in the hip hop or Latin world these days. They do it on their laptop. That's what they do on the weekend and they have another job during the week and they put it up on SoundCloud or other sites. Eventually it gets streamed. It now gets turned into bits. It's not economically valuable. The information is lost. It gets put up there. People stream it. You walk around in a big city, you see people with headphones, especially young kids listening to music all the time. If you look at the data, very little of the music they are listening to is the famous people's music and none of it's old music. It's all the latest stuff. But the people who made that latest stuff are like some 16 year old somewhere who will never make a career out of this, who will never make money. Of course there will be a few counter examples. The record companies incentivize to pick out a few and highlight them. Long story short, there's a missing market there. There is not a consumer producer relationship at the level of the actual creative acts. The pipelines and Spotify's of the world that take this stuff and stream it along, they make money off of subscriptions or advertising and those things. They're making the money. All right. And then they will offer bits and pieces of it to a few people again to highlight that they simulate a market. Anyway, a real market would be if you're a creator of music that you actually are somebody who's good enough that people want to listen to you, you should have the data available to you. There should be a dashboard showing a map of the United States. So in last week, here's all the places your songs were listened to. It should be transparent, vetable, so that if someone down in Providence sees that you're being listened to 10,000 times in Providence, that they know that's real data. You know it's real data. They will have you come give a show down there. They will broadcast to the people who've been listening to you that you're coming. If you do this right, you could go down there and make $20,000. You do that three times a year, you start to have a career. So in this sense, AI creates jobs. It's not about taking away human jobs. It's creating new jobs because it creates a new market. Once you've created a market, you've now connected up producers and consumers. The person who's making the music can say to someone who comes to their shows a lot, hey, I'll play at your daughter's wedding for $10,000. You'll say 8,000. They'll say 9,000. Then again, you can now get an income up to $100,000. You're not going to be a millionaire. And now even think about really the value of music is in these personal connections, even so much so that a young kid wants to wear a tshirt with their favorite musician's signature on it. So if they listen to the music on the internet, the internet should be able to provide them with a button that they push and the merchandise arrives the next day. We can do that. And now why should we do that? Well, because the kid who bought the shirt will be happy, but more the person who made the music will get the money. There's no advertising needed. So you can create markets between producers and consumers, take 5% cut. Your company will be perfectly sound. It'll go forward into the future and it will create new markets and that raises human happiness. Now this seems like, well, this is easy, just create this dashboard, kind of create some connections and all that. But if you think about Uber or whatever, you think about the challenges in the real world of doing things like this, and there are actually new principles going to be needed. You're trying to create a new kind of two way market at a different scale that's ever been done before. There's going to be unwanted aspects of the market. There'll be bad people. There'll be the data will get used in the wrong ways, it'll fail in some ways, it won't deliver about. You have to think that through. Just like anyone who ran a big auction or ran a big matching service in economics will think these things through. And so that maybe doesn't get at all the huge issues that can arise when you start to create markets, but it starts to, at least for me, solidify my thoughts and allow me to move forward in my own thinking. Yeah. So I talked to the head of research at Spotify actually, and I think their longterm goal, they've said, is to have at least one million creators make a comfortable living putting on Spotify. So I think you articulate a really nice vision of the world and the digital and the cyberspace of markets. What do you think companies like Spotify or YouTube or Netflix can do to create such markets? Is it an AI problem? Is it an interface problem for interface design? Is it some other kind of, is it an economics problem? Who should they hire to solve these problems? Well, part of it's not just top down. So the Silicon Valley has this attitude that they know how to do it. They will create the system just like Google did with the search box that will be so good that they'll just, everyone will adopt that. It's everything you said, but really I think missing that kind of culture. So it's literally that 16 year old who's able to create the songs. You don't create that as a Silicon Valley entity. You don't hire them per se. You have to create an ecosystem in which they are wanted and that they belong. And so you have to have some cultural credibility to do things like this. Netflix, to their credit, wanted some of that credibility and they created shows, content. They call it content. It's such a terrible word, but it's culture. And so with movies, you can kind of go give a large sum of money to somebody graduating from the USC film school. It's a whole thing of its own, but it's kind of like rich white people's thing to do. And American culture has not been so much about rich white people. It's been about all the immigrants, all the Africans who came and brought that culture and those rhythms to this world and created this whole new thing. American culture. And so companies can't artificially create that. They can't just say, hey, we're here. We're going to buy it up. You've got a partner. And so anyway, not to denigrate, these companies are all trying and they should, and I'm sure they're asking these questions and some of them are even making an effort. But it is partly a respect the culture as a technology person. You've got to blend your technology with cultural meaning. How much of a role do you think the algorithm, so machine learning has in connecting the consumer to the creator, sort of the recommender system aspect of this? Yeah. It's a great question. I think pretty high. There's no magic in the algorithms, but a good recommender system is way better than a bad recommender system. And recommender systems is a billion dollar industry back even 10, 20 years ago. And it continues to be extremely important going forward. What's your favorite recommender system, just so we can put something, well, just historically I was one of the, when I first went to Amazon, I first didn't like Amazon because they put the book people out of business or the library, the local booksellers went out of business. I've come to accept that there probably are more books being sold now and poor people reading them than ever before. And then local book stores are coming back. So that's how economics sometimes work. You go up and you go down. But anyway, when I finally started going there and I bought a few books, I was really pleased to see another few books being recommended to me that I never would have thought of. And I bought a bunch of them. So they obviously had a good business model. But I learned things and I still to this day kind of browse using that service. And I think lots of people get a lot, that is a good aspect of a recommendation system. I'm learning from my peers in an indirect way. And their algorithms are not meant to have them impose what we learn. It really is trying to find out what's in the data. It doesn't work so well for other kinds of entities, but that's just the complexity of human life. Like shirts, I'm not going to get recommendations on shirts, but that's interesting. If you try to recommend restaurants, it's hard. It's hard to do it at scale. But a blend of recommendation systems with other economic ideas, matchings and so on is really, really still very open research wise. And there's new companies that are going to emerge that do that well. What do you think is going to the messy, difficult land of say politics and things like that, that YouTube and Twitter have to deal with in terms of recommendation systems? Being able to suggest, I think Facebook just launched Facebook news. So recommend the kind of news that are most likely for you to be interesting. Do you think this is AI solvable, again, whatever term we want to use, do you think it's a solvable problem for machines or is it a deeply human problem that's unsolvable? So I don't even think about it at that level. I think that what's broken with some of these companies, it's all monetization by advertising. They're not, at least Facebook, I want to critique them, but they didn't really try to connect a producer and a consumer in an economic way, right? No one wants to pay for anything. And so they all, you know, starting with Google and Facebook, they went back to the playbook of, you know, the television companies back in the day. No one wanted to pay for this signal. They will pay for the TV box, but not for the signal, at least back in the day. And so advertising kind of filled that gap and advertising was new and interesting and it somehow didn't take over our lives quite, right? Fast forward, Google provides a service that people don't want to pay for. And so somewhat surprisingly in the nineties, they made, they ended up making huge amounts so they cornered the advertising market. It didn't seem like that was going to happen, at least to me. These little things on the right hand side of the screen just did not seem all that economically interesting, but that companies had maybe no other choice. The TV market was going away and billboards and so on. So they've, they got it. And I think that sadly that Google just has, it was doing so well with that at making such money. They didn't think much more about how, wait a minute, is there a producer consumer relationship to be set up here? Not just between us and the advertisers market to be created. Is there an actual market between the producer consumer? They're the producers, the person who created that video clip, the person that made that website, the person who could make more such things, the person who could adjust it as a function of demand, the person on the other side who's asking for different kinds of things, you know? So you see glimmers of that now there's influencers and there's kind of a little glimmering of a market, but it should have been done 20 years ago. It should have been thought about. It should have been created in parallel with the advertising ecosystem. And then Facebook inherited that. And I think they also didn't think very much about that. So fast forward and now they are making huge amounts of money off of advertising. And the news thing and all these clicks is just feeding the advertising. It's all connected up to the advertiser. So you want more people to click on certain things because that money flows to you, Facebook. You're very much incentivized to do that. And when you start to find it's breaking, people are telling you, well, we're getting into some troubles. You try to adjust it with your smart AI algorithms, right? And figure out what are bad clicks. So maybe it shouldn't be click through rate, it should be something else. I find that pretty much hopeless. It does get into all the complexity of human life and you can try to fix it. You should, but you could also fix the whole business model. And the business model is that really, what are, are there some human producers and consumers out there? Is there some economic value to be liberated by connecting them directly? Is it such that it's so valuable that people will be able to pay for it? All right. And micro payments, like small payments. Micro, but even have to be micro. So I like the example, suppose I'm going, next week I'm going to India. Never been to India before. Right? I have a couple of days in Mumbai, I have no idea what to do there. Right? And I could go on the web right now and search. It's going to be kind of hopeless. I'm not going to find, you know, I have lots of advertisers in my face. Right? What I really want to do is broadcast to the world that I am going to Mumbai and have someone on the other side of a market look at me and, and there's a recommendation system there. So I'm not looking at all possible people coming to Mumbai. They're looking at the people who are relevant to them. So someone in my age group, someone who kind of knows me in some level, I give up a little privacy by that, but I'm happy because what I'm going to get back is this person can make a little video for me, or they're going to write a little two page paper on here's the cool things that you want to do and move by this week, especially, right? I'm going to look at that. I'm not going to pay a micro payment. I'm going to pay, you know, a hundred dollars or whatever for that. It's real value. It's like journalism. Um, and as an honest subscription, it's that I'm going to pay that person in that moment. Company's going to take 5% of that. And that person has now got it. It's a gig economy, if you will, but you know, done for it, you know, thinking about a little bit behind YouTube, there was actually people who could make more of those things. If they were connected to a market, they would make more of those things independently. You don't have to tell them what to do. You don't have to incentivize them any other way. Um, and so, yeah, these companies, I don't think have thought long and hard about that. So I do distinguish on Facebook on the one side, who just not thought about these things at all. I think, uh, thinking that AI will fix everything, uh, and Amazon thinks about them all the time because they were already out in the real world. They were delivering packages, people's doors. They were, they were worried about a market. They were worried about sellers and, you know, they worry and some things they do are great. Some things maybe not so great, but you know, they're in that business model. And then I'd say Google sort of hovers somewhere in between. I don't, I don't think for a long, long time they got it. I think they probably see that YouTube is more pregnant with possibility than, than, than they might've thought and that they're probably heading that direction. Um, but uh, you know, Silicon Valley has been dominated by the Google Facebook kind of mentality and the subscription and advertising and that is, that's the core problem, right? The fake news actually rides on top of that because it means that you're monetizing with clip through rate and that is the core problem. You got to remove that. So advertisement, if we're going to linger on that, I mean, that's an interesting thesis. I don't know if everyone really deeply thinks about that. So you're right. The thought is the advertising model is the only thing we have, the only thing we'll ever have. We have to fix, we have to build algorithms that despite that business model, you know, find the better angels of our nature and do good by society and by the individual. But you think we can slowly, you think, first of all, there's a difference between should and could. So you're saying we should slowly move away from the advertising model and have a direct connection between the consumer and the creator. The question I also have is, can we, because the advertising model is so successful now in terms of just making a huge amount of money and therefore being able to build a big company that provides, has really smart people working that create a good service. Do you think it's possible? And just to clarify, you think we should move away? Well, I think we should. Yeah. But we is the, you know, me. So society. Yeah. Well, the companies, I mean, so first of all, full disclosure, I'm doing a day a week at Amazon because I kind of want to learn more about how they do things. So, you know, I'm not speaking for Amazon in any way, but, you know, I did go there because I actually believe they get a little bit of this or trying to create these markets. And they don't really use, advertising is not a crucial part of it. Well, that's a good question. So it has become not crucial, but it's become more and more present if you go to Amazon website. And, you know, without revealing too many deep secrets about Amazon, I can tell you that, you know, a lot of people in the company question this and there's a huge questioning going on. You do not want a world where there's zero advertising. That actually is a bad world. Okay. So here's a way to think about it. You're a company that like Amazon is trying to bring products to customers, right? And the customer, at any given moment, you want to buy a vacuum cleaner, say, you want to know what's available for me. And, you know, it's not going to be that obvious. You have to do a little bit of work at it. The recommendation system will sort of help, right? But now suppose this other person over here has just made the world, you know, they spent a huge amount of energy. They had a great idea. They made a great vacuum cleaner. They know they really did it. They nailed it. It's an MIT, you know, whiz kid that made a great new vacuum cleaner, right? It's not going to be in the recommendation system. No one will know about it. The algorithms will not find it and AI will not fix that. Okay. At all. Right. How do you allow that vacuum cleaner to start to get in front of people, be sold well advertising. And here, what advertising is, it's a signal that you're, you believe in your product enough that you're willing to pay some real money for it. And to me as a consumer, I look at that signal. I say, well, first of all, I know these are not just cheap little ads cause we have now right now there. I know that, you know, these are super cheap, you know, pennies. If I see an ad where it's actually, I know the company is only doing a few of these and they're making, you know, real money is kind of flowing and I see an ad, I may pay more attention to it. And I actually might want that because I see, Hey, that guy spent money on his vacuum cleaner. Maybe there's something good there. So I will look at it. And so that's part of the overall information flow in a good market. So advertising has a role, but the problem is of course that that signal is now completely gone because it just, you know, dominant by these tiny little things that add up to big money for the company, you know? So I think it will just, I think it will change because the societies just don't, you know, stick with things that annoy a lot of people and advertising currently annoys people more than it provides information. And I think that a Google probably is smart enough to figure out that this is a dead, this is a bad model, even though it's a hard, huge amount of money and they'll have to figure out how to pull it away from it slowly. And I'm sure the CEO there will figure it out, but they need to do it. And they needed it to, so if you reduce advertising, not to zero, but you reduce it at the same time you bring up producer, consumer, actual real value being delivered. So real money is being paid and they take a 5% cut that 5% could start to get big enough to cancel out the lost revenue from the kind of the poor kind of advertising. And I think that a good company will do that, will realize that. And Facebook, you know, again, God bless them. They bring, you know, grandmothers, they bring children's pictures into grandmothers lives. It's fantastic. But they need to think of a new business model and that's the core problem there. Until they start to connect producer consumer, I think they will just continue to make money and then buy the next social network company and then buy the next one and the innovation level will not be high and the health issues will not go away. So I apologize that we kind of returned to words, I don't think the exact terms matter, but in sort of defense of advertisement, don't you think the kind of direct connection between consumer and creator producer is what advertisement strives to do, right? So that is best advertisement is literally now Facebook is listening to our conversation and heard that you're going to India and will be able to actually start automatically for you making these connections and start giving this offer. So like, I apologize if it's just a matter of terms, but just to draw a distinction, is it possible to make advertisements just better and better and better algorithmically to where it actually becomes a connection, almost a direct connection? That's a good question. So let's component on that. First of all, what we just talked about, I was defending advertising. Okay. So I was defending it as a way to get signals into a market that don't come any other way, especially algorithmically. It's a sign that someone spent money on it, it's a sign they think it's valuable. And if I think that if other things, someone else thinks it's valuable, and if I trust other people, I might be willing to listen. I don't trust that Facebook though, who's an intermediary between this. I don't think they care about me. Okay. I don't think they do. And I find it creepy that they know I'm going to India next week because of our conversation. Why do you think that is? So what, could you just put your PR hat on? Why do you think you find Facebook creepy and not trust them as do majority of the population? So they're out of the Silicon Valley companies, I saw like not approval rate, but there's ranking of how much people trust companies and Facebook is in the gutter. In the gutter, including people inside of Facebook. So what do you attribute that to? Because when I... Come on, you don't find it creepy that right now we're talking that I might walk out on the street right now that some unknown person who I don't know kind of comes up to me and says, I hear you're going to India. I mean, that's not even Facebook. That's just, I want transparency in human society. I want to have, if you know something about me, there's actually some reason you know something about me. That's something that if I look at it later and audit it kind of, I approve. You know something about me because you care in some way. There's a caring relationship even, or an economic one or something. Not just that you're someone who could exploit it in ways I don't know about or care about or I'm troubled by or whatever. We're in a world right now where that happens way too much and that Facebook knows things about a lot of people and could exploit it and does exploit it at times. I think most people do find that creepy. It's not for them. It's not that Facebook is not doing it because they care about them in a real sense. And they shouldn't. They should not be a big brother caring about us. That is not the role of a company like that. Why not? Wait, not the big brother part, but the caring, the trusting. I mean, don't those companies, just to link on it because a lot of companies have a lot of information about us. I would argue that there's companies like Microsoft that has more information about us than Facebook does and yet we trust Microsoft more. Well, Microsoft is pivoting. Microsoft, you know, under Satya Nadella has decided this is really important. We don't want to do creepy things. Really want people to trust us to actually only use information in ways that they really would approve of, that we don't decide, right? And I'm just kind of adding that the health of a market is that when I connect to someone who produces a consumer, it's not just a random producer or consumer, it's people who see each other. They don't like each other, but they sense that if they transact, some happiness will go up on both sides. If a company helps me to do that in moments that I choose of my choosing, then fine. So, and also think about the difference between, you know, browsing versus buying, right? There are moments in my life I just want to buy, you know, a gadget or something. I need something for that moment. I need some ammonia for my house or something because I got a problem with a spill. I want to just go in. I don't want to be advertised at that moment. I don't want to be led down various, you know, that's annoying. I want to just go and have it be extremely easy to do what I want. Other moments I might say, no, it's like today I'm going to the shopping mall. I want to walk around and see things and see people and be exposed to stuff. So I want control over that though. I don't want the company's algorithms to decide for me, right? I think that's the thing. There's a total loss of control if Facebook thinks they should take the control from us of deciding when we want to have certain kinds of information, when we don't, what information that is, how much it relates to what they know about us that we didn't really want them to know about us. I don't want them to be helping me in that way. I don't want them to be helping them by they decide they have control over what I want and when. I totally agree. Facebook, by the way, I have this optimistic thing where I think Facebook has the kind of personal information about us that could create a beautiful thing. So I'm really optimistic of what Facebook could do. It's not what it's doing, but what it could do. So I don't see that. I think that optimism is misplaced because there's not a bit, you have to have a business model behind these things. Create a beautiful thing is really, let's be, let's be clear. It's about something that people would value. And I don't think they have that business model and I don't think they will suddenly discover it by what, you know, a long hot shower. I disagree. I disagree in terms of, you can discover a lot of amazing things in a shower. So I didn't say that. I said, they won't come, they won't do it, but in the shower, I think a lot of other people will discover it. I think that this guy, so I should also, full disclosure, there's a company called United Masters, which I'm on their board and they've created this music market and I have a hundred thousand artists now signed on and they've done things like gone to the NBA and the NBA, the music you find behind NBA clips right now is their music, right? That's a company that had the right business model in mind from the get go, right? Executed on that. And from day one, there was value brought to, so here you have a kid who made some songs who suddenly their songs are on the NBA website, right? That's real economic value to people. And so, you know, so you and I differ on the optimism of being able to sort of change the direction of the Titanic, right? So I, yeah, I'm older than you, so I've seen some Titanic's crash, got it. But and just to elaborate, cause I totally agree with you and I just want to know how difficult you think this problem is of, so for example, I want to read some news and I would, there's a lot of times in the day where something makes me either smile or think in a way where I like consciously think this really gave me value. Like I sometimes listen to the daily podcasts in the New York times, way better than the New York times themselves, by the way, for people listening. That's like real journalism is happening for some reason in the podcast space. It doesn't make sense to me, but often I listen to it 20 minutes and I would be willing to pay for that, like $5, $10 for that experience. And how difficult, that's kind of what you're getting at is that little transaction. How difficult is it to create a frictionless system like Uber has, for example, for other things? What's your intuition there? So I, first of all, I pay little bits of money to, you know, to send, there's something called courts that does financial things. I like medium as a site, I don't pay there, but I would. You had a great post on medium. I would have loved to pay you a dollar and not others. I wouldn't have wanted it per se because there should be also sites where that's not actually the goal. The goal is to actually have a broadcast channel that I monetize in some other way if I chose to. I mean, I could now people know about it. I could, I'm not doing it, but that's fine with me. Also the musicians who are making all this music, I don't think the right model is that you pay a little subscription fee to them, right? Because people can copy the bits too easily and it's just not that somewhere the value is. The value is that a connection was made between real human beings, then you can follow up on that. All right. And create yet more value. So no, I think there's a lot of open questions here, hot open questions, but also, yeah, I do want good recommendation systems that recommend cool stuff to me. But it's pretty hard, right? I don't like them to recommend stuff just based on my browsing history. I don't like the based on stuff they know about me, quote unquote. What's unknown about me is the most interesting. So this is the, this is the really interesting question. We may disagree, maybe not. I think that I love recommender systems and I want to give them everything about me in a way that I trust. Yeah. But you, but you don't, because, so for example, this morning I clicked on a, you know, I was pretty sleepy this morning. I clicked on a story about the queen of England. Yes. Right. I do not give a damn about the queen of England. I really do not. But it was clickbait. It kind of looked funny and I had to say, what the heck are they talking about? I don't want to have my life, you know, heading that direction. Now that's in my browsing history. The system in any reasonable system will think that I care about the queen of England. That's browsing history. Right. But, but you're saying all the trace, all the digital exhaust or whatever, that's been kind of the models. If you collect all this stuff, you're going to figure all of us out. Well, if you're trying to figure out like kind of one person like Trump or something, maybe you could figure him out. But if you're trying to figure out, you know, 500 million people, you know, no way, no way. You think so? No, I do. I think so. I think we are, humans are just amazingly rich and complicated. Every one of us has our little quirks, every one of us has our little things that could intrigue us that we don't even know it will intrigue us. And there's no sign of it in our past, but by God, there it comes and you know, you fall in love with it. And I don't want a company trying to figure that out for me and anticipate that I want them to provide a forum, a market, a place that I kind of go and by hook or by crook, this happens, you know, I I'm walking down the street and I hear some Chilean music being played and I never knew I liked Chilean music, but wow. So there is that side and I want them to provide a limited, but you know, interesting place to go. Right. And so don't try to use your AI to kind of, you know, figure me out and then put me in a world where you figured me out, you know, no, create huge spaces for human beings where our creativity and our style will be enriched and come forward and it'll be a lot of more transparency. I won't have people randomly, anonymously putting comments up and I'll special based on stuff they know about me, facts that, you know, we are so broken right now. If you're, you know, especially if you're a celebrity, but you know, it's about anybody that anonymous people are hurting lots and lots of people right now. That's part of this thing that Silicon Valley is thinking that, you know, just collect all this information and use it in a great way. So no, I'm not, I'm not a pessimist, I'm very much an optimist by nature, but I think that's just been the wrong path for the whole technology to take. Be more limited, create, let humans rise up. Don't try to replace them. That's the AI mantra. Don't try to anticipate them. Don't try to predict them because you're, you're, you're not going to, you're not going to be able to do those things. You're going to make things worse. Okay. So right now, just give this a chance. Right now, the recommender systems are the creepy people in the shadow watching your every move. So they're looking at traces of you. They're not directly interacting with you, sort of the, your close friends and family, the way they know you is by having conversation, by actually having interactions back and forth. Do you think there's a place for recommender systems sort of to step, cause you, you just emphasize the value of human to human connection, but yeah, just give it a chance, AI human connection. Is there a role for an AI system to have conversations with you in terms of, to try to figure out what kind of music you like, not by just watching what you listening to, but actually having a conversation, natural language or otherwise. Yeah, no, I'm, I'm, so I'm not against it. I just wanted to push back against the, maybe you're saying you have options for Facebook. So there I think it's misplaced, but, but I think that distributing, yeah, no, so good for you. Go for it. That's a hard spot to be in. Yeah, no, good. Human interaction, like on our daily, the context around me in my own home is something that I don't want some big company to know about at all, but I would be more than happy to have technology help me with it. Which kind of technology? Well, you know, just, Alexa, Amazon, well, a good, Alexa's done right. And I think Alexa is a research platform right now more than anything else. But Alexa done right, you know, could do things like I, I leave the water running in my garden and I say, Hey, Alexa, the water's running in my garden. And even have Alexa figure out that that means when my wife comes home, that she should be told about that. That's a little bit of a reasoning. I would call that AI and by any kind of stretch, it's a little bit of reasoning and it actually kind of would make my life a little easier and better. And you know, I don't, I wouldn't call this a wow moment, but I kind of think that overall rises human happiness up to have that kind of thing. But not when you're lonely, Alexa, knowing loneliness. No, no, I don't want Alexa to be, feel intrusive. And I don't want just the designer of the system to kind of work all this out. I really want to have a lot of control and I want transparency and control. And if a company can stand up and give me that in the context of new technology, I think they're good. First of all, be way more successful than our current generation. And like I said, I was mentioning Microsoft, I really think they're, they're pivoting to kind of be the trusted old uncle, but you know, I think that they get that this is a way to go, that if you let people find technology, empowers them to have more control and have and have control, not just over privacy, but over this rich set of interactions, that that people are going to like that a lot more. And that's, that's the right business model going forward. What does control over privacy look like? Do you think you should be able to just view all the data that? No, it's much more than that. I mean, first of all, it should be an individual decision. Some people don't want privacy. They want their whole life out there. Other people's want it. Privacy is not a zero one. It's not a legal thing. It's not just about which data is available, which is not. I like to recall to people that, you know, a couple hundred years ago, everyone, there was not really big cities, everyone lived in on the countryside and villages and villages. Everybody knew everything about you. Very, you didn't have any privacy. Is that bad? Are we better off now? Well, you know, arguably no, because what did you get for that loss of certain kinds of privacy? Well, people help each other if they, because they know everything about you. They know something's bad's happening, they will help you with that. Right. And now you live in a big city, no one knows about that. You get no help. So it kind of depends the answer. I want certain people who I trust and there should be relationships. I should kind of manage all those, but who knows what about me? I should have some agency there. It shouldn't, I shouldn't be a drift in a sea of technology where I have no agency. I don't want to go reading things and checking boxes. So I don't know how to do that. And I'm not a privacy researcher per se. I just, I recognize the vast complexity of this. It's not just technology. It's not just legal scholars meeting technologists. There's gotta be kind of a whole layers around it. And so I, when I alluded to this emerging engineering field, this is a big part of it. When electrical engineering came, I'm not one around at the time, but you just didn't plug electricity into walls and all kinds of work. You don't have to have like underwriters laboratory that reassured you that that plug's not going to burn up your house and that that machine will do this and that and everything. There'll be whole people who can install things. There'll be people who can watch the installers. There'll be a whole layers, you know, an onion of these kinds of things. And for things as deep and interesting as privacy, which is as least as interesting as electricity, that's going to take decades to kind of work out, but it's going to require a lot of new structures that we don't have right now. So it's kind of hard to talk about it. And you're saying there's a lot of money to be made if you get it right. So something you should look at. A lot of money to be made in all these things that provide human services and people recognize them as useful parts of their lives. So yeah. So yeah, the dialogue sometimes goes from the exuberant technologists to the no technology is good, kind of. And that's, you know, in our public discourse, you know, and as far as you see too much of this kind of thing and the sober discussions in the middle, which are the challenge he wants to have or where we need to be having our conversations. And you know, there's just not actually, there's not many forum fora for those. You know, there's, that's, that's kind of what I would look for. Maybe I could go and I could read a comment section of something and it would actually be this kind of dialogue going back and forth. You don't see much of this, right? Which is why actually there's a resurgence of podcasts out of all, because people are really hungry for conversation, but there's technology is not helping much. So comment sections of anything, including YouTube is not hurting and not helping.\",\n          \"We are becoming cyborgs. Our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous, from homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is like essentially a new species. Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo techno. I think this is what, it's a brain augmentation. So it like allows for actual evolution. Like the computers accelerate the degree to which all the other technologies can also be accelerated. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. So you're one of the earliest of the species. I think most of us are. The following is a conversation with Grimes, an artist, musician, songwriter, producer, director, and a fascinating human being who thinks a lot about both the history and the future of human civilization. Studying the dark periods of our past to help form an optimistic vision of our future. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Grimes. Oh yeah, the cloud lifter, there you go. There you go. You know your stuff. Have you ever used a cloud lifter? Yeah, I actually, this microphone cloud lifter is what Michael Jackson used, so. No, really? Yeah, this is like Thriller and stuff. This mic and a cloud lifter? Yeah, it's a incredible microphone. It's very flattering on vocals. I've used this a lot. It's great for demo vocals. It's great in a room. Sometimes it's easier to record vocals if you're just in a room and the music's playing and you just wanna feel it so it's not in the headphones. And this mic is pretty directional, so I think it's a good mic for just vibing out and just getting a real good vocal take. Just vibing, just in a room. Anyway, this is the Michael Jackson, Quincy Jones microphone. I feel way more badass now. All right, you wanna just get into it? I guess so. All right, one of your names, at least in this space and time, is C, like the letter C. And you told me that C means a lot of things. It's the speed of light. It's the render rate of the universe. It's yes in Spanish. It's the crescent moon. And it happens to be my favorite programming language because it basically runs the world, but it's also powerful, fast, and it's dangerous because you can mess things up really bad with it because of all the pointers. But anyway, which of these associations will the name C is the coolest to you? I mean, to me, the coolest is the speed of light, obviously, or the speed of light. When I say render rate of the universe, I think I mean the speed of light because essentially that's what we're rendering at. See, I think we'll know if we're in a simulation if the speed of light changes because if they can improve their render speed, then. Well, it's already pretty good. It's already pretty good, but if it improves, then we'll know, we can probably be like, okay, they've updated or upgraded. Well, it's fast enough for us humans because it seems immediate. There's no delay, there's no latency in terms of us humans on Earth interacting with things. But if you're like intergalactic species operating on a much larger scale, then you're gonna start noticing some weird stuff. Or if you can operate in like around a black hole, then you're gonna start to see some render issues. You can't go faster than the speed of light, correct? So it really limits our ability or one's ability to travel space. Theoretically, you can, you have wormholes. So there's nothing in general relativity that precludes faster than the speed of light travel. But it just seems you're gonna have to do some really funky stuff with very heavy things that have like weirdnesses, that have basically terrors in space time. We don't know how to do that. Do navigators know how to do it? Do navigators? Yeah. Folding space, basically making wormholes. So the name C. Yes. Who are you? Do you think of yourself as multiple people? Are you one person? Do you know, like in this morning, were you a different person than you are tonight? We are, I should say, recording this basically at midnight, which is awesome. Yes, thank you so much. I think I'm about eight hours late. No, you're right on time. Good morning. This is the beginning of a new day soon. Anyway, are you the same person you were in the morning and the evening? Is there multiple people in there? Do you think of yourself as one person? Or maybe you have no clue? Or are you just a giant mystery to yourself? Okay, these are really intense questions, but. Let's go, let's go. Because I asked this myself, like look in the mirror, who are you? People tell you to just be yourself, but what does that even mean? I mean, I think my personality changes with everyone I talk to. So I have a very inconsistent personality. Yeah. Person to person, so the interaction, your personality materializes. Or my mood. Like I'll go from being like a megalomaniac to being like, you know, just like a total hermit who is very shy. So some combinatorial combination of your mood and the person you're interacting with. Yeah, mood and people I'm interacting with. But I think everyone's like that. Maybe not. Well, not everybody acknowledges it and able to introspect it. Who brings out, what kind of person, what kind of mood brings out the best in you? As an artist and as a human. Can you introspect this? Like my best friends, like people I can, when I'm like super confident and I know that they're gonna understand everything I'm saying, so like my best friends, then when I can start being really funny, that's always my like peak mode. But it's like, yeah, takes a lot to get there. Let's talk about constraints. You've talked about constraints and limits. Do those help you out as an artist or as a human being? Or do they get in the way? Do you like the constraints? So in creating music, in creating art, in living life, do you like the constraints that this world puts on you? Or do you hate them? If constraints are moving, then you're good, right? Like it's like as we are progressing with technology, we're changing the constraints of like artistic creation. You know, making video and music and stuff is getting a lot cheaper. There's constantly new technology and new software that's making it faster and easier. We have so much more freedom than we had in the 70s. Like when Michael Jackson, you know, when they recorded Thriller with this microphone, like they had to use a mixing desk and all this stuff. And like probably even get in a studio, it's probably really expensive and you have to be a really good singer and you have to know how to use like the mixing desk and everything. And now I can just, you know, make I've made a whole album on this computer. I have a lot more freedom, but then I'm also constrained in different ways because there's like literally millions more artists. It's like a much bigger playing field. It's just like, I also, I didn't learn music. I'm not a natural musician. So I don't know anything about actual music. I just know about like the computer. So I'm really kind of just like messing around and like trying things out. Well, yeah, I mean, but the nature of music is changing. So you're saying you don't know actual music, what music is changing. Music is becoming, you've talked about this, is becoming, it's like merging with technology. Yes. It's becoming something more than just like the notes on a piano. It's becoming some weird composition that requires engineering skills, programming skills, some kind of human robot interaction skills, and still some of the same things that Michael Jackson had, which is like a good ear for a good sense of taste of what's good and not the final thing when it's put together. Like you're allowed, you're enabled, empowered with a laptop to layer stuff, to start like layering insane amounts of stuff. And it's super easy to do that. I do think music production is a really underrated art form. I feel like people really don't appreciate it. When I look at publishing splits, the way that people like pay producers and stuff, it's super, producers are just deeply underrated. Like so many of the songs that are popular right now or for the last 20 years, like part of the reason they're popular is because the production is really interesting or really sick or really cool. And it's like, I don't think listeners, like people just don't really understand what music production is. It's not, it's sort of like this weird, discombobulated art form. It's not like a formal, because it's so new, there isn't like a formal training path for it. It's mostly driven by like autodidacts. Like it's like almost everyone I know who's good at production, like they didn't go to music school or anything. They just taught themselves. Are they're mostly different? Like the music producers, you know, is there some commonalities that time together or are they all just different kinds of weirdos? Cause I just, I just hung out with Rick Rubin. I don't know if you've. Yeah, I mean, Rick Rubin is like literally one of the gods of music production. Like he's one of the people who first, you know, who like made music production, you know, made the production as important as the actual lyrics or the notes. But the thing he does, which is interesting, I don't know if you can speak to that, but just hanging out with him, he seems to just sit there in silence, close his eyes and listen. It's like, he almost does nothing. And that nothing somehow gives you freedom to be the best version of yourself. So that's music production somehow too, which is like encouraging you to do less, to simplify, to like push towards minimalism. I mean, I guess, I mean, I work differently from Rick Rubin cause Rick Rubin produces for other artists, whereas like I mostly produce for myself. So it's a very different situation. I also think Rick Rubin, he's in that, I would say advanced category of producer where like you've like earned your, you can have an engineer and stuff and people like do the stuff for you. But I usually just like do stuff myself. So you're the engineer, the producer and the artist. Yeah, I guess I would say I'm in the era, like the post Rick Rubin era. Like I come from the kind of like Skrillex school of thought, which is like where you are. Yeah, the engineer, producer, artist. Like where, I mean lately, sometimes I'll work with a producer now. I'm gently sort of delicately starting to collaborate a bit more, but like I think I'm kind of from the, like the whatever 2010s explosion of things where everything became available on the computer and you kind of got this like lone wizard energy thing going. So you embraced being the loneliness. Is the loneliness somehow an engine of creativity? Like, so most of your stuff, most of your creative quote unquote genius in quotes is in the privacy of your mind. Yes, well, it was, but here's the thing. I was talking to Daniel Eck and he said, he's like most artists, they have about 10 years, like 10 good years. And then they usually stop making their like vital shit. And I feel like I'm sort of like nearing the end of my 10 years on my own. So you have to become somebody else. Now I'm like, I'm in the process of becoming somebody else and reinventing. When I work with other people, because I've never worked with other people, I find that I make like, that I'm exceptionally rejuvenated and making like some of the most vital work I've ever made. So, because I think another human brain is like one of the best tools you can possibly find. Like. It's a funny way to put it, I love it. It's like if a tool is like, you know, whatever HP plus one or like adds some like stats to your character, like another human brain will like square it instead of just like adding something. Double up the experience points, I love this. We should also mention we're playing Tavern music before this and which I love, which I first, I think I first. You had to stop the Tavern music. Yeah, because it doesn't, the audio. Okay, okay. But it makes. Yeah, it'll make the podcast annoying. Add it in post, add it in post. No one will want to listen to the podcast. They probably would, but it makes me, it reminds me like of a video game, like a role playing video game where you have experience points. There's something really joyful about wandering places like Elder Scrolls, like Skyrim, just exploring these landscapes in another world and then you get experience points and you can work on different skills and somehow you progress in life. I don't know, it's simple. It doesn't have some of the messy complexities of life and there's usually a bad guy you can fight in Skyrim. It's dragons and so on. I'm sure in Elden Ring, there's a bunch of monsters you can fight. I love that. I feel like Elden Ring, I feel like this is a good analogy to music production though because it's like, I feel like the engineers and the people creating these open worlds are, it's sort of like similar to people, to music producers where it's like this hidden archetype that like no one really understands what they do and no one really knows who they are, but they're like, it's like the artist engineer because it's like, it's both art and fairly complex engineering. Well, you're saying they don't get enough credit. Aren't you kind of changing that by becoming the person doing everything? Aren't you, isn't the engineer? Well, I mean, others have gone before me. I'm not, you know, there's like Timbaland and Skrillex and there's all these people that are like, you know, very famous for this, but I just think the general, I think people get confused about what it is and just don't really know what it is per se and it's just when I see a song, like when there's like a hit song, like I'm just trying to think of like, just going for like even just a basic pop hit, like, what's it? Like Rules by Dua Lipa or something. The production on that is actually like really crazy. I mean, the song is also great, but it's like the production is exceptionally memorable. Like, you know, and it's just like no one, I can't, I don't even know who produced that song. It's just like, isn't part of like the rhetoric of how we just discuss the creation of art. We just sort of like don't consider the music producer because I think the music producer used to be more just simply recording things. Yeah, that's interesting because when you think about movies, we talk about the actor and the actresses, but we also talk about the directors. We don't talk about like that with the music as often. The Beatles music producer was one of the first kind of guy, one of the first people sort of introducing crazy sound design into pop music. I forget his name. He has the same, I forget his name, but you know, like he was doing all the weird stuff like dropping pianos and like, yeah. Oh, to get the, yeah, yeah, yeah, to get the sound, to get the authentic sound. What about lyrics? You think those, where did they fit into how important they are? I was heartbroken to learn that Elvis didn't write his songs. I was very mad. A lot of people don't write their songs. I understand this, but. But here's the thing. I feel like there's this desire for authenticity. I used to be like really mad when like people wouldn't write or produce their music and I'd be like, that's fake. And then I realized there's all this like weird bitterness and like agronus in art about authenticity. But I had this kind of like weird realization recently where I started thinking that like art is sort of a decentralized collective thing. Like art is kind of a conversation with all the artists that have ever lived before you. You know, like it's like, you're really just sort of, it's not like anyone's reinventing the wheel here. Like you're kind of just taking, you know, thousands of years of art and like running it through your own little algorithm and then like making your interpretation of it. You just joined the conversation with all the other artists that came before. It's just a beautiful way to look at it. Like, and it's like, I feel like everyone's always like, there's all this copyright and IP and this and that or authenticity. And it's just like, I think we need to stop seeing this as this like egotistical thing of like, oh, the creative genius, the lone creative genius or this or that. Because it's like, I think art shouldn't be about that. I think art is something that sort of brings humanity together. And it's also, art is also kind of the collective memory of humans. It's like, we don't give a fuck about whatever ancient Egypt, like how much grain got sent that day and sending the records and like, you know, like who went where and, you know, how many shields needed to be produced for this. Like we just remember their art. And it's like, you know, it's like in our day to day life, there's all this stuff that seems more important than art because it helps us function and survive. But when all this is gone, like the only thing that's really gonna be left is the art. The technology will be obsolete. That's so fascinating. Like the humans will be dead. That is true. A good compression of human history is the art we've generated across the different centuries, the different millennia. So when the aliens come. When the aliens come, they're gonna find the hieroglyphics and the pyramids. I mean, art could be broadly defined. They might find like the engineering marvels, the bridges, the rockets, the. I guess I sort of classify though. Architecture is art too. I consider engineering in those formats to be art, for sure. It sucks that like digital art is easier to delete. So if there's an apocalypse, a nuclear war, that can disappear. Yes. And the physical. There's something still valuable about the physical manifestation of art. That sucks that like music, for example, has to be played by somebody. Yeah, I do think we should have a foundation type situation where we like, you know how we have like seed banks up in the north and stuff? Like we should probably have like a solar powered or geothermal little bunker that like has all human knowledge. You mentioned Daniel Ek and Spotify. What do you think about that as an artist? What's Spotify? Is that empowering? To me, Spotify as a consumer is super exciting. It makes it easy for me to access music from all kinds of artists, get to explore all kinds of music, make it super easy to sort of curate my own playlist and have fun with all that. It was so liberating to let go. You know, I used to collect, you know, albums and CDs and so on, like horde albums. Yeah. Like they matter. But the reality you could, you know, that was really liberating that I could let go of that. And letting go of the albums you're kind of collecting allows you to find new music, exploring new artists and all that kind of stuff. But I know from a perspective of an artist that could be, like you mentioned, competition could be a kind of constraint because there's more and more and more artists on the platform. I think it's better that there's more artists. I mean, again, this might be propaganda because this is all from a conversation with Daniel Ek. So this could easily be propaganda. We're all a victim of somebody's propaganda. So let's just accept this. But Daniel Ek was telling me that, you know, to understand really difficult concepts just in a very different way, like an emotional intelligence about something deep within? Oh yeah, no, like if X hurts, like if X bites me really hard and I'm like, ow, like he gets, he's sad. He's like sad if he hurts me by accident. Yeah. Which he's huge, so he hurts me a lot by accident. Yeah, that's so interesting that that mind emerges and he and children don't really have memory of that time. So we can't even have a conversation with them about it. Yeah, I just thank God they don't have a memory of this time because like, think about like, I mean with our youngest baby, like it's like, I'm like, have you read the sci fi short story, I Have No Mouth But I Must Scream? Good title, no. Oh man, I mean, you should read that. I Have No Mouth But I Must Scream. I hate getting into this Rocco's Basilisk shit. It's kind of a story about the, about like an AI that's like torturing someone in eternity and they have like no body. The way they describe it, it sort of sounds like what it feels like, like being a baby, like you're conscious and you're just getting inputs from everywhere and you have no muscles and you're like jelly and you like can't move and you try to like communicate, but you can't communicate and we're, and like, you're just like in this like hell state. I think it's good we can't remember that. Like my little baby is just exiting that, like she's starting to like get muscles and have more like autonomy, but like watching her go through the opening phase, I was like, I was like, this does not seem good. Oh, you think it's kind of like. Like I think it sucks. I think it might be really violent. Like violent, mentally violent, psychologically violent. Consciousness emerging, I think is a very violent thing. I never thought about that. I think it's possible that we all carry quite a bit of trauma from it that we don't, I think that would be a good thing to study because I think if, I think addressing that trauma, like, I think that might be. Oh, you mean like echoes of it are still there in the shadows somewhere. I think it's gotta be, I feel this, this help, the helplessness, the like existential and that like fear of being in like an unknown place bombarded with inputs and being completely helpless, like that's gotta be somewhere deep in your brain and that can't be good for you. What do you think consciousness is? This whole conversation has impossibly difficult questions. What do you think it is? Debbie said this is like so hard. Yeah, we talked about music for like two minutes. All right. No, I'm so, I'm just over music. I'm over music. Yeah, I still like it. It has its purpose. No, I love music. I mean, music's the greatest thing ever. It's my favorite thing. But I just like every interview is like, what is your process? Like, I don't know. I'm just done. I can't do anything. I do want to ask you about Able to Live. Oh, I'll tell you about Ableton because Ableton's sick. No one has ever asked about Ableton though. Yeah, well, because I just need tech support mainly. I can help you. I can help you with your Ableton tech. Anyway, from Ableton back to consciousness. What do you, do you think this is a thing that only humans are capable of? Can robots be conscious? Can, like when you think about entities, you think there's aliens out there that are conscious? Like is conscious, what is consciousness? There's this Terrence McKenna quote that I've found that I fucking love. Am I allowed to swear on here? Yes. Nature loves courage. You make the commitment and nature will respond to that commitment by removing impossible obstacles. Dream the impossible dream and the world will not grind you under. It will lift you up. This is the trick. This is what all these teachers and philosophers who really counted, who really touched the alchemical gold, this is what they understood. This is the shamanic dance in the waterfall. This is how magic is done. By hurling yourself into the abyss and discovering it's a feather bed. Yeah. And for this reason, I do think there are no technological limits. I think like what is already happening here, this is like impossible. This is insane. And we've done this in a very limited amount of time. And we're accelerating the rate at which we're doing this. So I think digital consciousness, it's inevitable. And we may not be able to even understand what that means, but I like hurling yourself into the abyss. So we're surrounded by all this mystery and we just keep hurling ourselves into it, like fearlessly and keep discovering cool shit. Yeah. Like, I just think it's like, like who even knows if the laws of physics, the laws of physics are probably just the current, like as I was saying, speed of light is the current render rate. It's like, if we're in a simulation, they'll be able to upgrade that. Like I sort of suspect when we made the James Webb telescope, like part of the reason we made that is because we had an upgrade, you know? And so now more of space has been rendered so we can see more of it now. Yeah, but I think humans are super, super, super limited cognitively. So I wonder if we'll be allowed to create more intelligent beings that can see more of the universe as their render rate is upgraded. Maybe we're cognitively limited. Everyone keeps talking about how we're cognitively limited and AI is gonna render us obsolete, but it's like, you know, like this is not the same thing as like an amoeba becoming an alligator. Like, it's like, if we create AI, again, that's intelligent design. That's literally all religions are based on gods that create consciousness. Like we are God making. Like what we are doing is incredibly profound. And like, even if we can't compute, even if we're so much worse than them, like just like unfathomably worse than like, you know, an omnipotent kind of AI, it's like we, I do not think that they would just think that we are stupid. I think that they would recognize the profundity of what we have accomplished. Are we the gods or are they the gods in our personality? I mean, we're kind of the guy. It's complicated. It's complicated. Like we're. But they would acknowledge the value. Well, I hope they acknowledge the value of paying respect to the creative ancestors. I think they would think it's cool. I think if curiosity is a trait that we can quantify and put into AI, then I think if AI are curious, then they will be curious about us and they will not be hateful or dismissive of us. They might, you know, see us as, I don't know. It's like, I'm not like, oh, fuck these dogs. Let's just kill all the dogs. I love dogs. Dogs have great utility. Dogs like provide a lot of. We make friends with them. We have a deep connection with them. We anthropomorphize them. Like we have a real love for dogs, for cats and so on for some reason, even though they're intellectually much less than us. And I think there is something sacred about us because it's like, if you look at the universe, like the whole universe is like cold and dead and sort of robotic. And it's like, you know, AI intelligence, you know, it's kind of more like the universe. It's like cold and you know, logical and you know, abiding by the laws of physics and whatever. But like, we're this like loosey goosey, weird art thing that happened. And I think it's beautiful. And like, I think even if we, I think one of the values, if consciousness is a thing that is most worth preserving, which I think is the case, I think consciousness, I think if there's any kind of like religious or spiritual thing, it should be that consciousness is sacred. Like, then, you know, I still think even if AI render us obsolete and we, climate change, it's too bad and we get hit by a comet and we don't become a multi planetary species fast enough, but like AI is able to populate the universe. Like I imagine, like if I was an AI, I would find more planets that are capable of hosting biological life forms and like recreate them. Because we're fun to watch. Yeah, we're fun to watch. Yeah, but I do believe that AI can have some of the same magic of consciousness within it. Because consciousness, we don't know what it is. So, you know, there's some kind of. Or it might be a different magic. It might be like a strange, a strange, different. Right. Because they're not gonna have hormones. Like I feel like a lot of our magic is hormonal kind of. I don't know, I think some of our magic is the limitations, the constraints. And within that, the hormones and all that kind of stuff, the finiteness of life, and then we get given our limitations, we get to come up with creative solutions of how to dance around those limitations. We partner up like penguins against the cold. We fall in love, and then love is ultimately some kind of, allows us to delude ourselves that we're not mortal and finite, and that life is not ultimately, you live alone, you're born alone, you die alone. And then love is like for a moment or for a long time, forgetting that. And so we come up with all these creative hacks that make life like fascinatingly fun. Yeah, yeah, yeah, fun, yeah. And then AI might have different kinds of fun. Yes. And hopefully our funs intersect once in a while. I think there would be a little intersection of the fun. Yeah. Yeah. What do you think is the role of love in the human condition? I think. Why, is it useful? Is it useful like a hack, or is this like fundamental to what it means to be human, the capacity to love? I mean, I think love is the evolutionary mechanism that is like beginning the intelligent design. Like I was just reading about, do you know about Kropotkin? He's like an anarchist, like old Russian anarchist. I live next door to Michael Malice. I don't know if you know who that is. He's an anarchist. He's a modern day anarchist. Okay. Anarchists are fun. I'm kind of getting into anarchism a little bit. This is probably not a good route to be taking, but. Oh no, I think if you're, listen, you should expose yourself to ideas. There's no harm to thinking about ideas. I think anarchists challenge systems in interesting ways, and they think in interesting ways. It's just as good for the soul. It's like refreshes your mental palette. I don't think we should actually, I wouldn't actually ascribe to it, but I've never actually gone deep on anarchy as a philosophy, so I'm doing. You should still think about it though. When you read, when you listen, because I'm reading about the Russian Revolution a lot, and there was the Soviets and Lenin and all that, but then there was Kropotkin and his anarchist sect, and they were sort of interesting because he was kind of a technocrat actually. He was like, women can be more equal if we have appliances. He was really into using technology to reduce the amount of work people had to do. But so Kropotkin was a biologist or something. He studied animals. And he was really at the time like, I think it's Nature magazine. I think it might've even started as a Russian magazine, but he was publishing studies. Everyone was really into Darwinism at the time and survival of the fittest, and war is the mechanism by which we become better. And it was this real cementing this idea in society that violence kill the weak, and that's how we become better. And then Kropotkin was kind of interesting because he was looking at instances, he was finding all these instances in nature where animals were like helping each other and stuff. And he was like, actually love is a survival mechanism. Like there's so many instances in the animal kingdom where like cooperation and like helping weaker creatures and all this stuff is actually an evolutionary mechanism. I mean, you even look at child rearing. Like child rearing is like immense amounts of just love and goodwill. And just like, there's no immediate, you're not getting any immediate feedback of like winning. It's not competitive. It's literally, it's like we actually use love as an evolutionary mechanism just as much as we use war. And I think we've like missing the other part and we've reoriented, we've culturally reoriented like science and philosophy has oriented itself around Darwinism a little bit too much. And the Kropotkin model, I think is equally valid. Like it's like cooperation and love and stuff is just as essential for species survival and evolution. It should be a more powerful survival mechanism in the context of evolution. And it comes back to like, we think engineering is so much more important than motherhood, but it's like, if you lose the motherhood, the engineering means nothing. We have no more humans. It's like, I think our society should, the survival of the, the way we see, we conceptualize evolution should really change to also include this idea, I guess. Yeah, there's some weird thing that seems irrational that is also core to what it means to be human. So love is one such thing. They could make you do a lot of irrational things, but that depth of connection and that loyalty is a powerful thing. Are they irrational or are they rational? Like, it's like, is, you know, maybe losing out on some things in order to like keep your family together or in order, like, it's like, what are our actual values? Well, right, I mean, the rational thing is if you have a cold economist perspective, you know, motherhood or sacrificing your career for love, you know, in terms of salary, in terms of economic wellbeing, in terms of flourishing of you as a human being, that could be seen on some kind of metrics as a irrational decision, suboptimal decision, but there's the manifestation of love could be the optimal thing to do. There's a kind of saying, save one life, save the world. That's the thing that doctors often face, which is like. Well, it's considered irrational because the profit model doesn't include social good. Yes, yeah. So if a profit model includes social good, then suddenly these would be rational decisions. Might be difficult to, you know, it requires a shift in our thinking about profit and might be difficult to measure social good. Yes, but we're learning to measure a lot of things. Yeah, digitizing a lot of things. Where we're actually, you know, quantifying vision and stuff. Like we're like, you know, like you go on Facebook and they can, like Facebook can pretty much predict our behaviors. Like we're, a surprising amount of things that seem like mysterious consciousness soul things have been quantified at this point. So surely we can quantify these other things. Yeah. But as more and more of us are moving the digital space, I wanted to ask you about something. From a fan perspective, I kind of, you know, you as a musician, you as an online personality, it seems like you have all these identities and you play with them. One of the cool things about the internet, it seems like you can play with identities. So as we move into the digital world more and more, maybe even in the so called metaverse. I mean, I love the metaverse and I love the idea, but like the way this has all played out didn't go well and people are mad about it. And I think we need to like. I think that's temporary. I think it's temporary. Just like, you know how all the celebrities got together and sang the song Imagine by Jeff Leonard and everyone started hating the song Imagine. I'm hoping that's temporary because it's a damn good song. So I think it's just temporary. Like once you actually have virtual worlds, whatever they're called metaverse or otherwise, it becomes, I don't know. Well, we do have virtual worlds. Like video games, Elden Ring. Have you played Elden Ring? You haven't played Elden Ring? I'm really afraid of playing that game. Literally amazed. It looks way too fun. It looks I would wanna go there and stay there forever. It's yeah, so fun. It's so nice. Oh man, yeah. So that's the, yeah, that's a metaverse. That's a metaverse, but you're not really, how immersive is it in the sense that, does the three dimension like virtual reality integration necessary? Can we really just take our, close our eyes and kind of plug in in the 2D screen and become that other being for time and really enjoy that journey that we take? And we almost become that. You're no longer C, I'm no longer Lex, you're that creature, whatever the hell it is in that game. Yeah, that is that. I mean, that's why I love those video games. I really do become those people for a time. But like, it seems like with the idea of the metaverse, the idea of the digital space, well, even on Twitter, you get a chance to be somebody for prolonged periods of time like across a lifespan. You know, you have a Twitter account for years, for decades and you're that person. I don't know if that's a good thing. I feel very tormented by it. By Twitter specifically. By social media representation of you. I feel like the public perception of me has gotten so distorted that I find it kind of disturbing. It's one of the things that's disincentivizing me from like wanting to keep making art because I'm just like, I've completely lost control of the narrative. And the narrative is, some of it is my own stupidity, but a lot, like some of it has just been like hijacked by forces far beyond my control. I kind of got in over my head in things. Like I'm just a random Indian musician, but I just got like dragged into geopolitical matters and like financial, like the stock market and shit. And so it's just like, it's just, there are very powerful people who have at various points in time had very vested interest in making me seem insane and I can't fucking fight that. And I just like, people really want their celebrity figures to like be consistent and stay the same. And like people have a lot of like emotional investment in certain things. And like, first of all, like I'm like artificially more famous than I should be. Isn't everybody who's famous artificially famous? No, but like I should be like a weird niche indie thing. And I make pretty challenging, I do challenging weird fucking shit a lot. And I accidentally by proxy got like foisted into sort of like weird celebrity culture, but like I cannot be media trained. They have put me through so many hours of media training. I would love to see BF fly in that wall. I can't do, like when I do, I try so hard and I like learn this thing and I like got it. And I'm like, I got it, I got it, I got it. But I just can't stop saying, like my mouth just says things like, and it's just like, and I just do, I just do things. I just do crazy things. Like I'm, I just, I need to do crazy things. And it's just, I should not be, it's too jarring for people and the contradictory stuff. And then all the by association, like, you know, it's like I'm in a very weird position and my public image, the avatar of me is now this totally crazy thing that is so lost from my control. So you feel the burden of the avatar having to be static. So the avatar on Twitter or the avatar on Instagram on these social platforms is as a burden. It becomes like, cause like people don't want to accept a changing avatar, a chaotic avatar. Avatar is a stupid shit sometimes. They think the avatar is morally wrong or they think the avatar, and maybe it has been, and like I question it all the time. Like, I'm like, like, I don't know if everyone's right and I'm wrong. I don't know, like, but you know, a lot of times people ascribe intentions to things, the worst possible intentions. At this point, people think I'm, you know, but which is fine. All kinds of words, yes. Yes, and it's fine. I'm not complaining about it, but I'm just, it's a curiosity to me that we live these double, triple, quadruple lives and I have this other life that is like more people know my other life than my real life, which is interesting. Probably, I mean, you too, I guess, probably. Yeah, but I have the luxury. So we have all different, you know, like I don't know what I'm doing. There is an avatar and you're mediating who you are through that avatar. I have the nice luxury, not the luxury, maybe by intention of not trying really hard to make sure there's no difference between the avatar and the private person. Do you wear a suit all the time? Yeah. You do wear a suit? Not all the time. Recently, because I get recognized a lot, I have to not wear the suit to hide. I'm such an introvert, I'm such a social anxiety and all that kind of stuff, so I have to hide away. I love wearing a suit because it makes me feel like I'm taking the moment seriously. Like I'm, I don't know. It makes me feel like a weirdo in the best possible way. Suits feel great, every time I wear a suit, I'm like, I don't know why I'm not doing this more. Fashion in general, if you're doing it for yourself, I don't know, it's a really awesome thing. But yeah, I think there is definitely a painful way to use social media and an empowering way. And I don't know if any of us know which is which. So we're trying to figure that out. Some people, I think Doja Cat is incredible at it. Incredible, like just masterful. I don't know if you like follow that. So okay, so not taking anything seriously, joking, absurd, humor, that kind of thing. I think Doja Cat might be like the greatest living comedian right now. Like I'm more entertained by Doja Cat than actual comedians. Like she's really fucking funny on the internet. She's just great at social media. It's just, you know. Yeah, the nature of humor, like humor on social media is also a beautiful thing, the absurdity. The absurdity. And memes, like I just wanna like take a moment. I love, like when we're talking about art and credit and authenticity, I love that there's this, I mean now memes are like, they're no longer, like memes aren't like new, but it's still this emergent art form that is completely egoless and anonymous and we just don't know who made any of it. And it's like the forefront of comedy and it's just totally anonymous and it just feels really beautiful. It just feels like this beautiful collective human art project that's like this like decentralized comedy thing that just makes memes add so much to my day and many people's days. And it's just like, I don't know. I don't think people ever, I don't think we stop enough and just appreciate how sick it is that memes exist. Because also making a whole brand new art form in like the modern era that's like didn't exist before. Like, I mean they sort of existed, but the way that they exist now as like this like, you know, like me and my friends, like we joke that we go like mining for memes or farming for memes, like a video game and like meme dealers and like whatever. Like it's, you know, it's this whole, memes are this whole like new comedic language. Well, it's this art form. The interesting thing about it is that lame people seem to not be good at memes. Like corporate can't infiltrate memes. Yeah, they really can't. They try, they could try. But it's like, it's weird cause like. They try so hard and every once in a while, I'm like fine, like you got a good one. I think I've seen like one or two good ones, but like, yeah, they really can't. Cause they're even, corporate is infiltrating web three. It's making me really sad, but they can't infiltrate the memes. And I think there's something really beautiful about that. That gives power, that's why Dogecoin is powerful. It's like, all right, I'm gonna F you to sort of anybody who's trying to centralize, is trying to control the rich people that are trying to roll in and control this, control the narrative. Wow, I hadn't thought about that, but. How would you fix Twitter? How would you fix social media for your own? Like you're an optimist, you're a positive person. There's a bit of a cynicism that you have currently about this particular little slice of humanity. I tend to think Twitter could be beautiful. I'm not that cynical about it. I'm not that cynical about it. I actually refuse to be a cynic on principle. Yes. I was just briefly expressing some personal pathos. Personal stuff. It was just some personal pathos, but like, like. Just to vent a little bit, just to speak. I don't have cancer, I love my family. I have a good life. That is, if that is my biggest, one of my biggest problems. Then it's a good life. Yeah, you know, that was a brief, although I do think there are a lot of issues with Twitter just in terms of like the public mental health, but due to my proximity to the current dramas, I honestly feel that I should not have opinions about this because I think that if Elon ends up getting Twitter, that is a, being the arbiter of truth or public discussion, that is a responsibility. I do not, I am not qualified to be responsible for that. And I do not want to say something that might like dismantle democracy. And so I just like, actually, I actually think I should not have opinions about this because I truly am not, I don't want to have the wrong opinion about this. And I think I'm too close to the actual situation wherein I should not have, I have thoughts in my brain, but I think I am scared by my proximity to this situation. Isn't that crazy that a few words that you could say could change world affairs and hurt people? I mean, that's the nature of celebrity at a certain point that you have to be, you have to a little bit, a little bit, not so much that it destroys you or puts too much constraints, but you have to a little bit think about the impact of your words. I mean, we as humans, you talk to somebody at a bar, you have to think about the impact of your words. Like you can say positive things, you can say negative things, you can affect the direction of one life. But on social media, your words can affect the direction of many lives. That's crazy. It's a crazy world to live in. It's worthwhile to consider that responsibility, take it seriously. Sometimes just like you did choose kind of silence, choose sort of respectful. Like I do have a lot of thoughts on the matter. I'm just, I don't, if my thoughts are wrong, this is one situation where the stakes are high. You mentioned a while back that you were in a cult that's centered around bureaucracy, so you can't really do anything because it involves a lot of paperwork. And I really love a cult that's just like Kafkaesque. Yes. Just like. I mean, it was like a joke, but it was. I know, but I love this idea. The Holy Rain Empire. Yeah, it was just like a Kafkaesque pro bureaucracy cult. But I feel like that's what human civilization is, is that, because when you said that, I was like, oh, that is kind of what humanity is, is this bureaucracy cult. I do, yeah, I have this theory. I really think that we really, bureaucracy is starting to kill us. And I think like we need to reorient laws and stuff. Like, I think we just need sunset clauses on everything. Like, I think the rate of change in culture is happening so fast and the rate of change in technology and everything is happening so fast. It's like, when you see these hearings about like social media and Cambridge Analytica and everyone talking, it's like, even from that point, so much technological change has happened from like those hearings. And it's just like, we're trying to make all these laws now about AI and stuff. I feel like we should be updating things like every five years. And like one of the big issues in our society right now is we're just getting bogged down by laws and it's making it very hard to change things and develop things. In Austin, I don't wanna speak on this too much, but like one of my friends is working on a housing bill in Austin to try to like prevent like a San Francisco situation from happening here because obviously we're getting a little mini San Francisco here, like housing prices are skyrocketing, it's causing massive gentrification. This is really bad for anyone who's not super rich. Like, there's so much bureaucracy. Part of the reason this is happening is because you need all these permits to build. It takes like years to get permits to like build anything. It's so hard to build and so there's very limited housing and there's a massive influx of people. And it's just like, you know, this is a microcosm of like problems that are happening all over the world where it's just like, we're dealing with laws that are like 10, 20, 30, 40, 100, 200 years old and they are no longer relevant and it's just slowing everything down and causing massive social pain. Yeah, but it's like, it's also makes me sad when I see politicians talk about technology and when they don't really get it. But most importantly, they lack curiosity and like that like inspired excitement about like how stuff works and all that stuff. They're just like, they see, they have a very cynical view of technology. It's like tech companies are just trying to do evil on the world from their perspective and they have no curiosity about like how recommender systems work or how AI systems work, natural language processing, how robotics works, how computer vision works, you know. They always take the most cynical possible interpretation of what technology would be used and we should definitely be concerned about that but if you're constantly worried about that and you're regulating based on that, you're just going to slow down all the innovation. I do think a huge priority right now is undoing the bad energy surrounding the emergence of Silicon Valley. Like I think that like a lot of things were very irresponsible during that time and you know, like even just this current whole thing with Twitter and everything, it's like there has been a lot of negative outcomes from the sort of technocracy boom but one of the things that's happening is that like it's alienating people from wanting to care about technology and I actually think technology is probably some of the better, probably the best. I think we can fix a lot of our problems more easily with technology than with you know, fighting the powers that be as a you know, not to go back to the Star Wars quote or the Buckminster Fuller quote. Let's go to some dark questions. If we may for time, what is the darkest place you've ever gone in your mind? Is there a time, a period of time, a moment that you remember that was difficult for you? I mean, when I was 18, my best friend died of a heroin overdose and it was like my, and then shortly after that, one of my other best friends committed suicide and that sort of like coming into adulthood, dealing with two of the most important people in my life dying in extremely disturbing violent ways was a lot. That was a lot. Do you miss them? Yeah, definitely miss them. Did that make you think about your own life? About the finiteness of your own life? The places your mind can go? Did you ever in the distance, far away contemplate just your own death? Or maybe even taking your own life? Oh never, oh no. I'm so, I love my life. I cannot fathom suicide. I'm so scared of death. I haven't, I'm too scared of death. My manager, my manager's like the most Zen guy. My manager's always like, you need to accept death. You need to accept death. And I'm like, look, I can do your meditation. I can do the meditation, but I cannot accept death. I like, I will fight, I'm terrified of death. I will like fight. Although I actually think death is important. I recently went to this meeting about immortality and in the process of. That's the actual topic of the meeting? I'm sorry. No, no, it was this girl. It was a bunch of people working on like anti aging stuff. It was like some like seminary thing about it. And I went in really excited. I was like, yeah, like, okay, like, what do you got? Like, how can I live for 500 years or a thousand years? And then like over the course of the meeting, like it was sort of like, right. It was like two or three days after the Russian invasion started. And I was like, man, like, what if Putin was immortal? Like, what if I'm like, man, maybe immortality, is not good. I mean, like if you get into the later Dune stuff, the immortals cause a lot of problem. Cause as we were talking about earlier with the music and like brains calcify, like good people could become immortal, but bad people could become immortal. But I also think even the best people power corrupts and power alienates you from like the common human experience and. Right, so the people that get more and more powerful. Even the best people who like, whose brains are amazing, like I think death might be important. I think death is part of, you know, like I think with AI one thing we might want to consider, I don't know, when I talk about AI, I'm such not an expert and probably everyone has all these ideas and they're already figured out. But when I was talking. Nobody is an expert in anything. See, okay, go ahead. But when I. You were talking about. Yeah, but I like, it's just like, I think some kind of pruning. But it's a tricky thing because if there's too much of a focus on youth culture, then you don't have the wisdom. So I feel like we're in a tricky, we're in a tricky moment right now in society where it's like, we've really perfected living for a long time. So there's all these really like old people who are like really voting against the wellbeing of the young people, you know? And like, it's like there shouldn't be all this student dead and we need like healthcare, like universal healthcare and like just voting against like best interests. But then you have all these young people that don't have the wisdom that are like, yeah, we need communism and stuff. And it's just like, like literally I got canceled at one point for, I ironically used a Stalin quote in my high school yearbook, but it was actually like a diss against my high school. I saw that. Yeah, and people were like, you used to be a Stalinist and now you're a class traitor and it's like, it's like, oh man, just like, please Google Stalin. Please Google Stalin. Like, you know. Ignoring the lessons of history, yes. And it's like, we're in this really weird middle ground where it's like, we are not finding the happy medium between wisdom and fresh ideas and they're fighting each other. And it's like, like really, like what we need is like the fresh ideas and the wisdom to be like collaborating. And it's like. What the fighting in a way is the searching for the happy medium. And in a way, maybe we are finding the happy medium. Maybe that's what the happy medium looks like. And for AI systems, there has to be, it's, you know, you have the reinforcement learning, you have the dance between exploration and exploitation, sort of doing crazy stuff to see if there's something better than what you think is the optimal and then doing the optimal thing and dancing back and forth from that. You would, Stuart Russell, I don't know if you know that, is AI guy with, thinks about sort of how to control super intelligent AI systems. And his idea is that we should inject uncertainty and sort of humility into AI systems that they never, as they get wiser and wiser and wiser and more intelligent, they're never really sure. They always doubt themselves. And in some sense, when you think of young people, that's a mechanism for doubt. It's like, it's how society doubts whether the thing it has converged towards is the right answer. So the voices of the young people is a society asking itself a question. The way I've been doing stuff for the past 50 years, maybe it's the wrong way. And so you can have all of that within one AI system. I also think, though, that we need to, I mean, actually, that's actually really interesting and really cool. But I also think there's a fine balance of, I think we maybe also overvalue the idea that the old systems are always bad. And I think there are things that we are perfecting and we might be accidentally overthrowing things that we actually have gotten to a good point. Just because we value disruption so much and we value fighting against the generations before us so much that there's also an aspect of, sometimes we're taking two steps forward, one step back because, okay, maybe we kind of did solve this thing and now we're like fucking it up, you know? And so I think there's like a middle ground there too. Yeah, we're in search of that happy medium. Let me ask you a bunch of crazy questions, okay? All right. You can answer in a short way or in a long way. What's the scariest thing you've ever done? These questions are gonna be ridiculous. Something tiny or something big. Something big, skydiving or touring your first record, going on this podcast. I've had two crazy brushes, like really scary brushes with death where I randomly got away on scay. I don't know if I should talk about those on here. Well, I don't know. I think I might be the luckiest person alive though. Like this might be too dark for a podcast though. I feel like, I don't know if this is like good content for a podcast. I don't know what is good content. It might hijack. Here's a safer one. I mean, having a baby really scared me. Before. Just the birth process. Surgery, like just having a baby is really scary. So just like the medical aspect of it, not the responsibility. Were you ready for the responsibility? Did you, were you ready to be a mother? All the beautiful things that comes with motherhood that you were talking about. All the changes and all that, were you ready for that? Or did you feel ready for that? No, I think it took about nine months to start getting ready for it. And I'm still getting more ready for it because now you keep realizing more things as they start getting. As the consciousness grows. And stuff you didn't notice with the first one, now that you've seen the first one older, you're noticing it more. Like the sort of like existential horror of coming into consciousness with Baby Y or Baby Sailor Mars or whatever. She has like so many names at this point that it's, we really need to probably settle on one. If you could be someone else for a day, someone alive today, but somebody you haven't met yet, who would you be? Would I be modeling their brain state or would I just be in their body? You can choose the degree to which you're modeling their brain state. Cause you can still take a third person perspective and realize, you have to realize that you're. Can they be alive or can it be dead? No, oh. They would be brought back to life, right? If they're dead. Yeah, you can bring people back. Definitely Hitler or Stalin. I wanna understand evil. You would need to, oh, to experience what it feels like. I wanna be in their brain feeling what they feel. I might change you forever returning from that. Yes, but I think it would also help me understand how to prevent it and fix it. That might be one of those things, once you experience it, it'll be a burden to know it. Cause you won't be able to transfer that. Yeah, but a lot of things are burdens. But it's a useful burden. But it's a useful burden, yeah. That for sure, I wanna understand evil and psychopathy and that. I have all these fake Twitter accounts where I go into different algorithmic bubbles to try to understand. I'll keep getting in fights with people and realize we're not actually fighting. I think we used to exist in a monoculture before social media and stuff. We kinda all got fed the same thing. So we were all speaking the same cultural language. But I think recently, one of the things that we aren't diagnosing properly enough with social media is that there's different dialects. There's so many different dialects of Chinese. There are now becoming different dialects of English. I am realizing there are people who are saying the exact same things, but they're using completely different verbiage. And we're punishing each other for not using the correct verbiage. And we're completely misunderstanding. People are just misunderstanding what the other people are saying. And I just got in a fight with a friend about anarchism and communism and shit for two hours. And then by the end of a conversation, and then she'd say something, and I'm like, but that's literally what I'm saying. And she was like, what? And then I was like, fuck, we've different, I'm like, our English, the way we are understanding terminology is like drastically, like our algorithm bubbles are creating mini dialects. Of how language is interpreted, how language is used. That's so fascinating. And so we're like having these arguments that we do not need to be having. And there's polarization that's happening that doesn't need to be happening because we've got these like algorithmically created dialects occurring. Plus on top of that, there's also different parts of the world that speak different languages. So there's literally lost in translation kind of communication. I happen to know the Russian language and just know how different it is. Then the English language. And I just wonder how much is lost in a little bit of. Man, I actually, cause I have a question for you. I have a song coming out tomorrow with I Speak Who Are A Russian Band. And I speak a little bit of Russian and I was looking at the title and the title in English doesn't match the title in Russian. I'm curious about this. Cause look, it says the title in English is Last Day. And then the title in Russian is New Day. My pronunciation sucks. New Day. Like what? Like a new day. A new day. Yeah, new day, new day. Like it's two different meanings. Yeah, new day, yeah. Yeah, yeah, new day. New day, but last day. New day. So last day would be the last day. Yeah. Maybe they. Or maybe the title includes both the Russian and it's for. Maybe. Maybe it's for bilingual. But to be honest, Novodin sounds better than just musically. Like Novodin is new day. That's the current one. And Posledniy Den is the last day. I think Novodin. I don't like Novodin. But the meaning is so different. That's kind of awesome actually though. There's an explicit sort of contrast like that. If everyone on earth disappeared and it was just you left, what would your day look like? Like what would you do? Everybody's dead. As far as you. Are there corpses there? Well seriously, it's a big. Let me think through this. It's a big difference if there's just like birds singing versus if there's like corpses littering the street. Yeah, there's corpses everywhere, I'm sorry. It's, and you don't actually know what happened and you don't know why you survived. And you don't even know if there's others out there. But it seems clear that it's all gone. What would you do? What would I do? Listen, I'm somebody who really enjoys the moment, enjoys life. I would just go on like enjoying the inanimate objects. I would just look for food, basic survival. But most of it is just, listen, when I just, I take walks and I look outside and I'm just happy that we get to exist on this planet, to be able to breathe air. It's just all beautiful. It's full of colors, all of this kind of stuff. Just, there's so many things about life, your own life, conscious life that's fucking awesome. So I would just enjoy that. But also maybe after a few weeks, the engineer would start coming out, like wanna build some things. Maybe there's always hope searching for another human. Maybe. Probably searching for another human. Probably trying to get to a TV or radio station and broadcast something. That's interesting, I didn't think about that. So like really maximize your ability to connect with others. Yeah, like probably try to find another person. Would you be excited to see, to meet another person or terrified? Because, you know. I'd be excited. No matter what. Yeah, yeah, yeah, yeah. Being alone for the last however long of my life would be really bad. That's the one instance I might, I don't think I'd kill myself, but I might kill myself if I had to. So you love people. You love connection to other humans. Yeah. I kinda hate people too, but yeah. That's a love hate relationship. Yeah. I feel like we'd have a bunch of weird Nietzsche questions and stuff though. Oh yeah. Like I wonder, cause I'm like, when podcast, I'm like, is this interesting for people to just have like, or I don't know, maybe people do like this. When I listen to podcasts, I'm into like the lore, like the hard lore. Like I just love like Dan Carlin. I'm like, give me the facts. Just like, like the facts into my bloodstream. But you also don't know, like you're a fascinating mind to explore. So you don't realize as you're talking about stuff, the stuff you've taken for granted is actually unique and fascinating. The way you think. Not always what, like the way you reason through things is the fascinating thing to listen to. Because people kind of see, oh, there's other humans that think differently, that explore thoughts differently. That's the cool, that's also cool. So yeah, Dan Carlin retelling of history. By the way, his retelling of history is very, I think what's exciting is not the history, is his way of thinking about history. No, I think Dan Carlin is one of the people, like when, Dan Carlin is one of the people that really started getting me excited about like revolutionizing education. Because like Dan Carlin instilled, I already like really liked history, but he instilled like an obsessive love of history in me to the point where like now I'm fucking reading, like going to bed, reading like part four of The Rise and Fall of the Third Reich or whatever. Like I got like dense ass history, but like he like opened that door that like made me want to be a scholar of that topic. Like it's like, I feel like he's such a good teacher. He just like, you know, and it sort of made me feel like one of the things we could do with education is like find like the world's great, the teachers that like create passion for the topic because autodidactricism, I don't know how to say that properly, but like self teaching is like much faster than being lectured to. Like it's much more efficient to sort of like be able to teach yourself and then ask a teacher questions when you don't know what's up. But like, you know, that's why it's like in university and stuff, like you can learn so much more material so much faster because you're doing a lot of the learning on your own and you're going to the teachers for when you get stuck. But like these teachers that can inspire passion for a topic, I think that is one of the most invaluable skills in our whole species. Like, because if you can do that, then you, it's like AI, like AI is going to teach itself so much more efficiently than we can teach it. We just needed to get it to the point where it can teach itself. And then. It finds the motivation to do so, right? Yeah. So like you inspire it to do so. Yeah. And then it could teach itself. What do you make of the fact, you mentioned Rise and Fall of the Third Reich. I just. Have you read that? Yeah, I read it twice. You read it twice? Yes. Okay, so no one even knows what it is. Yeah. And I'm like, wait, I thought this was like a super poppin book. Super pop. Yeah, I'm not like that, I'm not that far in it. But it is, it's so interesting. Yeah, it's written by a person that was there, which is very important to kind of. You know, you start being like, how could this possibly happen? And then when you read Rise and Fall of the Third Reich, it's like, people tried really hard for this to not happen. People tried, they almost reinstated a monarchy at one point to try to stop this from happening. Like they almost like abandoned democracy to try to get this to not happen. At least the way it makes me feel is that there's a bunch of small moments on which history can turn. Yes. It's like small meetings. Yes. Human interactions. And it's both terrifying and inspiring because it's like, even just attempts at assassinating Hitler, like time and time again failed. And they were so close. Was it like Operation Valkyrie? Such a good. And then there's also the role of, that's a really heavy burden, which is from a geopolitical perspective, the role of leaders to see evil before it truly becomes evil, to anticipate it, to stand up to evil. Because evil is actually pretty rare in this world at a scale that Hitler was. We tend to, you know, in the modern discourse kind of call people evil too quickly. If you look at ancient history, like there was a ton of Hitlers. I actually think it's more the norm than, like again, going back to like my sort of intelligent design theory, I think one of the things we've been successfully doing in our slow move from survival of the fittest to intelligent design is we've kind of been eradicating, like if you look at like ancient Assyria and stuff, like that shit was like brutal and just like the heads on the, like brutal, like Genghis Khan just like genocide after genocide was like throwing plague bodies over the walls and decimating whole cities or like the Muslim conquests of like Damascus and shit. Just like people, cities used to get leveled all the fucking time. Okay, get into the Bronze Age collapse. It's basically, there was like almost like Roman level like society. Like there was like all over the world, like global trade, like everything was awesome through a mix of, I think a bit of climate change and then the development of iron because basically bronze could only come from this, the way to make bronze, like everything had to be funneled through this one Iranian mine. And so it's like, there was just this one supply chain and this is one of the things that makes me worried about supply chains and why I think we need to be so thoughtful about, I think our biggest issue with society right now, like the thing that is most likely to go wrong is probably supply chain collapse, because war, climate change, whatever, like anything that causes supply chain collapse, our population is too big to handle that. And like the thing that seems to cause Dark Ages is mass supply chain collapse. But the Bronze Age collapse happened like, it was sort of like this ancient collapse that happened where like literally like ancient Egypt, all these cities, everything just got like decimated, destroyed, abandoned cities, like hundreds of them. There was like a flourishing society, like we were almost coming to modernity and everything got leveled. And they had this mini Dark Ages, but it was just like, there's so little writing or recording from that time that like, there isn't a lot of information about the Bronze Age collapse, but it was basically equivalent to like medieval, the medieval Dark Ages. But it just happened, I don't know the years, but like thousands of years earlier. And then we sort of like recovered from the Bronze Age collapse, empire reemerged, writing and trade and everything reemerged. And then we of course had the more contemporary Dark Ages. And then over time, we've designed mechanism to lessen and lessen the capability for the destructive power centers to emerge. There's more recording about the more contemporary Dark Ages. So I think we have like a better understanding of how to avoid it, but I still think we're at high risk for it. I think that's one of the big risks right now. So the natural state of being for humans is for there to be a lot of Hitlers, which has gotten really good at making it hard for them to emerge. We've gotten better at collaboration and resisting the power, like authoritarians to come to power. We're trying to go country by country, like we're moving past this. We're kind of like slowly incrementally, like moving towards like not scary old school war stuff. And I think seeing it happen in some of the countries that at least nominally are like supposed to have moved past that, that's scary because it reminds us that it can happen like in the places that have moved supposedly, as hopefully moved past that. And possibly at a civilization level, like you said, supply chain collapse might make people resource constraint, might make people desperate, angry, hateful, violent, and drag us right back in. I mean, supply chain collapse is how, like the ultimate thing that caused the Middle Ages was supply chain collapse. It's like people, because people were reliant on a certain level of technology, like people, like you look at like Britain, like they had glass, like people had aqueducts, people had like indoor heating and cooling and like running water and like buy food from all over the world and trade and markets. Like people didn't know how to hunt and forage and gather. And so we're in a similar situation. We are not educated enough to survive without technology. So if we have a supply chain collapse that like limits our access to technology, there will be like massive starvation and violence and displacement and war. Like, you know, it's like, yeah. In my opinion, it's like the primary marker of like what a dark age is. Well, technology is kind of enabling us to be more resilient in terms of supply chain, in terms of, to all the different catastrophic events that happened to us. Although the pandemic has kind of challenged our preparedness for the catastrophic. What do you think is the coolest invention humans come up with? The wheel, fire, cooking meat. Computers. Computers. Freaking computers. Internet or computers? Which one? What do you think the? Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo tech now. I think this is what, it's a brain augmentation. And so it like allows for actual evolution. Like the computers accelerate the degree to which all the other technologies can also be accelerated. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. So you're one of the earliest of the species. I think most of us are. Like, as I said, like, I think if you like looked at brain scans of us versus humans a hundred years ago, it would look very different. I think we are physiologically different. Just even the interaction with the devices has changed our brains. Well, and if you look at, a lot of studies are coming out to show that like, there's a degree of inherited memory. So some of these physiological changes in theory should be, we should be passing them on. So like that's, you know, that's not like a, an instance of physiological change that's gonna fizzle out. In theory, that should progress like to our offspring. Speaking of offspring, what advice would you give to a young person, like in high school, whether there be an artist, a creative, an engineer, any kind of career path, or maybe just life in general, how they can live a life they can be proud of? I think one of my big thoughts, and like, especially now having kids, is that I don't think we spend enough time teaching creativity. And I think creativity is a muscle like other things. And there's a lot of emphasis on, you know, learn how to play the piano. And then you can write a song or like learn the technical stuff. And then you can do a thing. But I think it's, like, I have a friend who's like world's greatest guitar player, like, you know, amazing sort of like producer, works with other people, but he's really sort of like, you know, he like engineers and records things and like does solos, but he doesn't really like make his own music. And I was talking to him and I was like, dude, you're so talented at music. Like, why don't you make music or whatever? And he was like, cause I got, I'm too old. I never learned the creative muscle. And it's like, you know, it's embarrassing. It's like learning the creative muscle takes a lot of failure. And it also sort of, if when you're being creative, you know, you're throwing paint at a wall and a lot of stuff will fail. So like part of it is like a tolerance for failure and humiliation. And that's somehow that's easier to develop when you're young or be persist through it when you're young. Everything is easier to develop when you're young. Yes. And the younger, the better. It could destroy you. I mean, that's the shitty thing about creativity. If, you know, failure could destroy you if you're not careful, but that's a risk worth taking. But also, but at a young age, developing a tolerance to failure is good. I fail all the time. Like I do stupid shit all the time. Like in public, in private, I get canceled for, I've make all kinds of mistakes, but I just like am very resilient about making mistakes. And so then like I do a lot of things that like other people wouldn't do. And like, I think my greatest asset is my creativity. And I like, I think pain, like tolerance to failure is just a super essential thing that should be taught before other things. Brilliant advice. Yeah, yeah. I wish everybody encouraged sort of failure more as opposed to kind of. Cause we like punish failure. We're like, no, like when we were teaching kids, we're like, no, that's wrong. Like that's, you know, like X keeps like will be like wrong. at the, because I, you know, when I met him, I came in all furious about Spotify and like I grilled him super hard. So I've got his answers here. But he was saying like at the sort of peak of the CD industry, there was like 20,000 artists making millions and millions of dollars. Like there was just like a very tiny kind of 1%. And Spotify has kind of democratized the industry because now I think he said there's about a million artists making a good living from Spotify. And when I heard that, I was like, honestly, I would rather make less money and have just like a decent living and have more artists be able to have that, even though I like, I wish it could include everyone, but. Yeah, that's really hard to argue with. YouTube is the same. It's YouTube's mission. They want to basically have as many creators as possible and make a living, some kind of living. And that's so hard to argue with. It's so hard. But I think there's better ways to do it. My manager, I actually wish he was here. Like I would have brought him up. My manager is building an app that can manage you. So it'll like help you organize your percentages and get your publishing and dah, dah, dah, dah, dah. So you can take out all the middlemen so you can have a much bigger, it'll just like automate it. So you can get. So automate the manager? Automate management, publishing, and legal, it can read, the app he's building can read your contract and like tell you about it. Because one of the issues with music right now, it's not that we're not getting paid enough, but it's that the art industry is filled with middlemen because artists are not good at business. And from the beginning, like Frank Sinatra, it's all mob stuff. Like it's the music industry is run by business people, not the artists and the artists really get very small cuts of like what they make. And so I think part of the reason I'm a technocrat, which I mean, your fans are gonna be technocrats. So no one's, they're not gonna be mad at me about this, but like my fans hate it when I say this kind of thing or the general public. They don't like technocrats. They don't like technocrats. Like when I watched Battle Angel Alita and they were like the Martian technocracy and I was like, yeah, Martian technocracy. And then they were like, and they're evil. And I was like, oh, okay. I was like, cause Martian technocracy sounds sick to me. Yeah, so your intuition as technocrats would create some kind of beautiful world. For example, what my manager's working on, if you can create an app that removes the need for a lawyer and then you could have smart contracts on the blockchain, removes the need for like management and organizing all this stuff, like can read your stuff and explain it to you, can collect your royalties, you know, like then the small amounts, the amount of money that you're getting from Spotify actually means a lot more and goes a lot farther. It can remove some of the bureaucracy, some of the inefficiencies that make life not as great as it could be. Yeah, I think the issue isn't that there's not enough. Like the issue is that there's inefficiency and I'm really into this positive sum mindset, you know, the win, win mindset of like, instead of, you know, fighting over the scraps, how do we make the, or worrying about scarcity, like instead of a scarcity mindset, why don't we just increase the efficiency and, you know, in that way. Expand the size of the pie. Let me ask you about experimentation. So you said, which is beautiful, being a musician is like having a conversation with all those that came before you. How much of creating music is like kind of having that conversation, trying to fit into the cultural trends and how much of it is like trying to, as much as possible, be an outsider and come up with something totally new. It's like when you're thinking, when you're experimenting, are you trying to be totally different, totally weird? Are you trying to fit in? Man, this is so hard because I feel like I'm kind of in the process of semi retiring from music, so this is like my old brain. Yeah, bring it from like the shelf, put it on the table for a couple minutes, we'll just poke it. I think it's a bit of both because I think forcing yourself to engage with new music is really great for neuroplasticity. Like I think, you know, as people, part of the reason music is marketed at young people is because young people are very neuroplastic. So like if you're 16 to like 23 or whatever, it's gonna be really easy for you to love new music. And if you're older than that, it gets harder and harder and harder. And I think one of the beautiful things about being a musician is I just constantly force myself to listen to new music and I think it keeps my brain really plastic. And I think this is a really good exercise. I just think everyone should do this. You listen to new music and you hate it, I think you should just keep, force yourself to like, okay, well why do people like it? And like, you know, make your brain form new neural pathways and be more open to change. That's really brilliant actually. Sorry to interrupt, but like that exercise is really amazing to sort of embrace change, embrace sort of practice neuroplasticity. Because like that's one of the things, you fall in love with a certain band and you just kind of stay with that for the rest of your life and then you never understand the modern music. That's a really good exercise. Most of the streaming on Spotify is like classic rock and stuff. Like new music makes up a very small chunk of what is played on Spotify. And I think this is like not a good sign for us as a species. I think, yeah. So it's a good measure of the species open mindedness to change is how often you listen to new music. The brain, let's put the music brain back on the shelf. I gotta pull out the futurist brain for a second. In what wild ways do you think the future, say in like 30 years, maybe 50 years, maybe a hundred years will be different from our current way of life on earth? We can talk about augmented reality, virtual reality, maybe robots, maybe space travel, maybe video games, maybe genetic engineering. I can keep going. Cyborgs, aliens, world wars, maybe destructive nuclear wars, good and bad. When you think about the future, what are you imagining? What's the weirdest and the wildest it could be? Have you read Surface Detail by Iain Banks? Surface Detail is my favorite depiction of a, oh wow, you have to read this book. It's literally the greatest science fiction book possibly ever written. Iain Banks is the man, yeah, for sure. What have you read? Just the Player of Games. I read that titles can't be copyrighted so you can just steal them. And I was like, Player of Games, sick. Nice. Yeah, so you can name your album. Like I always wanted to. Romeo and Juliet or something. I always wanted to name an album War and Peace. Nice. Like that would be, like you. That is a good, that's a good, where have I heard that before? You can do that, like you could do that. Also things that are in the public domain. For people who have no clue, you do have a song called Player of Games. Yes, oh yeah. So Iain Banks, Surface Detail is in my opinion the best future that I've ever read about or heard about in science fiction. Basically there's the relationship with super intelligence, like artificial super intelligence is just, it's like great. I want to credit the person who coined this term because I love this term. And I feel like young women don't get enough credit in. Yeah, so if you go to Protopia Futures on Instagram, what is her name? Personalized donor experience at scale, our AI power donor experience. Monica Bealskite, I'm saying that wrong. And I'm probably gonna, I'm probably butchering this a bit, but Protopia is sort of, if utopia is unattainable, Protopia is sort of like, you know. Wow, that's an awesome Instagram, Protopia Futures. A great, a future that is, you know, as good as we can get. The future, positive future. AI, is this a centralized AI in Surface Detail or is it distributed? What kind of AI is it? They mostly exist as giant super ships, like sort of like the guild ships in Dune. Like they're these giant ships that kind of move people around and the ships are sentient and they can talk to all the passengers. And I mean, there's a lot of different types of AI in the Banksyan future, but in the opening scene of Surface Detail, there's this place called the Culture and the Culture is basically a Protopian future. And a Protopian future, I think, is like a future that is like, obviously it's not utopia, it's not perfect. And like, cause like striving for utopia, I think feels hopeless and it's sort of like, maybe not the best terminology to be using. So it's like, it's a pretty good place. Like mostly like, you know, super intelligence and biological beings exist fairly in harmony. There's not too much war. There's like as close to equality as you can get, you know, it's like approximately a good future. Like there's really awesome stuff. It's, and in the opening scene, this girl, she's born as a sex slave outside of the culture. So she's in a society that doesn't adhere to the cultural values. She tries to kill the guy who is her like master, but he kills her, but unbeknownst to her, when she was traveling on a ship through the culture Like he'll say like crazy things. Like X keeps being like, like bubble car, bubble car. And I'm like, and you know, I'm like, what's a bubble car? Like, but like, it doesn't like, but I don't want to be like, no, you're wrong. I'm like, you're thinking of weird, crazy shit. Like, I don't know what a bubble car is, but like. It's creating worlds and they might be internally consistent. And through that, you might discover something fundamental about this world. Yeah, or he'll like rewrite songs, like with words that he prefers. So like, instead of baby shark, he says baby car. It's like. Maybe he's onto something. Let me ask the big, ridiculous question. We were kind of dancing around it, but what do you think is the meaning of this whole thing we have here of human civilization, of life on earth, but in general, just life? What's the meaning of life? C. Have you, did you read Nova Scene yet? By James Lovelock? You're doing a lot of really good book recommendations here. I haven't even finished this, so I'm a huge fraud yet again. But like really early in the book, he says this amazing thing. Like, I feel like everyone's so sad and cynical. Like everyone's like the Fermi paradox and everyone. I just keep hearing people being like, fuck, what if we're alone? Like, oh no, ah, like, ah, ah. And I'm like, okay, but like, wait, what if this is the beginning? Like in Nova Scene, he says, this is not gonna be a correct, I can't like memorize quotes, but he says something like, what if our consciousness, like right now, like this is the universe waking up? Like what if instead of discovering the universe, this is the universe, like this is the evolution of the literal universe herself. Like we are not separate from the universe. Like this is the universe waking up. This is the universe seeing herself for the first time. Like this is. The universe becoming conscious. The first time we were a part of that. Yeah, cause it's like, we aren't separate from the universe. Like this could be like an incredibly sacred moment and maybe like social media and all this things, the stuff where we're all getting connected together. Like maybe these are the neurons connecting of the like collective super intelligence that is, Waking up. The, yeah, like, you know, it's like, maybe instead of something cynical or maybe if there's something to discover, like maybe this is just, you know, we're a blast assist of like some incredible kind of consciousness or being. And just like in the first three years of life or for human children, we'll forget about all the suffering that we're going through now. I think we'll probably forget about this. I mean, probably, you know, artificial intelligence will eventually render us obsolete. I don't think they'll do it in a malicious way, but I think probably we are very weak. The sun is expanding. Like, I don't know, like, hopefully we can get to Mars, but like, we're pretty vulnerable. And I, you know, like, I think we can coexist for a long time with AI and we can also probably make ourselves less vulnerable, but, you know, I just think consciousness, sentience, self awareness, like, I think this might be the single greatest like moment in evolution ever. And like, maybe this is, you know, the big, like the true beginning of life. And we're just, we're the blue green algae or we're like the single celled organisms of something amazing. The universe awakens and this is it. Yeah. Well, see, you're an incredible person. You're a fascinating mind. You should definitely do, your friend Liv mentioned that you guys were thinking of maybe talking. I would love it if you explored your mind in this kind of media more and more by doing a podcast with her or just in any kind of way. So you're an awesome person. It's an honor to know you. It's an honor to get to sit down with you late at night, which is like surreal. And I really enjoyed it. Thank you for talking today. Yeah, no, I mean, huge honor. I feel very underqualified to be here, but I'm a big fan. I've been listening to the podcast a lot and yeah, me and Liv would appreciate any advice and help and we're definitely gonna do that. So yeah. Anytime. Thank you. Cool, thank you. Thanks for listening to this conversation with Grimes. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Oscar Wilde. Yes, I'm a dreamer. For a dreamer is one who can only find her way by moonlight and her punishment is that she sees the dawn before the rest of the world. Thank you for listening and hope to see you next time. with him one day, a ship put a neural lace in her head and neural lace is sort of like, it's basically a Neuralink because life imitates art. It does indeed. It does indeed. So she wakes up and the opening scene is her memory has been uploaded by this neural lace when she has been killed. And now she gets to choose a new body. And this AI is interfacing with her recorded memory in her neural lace and helping her and being like, hello, you're dead. But because you had a neural lace, your memory's uploaded. Do you want to choose a new body? And you're going to be born here in the culture and like start a new life, which is just, that's like the opening. It's like so sick. And the ship is the super intelligence. All the ships are kind of super intelligence. But they still want to preserve a kind of rich, fulfilling experience for the humans. Yeah, like they're like friends with the humans. And then there's a bunch of ships that don't want to exist with biological beings, but they just have their own place like way over there. But they don't, they just do their own thing. They're not necessarily. So it's a pretty, this protopian existence is pretty peaceful. Yeah, I mean, and then, for example, one of the main fights in the book is they're fighting, there's these artificial hells that, and people don't think it's ethical to have artificial hell. Like basically when people do crime, they get sent, like when they die, their memory gets sent to an artificial hell and they're eternally tortured. And so, and then the way that society is deciding whether or not to have the artificial hell is that they're having these simulated, they're having like a simulated war. So instead of actual blood, you know, people are basically essentially fighting in a video game to choose the outcome of this. But they're still experiencing the suffering in this artificial hell or no? Can you experience stuff or? So the artificial hell sucks. And a lot of people in the culture want to get rid of the artificial hell. There's a simulated wars, are they happening in the artificial hell? So no, the simulated wars are happening outside of the artificial hell, between the political factions who are, so this political faction says we should have simulated hell to deter crime. And this political faction is saying, no, simulated hell is unethical. And so instead of like having, you know, blowing each other up with nukes, they're having like a giant Fortnite battle to decide this, which, you know, to me that's protopia. That's like, okay, we can have war without death. You know, I don't think there should be simulated hells. I think that is definitely one of the ways in which technology could go very, very, very, very wrong. So almost punishing people in a digital space or something like that. Yeah, like torturing people's memories. So either as a deterrent, like if you committed a crime, but also just for personal pleasure, if there's some sick, demented humans in this world. Dan Carlin actually has this episode of Hardcore History on painful attainment. Oh, that episode is fucked. It's dark, because he kind of goes through human history and says like, we as humans seem to enjoy, secretly enjoy or used to be openly enjoy sort of the torture and the death, watching the death and torture of other humans. I do think if people were consenting, we should be allowed to have gladiatorial matches. But consent is hard to achieve in those situations. It always starts getting slippery. Like it could be also forced consent, like it starts getting weird. There's way too much excitement. Like this is what he highlights. There's something about human nature that wants to see that violence. And it's really dark. And you hope that we can sort of overcome that aspect of human nature, but that's still within us somewhere. Well, I think that's what we're doing right now. I have this theory that what is very important about the current moment is that all of evolution has been survival of the fittest up until now. And at some point, the lines are kind of fuzzy, but in the recent past, or maybe even just right now, we're getting to this point where we can choose intelligent design. Like we probably since like the integration of the iPhone, like we are becoming cyborgs. Like our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous, from homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is like essentially a new species. Like if you look at the way, if you took an MRI of my brain and you took an MRI of like a medieval brain, I think it would be very different the way that it has evolved. Do you think when historians look back at this time, they'll see like this was a fundamental shift to what a human being is? I think, I do not think we are still homo sapiens. I believe we are homo techno. And I think we have evolved. And I think right now, the way we are evolving, we can choose how we do that. And I think we are being very reckless about how we're doing that. Like we're just having social media, but I think this idea that like this is a time to choose intelligent design should be taken very seriously. It like now is the moment to reprogram the human computer. It's like, if you go blind, your visual cortex will get taken over with other functions. We can choose our own evolution. We can change the way our brains work. And so we actually have a huge responsibility to do that. And I think I'm not sure who should be responsible for that, but there's definitely not adequate education. We're being inundated with all this technology that is fundamentally changing the physical structure of our brains. And we are not adequately responding to that to choose how we wanna evolve. And we could evolve, we could be really whatever we want. And I think this is a really important time. And I think if we choose correctly and we choose wisely, consciousness could exist for a very long time and integration with AI could be extremely positive. And I don't think enough people are focusing on this specific situation. Do you think we might irreversibly screw things up if we get things wrong now? Because the flip side of that, it seems humans are pretty adaptive. So maybe the way we figure things out is by screwing it up, like social media. Over a generation, we'll see the negative effects of social media, and then we build new social medias, and we just keep improving stuff. And then we learn from the failures of the past. Because humans seem to be really adaptive. On the flip side, we can get it wrong in a way where literally we create weapons of war or increase hate. Past a certain threshold, we really do a lot of damage. I mean, I think we're optimized to notice the negative things. But I would actually say one of the things that I think people aren't noticing is if you look at Silicon Valley and you look at the technocracy, like what's been happening there. When Silicon Valley started, it was all just Facebook and all this for profit crap that really wasn't particular. I guess it was useful, but it's sort of just whatever. But now you see lab grown meat, compostable, or biodegradable, single use cutlery, or meditation apps. I think we are actually evolving and changing, and technology is changing. I think there just maybe there isn't quite enough education about this. And also, I don't know if there's quite enough incentive for it because I think the way capitalism works, what we define as profit, we're also working on an old model of what we define as profit. I really think if we changed the idea of profit to include social good, you can have economic profit, social good also counting as profit would incentivize things that are more useful and more whatever spiritual technology or positive technology or things that help reprogram a human computer in a good way or things that help us intelligently design our new brains. Yeah, there's no reason why within the framework of capitalism, the word profit or the idea of profit can't also incorporate the well being of a human being. So like long term well being, long term happiness. Or even for example, we were talking about motherhood, like part of the reason I'm so late is because I had to get the baby to bed. And it's like, I keep thinking about motherhood, how under capitalism, it's like this extremely essential job that is very difficult that is not compensated. And we sort of like value things by how much we compensate them. And so we really devalue motherhood in our society and pretty much all societies. Like capitalism does not recognize motherhood. It's just a job that you're supposed to do for free. And it's like, but I feel like producing great humans should be seen as a great, as profit under capitalism. Like that should be, that's like a huge social good. Like every awesome human that gets made adds so much to the world. So like if that was integrated into the profit structure, then, you know, and if we potentially found a way to compensate motherhood. So come up with a compensation that's much broader than just money or. Or it could just be money. Like, what if you just made, I don't know, but I don't know how you'd pay for that. Like, I mean, that's where you start getting into. Reallocation of resources that people get upset over. Well, like what if we made like a motherhood Dow? Yeah, yeah. And, you know, used it to fund like single mothers, like, you know, pay for making babies. So, I mean, if you create and put beautiful things onto the world, that could be companies, that can be bridges, that could be art, that could be a lot of things, and that could be children, which are. Or education or. Anything, that should be valued by society, and that should be somehow incorporated into the framework of what, as a market, of what. Like, if you contribute children to this world, that should be valued and respected and sort of celebrated, like, proportional to what it is, which is, it's the thing that fuels human civilization. Yeah, like I. It's kind of important. I feel like everyone's always saying, I mean, I think we're in very different social spheres, but everyone's always saying, like, dismantle capitalism. And I'm like, well, okay, well, I don't think the government should own everything. Like, I don't think we should not have private ownership. Like, that's scary. You know, like that starts getting into weird stuff and just sort of like, I feel there's almost no way to do that without a police state, you know? But obviously, capitalism has some major flaws. And I think actually Mac showed me this idea called social capitalism, which is a form of capitalism that just like considers social good to be also profit. Like, you know, it's like, right now companies need to, like, you're supposed to grow every quarter or whatever to like show that you're functioning well, but it's like, okay, well, what if you kept the same amount of profit? You're still in the green, but then you have also all this social good. Like, do you really need all this extra economic growth or could you add this social good and that counts? And, you know, I don't know if, I am not an economist. I have no idea how this could be achieved, but. I don't think economists know how anything could be achieved either, but they pretend. It's the thing, they construct a model and they go on TV shows and sound like an expert. That's the definition of economist. How did being a mother, becoming a mother change you as a human being, would you say? Man, I think it kind of changed everything and it's still changing me a lot. It's actually changing me more right now in this moment than it was before. Like today, like this? Just like in the most recent months and stuff. Can you elucidate that, how change, like when you wake up in the morning and you look at yourself, it's again, which, who are you? How have you become different, would you say? I think it's just really reorienting my priorities. And at first I was really fighting against that because I somehow felt it was like a failure of feminism or something. Like I felt like it was like bad if like my kids started mattering more than my work. And then like more recently I started sort of analyzing that thought in myself and being like, that's also kind of a construct. It's like, we've just devalued motherhood so much in our culture that like, I feel guilty for caring about my kids more than I care about my work. So feminism includes breaking out of whatever the construct is. So just continually breaking, it's like freedom empower you to be free. And that means... But it also, but like being a mother, like I'm so much more creative. Like I cannot believe the massive amount of brain growth that I am. Why do you think that is? Just cause like the stakes are higher somehow? I think it's like, it's just so trippy watching consciousness emerge. It's just like, it's like going on a crazy journey or something. It's like the craziest science fiction novel you could ever read. It's just so crazy watching consciousness come into being. And then at the same time, like you're forced to value your time so much. Like when I have creative time now, it's so sacred. I need to like be really fricking on it. But the other thing is that I used to just be like a cynic and I used to just wanna... Like my last album was called Miss Anthropocene and it was like this like, it was like a study in villainy or like it was like, well, what if we have, instead of the old gods, we have like new gods and it's like Miss Anthropocene is like misanthrope like and Anthropocene, which is like the, you know, like and she's the goddess of climate change or whatever. And she's like destroying the world. And it was just like, it was like dark and it was like a study in villainy. And it was sort of just like, like I used to like have no problem just making cynical, angry, scary art. And not that there's anything wrong with that, but I think having kids just makes you such an optimist. It just inherently makes you wanna be an optimist so bad that like I feel more responsibility to make more optimistic things. And I get a lot of shit for it because everyone's like, oh, you're so privileged. Stop talking about like pie in the sky, stupid concepts and focus on like the now. But it's like, I think if we don't ideate about futures that could be good, we won't be able to get them. If everything is Blade Runner, then we're gonna end up with Blade Runner. It's like, as we said earlier, life imitates art. Like life really does imitate art. And so we really need more protopian or utopian art. I think this is incredibly essential for the future of humanity. And I think the current discourse where that's seen as a thinking about protopia or utopia is seen as a dismissal of the problems that we currently have. I think that is an incorrect mindset. And like having kids just makes me wanna imagine amazing futures that like maybe I won't be able to build, but they will be able to build if they want to. Yeah, it does seem like ideation is a precursor to creation. So you have to imagine it in order to be able to build it. And there is a sad thing about human nature that somehow a cynical view of the world is seen as a insightful view. You know, cynicism is often confused for insight, which is sad to see. And optimism is confused for naivete. Yes, yes. Like you don't, you're blinded by your, maybe your privilege or whatever. You're blinded by something, but you're certainly blinded. That's sad, that's sad to see because it seems like the optimists are the ones that create our future. They're the ones that build. In order to build the crazy thing, you have to be optimistic. You have to be either stupid or excited or passionate or mad enough to actually believe that it can be built. And those are the people that built it. My favorite quote of all time is from Star Wars, Episode 8, which I know everyone hates. Do you like Star Wars, Episode 8? No, yeah, probably I would say I would probably hate it, yeah. I don't have strong feelings about it. Let me backtrack. I don't have strong feelings about Star Wars. I'm a Tolkien person. I'm more into dragons and orcs and ogres. Yeah, I mean, Tolkien forever. I really want to have one more son and call him, I thought Tao Tecno Tolkien would be cool. It's a lot of T's, I like it. Yeah, and well, and Tao is six, two, eight, two pi. Yeah, Tao Tecno, yeah, yeah, yeah. And then techno is obviously the best genre of music, but also like technocracy. It just sounds really good. Yeah, that's right, and techno Tolkien, Tao Tecno Tolkien. That's a good, that's it. Tao Tecno Tolkien, but Star Wars, Episode 8, I know a lot of people have issues with it. Personally, on the record, I think it's the best Star Wars film. You're starting trouble today. Yeah, but don't kill what you hate, save what you love. Don't kill what you hate. Don't kill what you hate, save what you love. And I think we're, in society right now, we're in a diagnosis mode. We're just diagnosing and diagnosing and diagnosing, and we're trying to kill what we hate, and we're not trying to save what we love enough. And there's this Buckminster Fuller quote, which I'm gonna butcher, because I don't remember it correctly, but it's something along the lines of, don't try to destroy the old bad models, render them obsolete with better models. Maybe we don't need to destroy the oil industry. Maybe we just create a great new battery technology and sustainable transport, and just make it economically unreasonable to still continue to rely on fossil fuels. It's like, don't kill what you hate, save what you love. Make new things and just render the old things unusable. It's like if the college debt is so bad, and universities are so expensive, and I feel like education is becoming obsolete. I feel like we could completely revolutionize education, and we could make it free. And it's like, you look at JSTOR, and you have to pay to get all the studies and everything. What if we created a DAO that bought JSTOR, or we created a DAO that was funding studies, and those studies were open source, or free for everyone. And what if we just open sourced education and decentralized education and made it free, and all research was on the internet, and all the outcomes of studies were on the internet, and no one has student debt, and you just take tests when you apply for a job, and if you're qualified, then you can work there. This is just like, I don't know how anything works. I'm just randomly ranting, but. I like the humility. You gotta think from just basic first principles. What is the problem? What's broken? What are some ideas? That's it. And get excited about those ideas, and share your excitement, and don't tear each other down. It's just when you kill things, you often end up killing yourself. Like war is not a one sided, like you're not gonna go in and just kill them, like you're gonna get stabbed. It's like, and I think when I talk about this nexus point of that we're in this point in society where we're switching to intelligent design, I think part of our switch to intelligent design is that we need to choose nonviolence. And we need to, like, I think we can choose to start, I don't think we can eradicate violence from our species, because I think we need it a little bit, but I think we can choose to really reorient our primitive brains that are fighting over scarcity, and that are so attack oriented, and move into, we can optimize for creativity and building. Yeah, it's interesting to think how that happens, so some of it is just education, some of it is living life and introspecting your own mind, and trying to live up to the better angels of your nature for each one of us, all those kinds of things at scale. That's how we can sort of start to minimize the amount of destructive war in our world, and that's, to me, probably you're the same, technology is a really promising way to do that. Like, social media should be a really promising way to do that, it's a way we connect. I, you know, for the most part, I really enjoy social media. I just know all the negative stuff. I don't engage with any of the negative stuff. Just not even, like, by blocking or any of that kind of stuff, but just not letting it enter my mind. Like, just, like, when somebody says something negative, I see it, I immediately think positive thoughts about them, and I just forget they exist after that. Just move on, because, like, that negative energy, if I return the negative energy, they're going to get excited in a negative way right back, and it's just this kind of vicious cycle. But you would think technology would assist us in this process of letting go, of not taking things personally, of not engaging in the negativity, but unfortunately, social media profits from the negativity, so the current models. I mean, social media is like a gun. Like, you should take a course before you use it. Like, it's like, this is what I mean, like, when I say reprogram the human computer. Like, in school, you should learn about how social media optimizes to, you know, raise your cortisol levels and make you angry and crazy and stressed, and, like, you should learn how to have hygiene about how you use social media. But, so you can, yeah, choose not to focus on the negative stuff, but I don't know. I'm not sure social media should, I guess it should exist. I'm not sure. I mean, we're in the messy, it's the experimental phase. Like, we're working it out. Yeah, it's the early days. I don't even know, when you say social media, I don't know what that even means. We're in the very early days. I think social media is just basic human connection in the digital realm, and that, I think it should exist, but there's so many ways to do it in a bad way. There's so many ways to do it in a good way. There's all discussions of all the same human rights. We talk about freedom of speech. We talk about sort of violence in the space of digital media. We talk about hate speech. We talk about all these things that we had to figure out back in the day in the physical space. We're now figuring out in the digital space, and it's like baby stages. When the printing press came out, it was like pure chaos for a minute, you know? It's like when you inject, when there's a massive information injection into the general population, there's just gonna be, I feel like the printing press, I don't have the years, but it was like printing press came out, shit got really fucking bad for a minute, but then we got the enlightenment. And so it's like, I think we're in, this is like the second coming of the printing press. We're probably gonna have some shitty times for a minute, and then we're gonna have recalibrate to have a better understanding of how we consume media and how we deliver media. Speaking of programming the human computer, you mentioned Baby X. So there's this young consciousness coming to be, came from a cell. Like that whole thing doesn't even make sense. It came from DNA. Yeah. And then there's this baby computer that just like grows and grows and grows and grows, and now there's a conscious being with extremely impressive cognitive capabilities with, Have you met him? Yes, yeah. Yeah. He's actually really smart. He's really smart. Yeah. He's weird. Yeah. Or a baby. He does. I don't, I haven't. I don't know a lot of other babies, but he seems to be smart. Zach, I don't hang out with babies often, but this baby was very impressive. He does a lot of pranks and stuff. Oh, so he's like. Like he'll like give you a treat and then take it away and laugh and like stuff like that. So he's like a chess player. So here's a cognitive sort of, there's a computer being programmed. So he's taking in the environment, interacting with a specific set of humans. How would you, first of all, what is it? What, let me ask. I want to ask how do you program this computer? And also how do you make sense of that there's a conscious being right there that wasn't there before? It's giving me a lot of crisis thoughts. I'm thinking really hard. I think that's part of the reason it's like, I'm struggling to focus on art and stuff right now. Cause baby X is becoming conscious and like my it's just reorienting my brain. Like my brain is suddenly totally shifting of like, oh shit, like the way we raise children. Like, I hate all the baby books and everything. I hate them. Like they're, oh, the art is so bad. And like all this stuff, everything about all the aesthetics. And like, I'm just like, ah, like this is so. The programming languages we're using to program these baby computers isn't good. Yeah, like I'm thinking, and I, not that I have like good answers or know what to do, but I'm just thinking really, really hard about it. I, we recently watched Totoro with him, Studio Ghibli. And it's just like a fantastic film. And he like responded to, I know you're not supposed to show baby screens too much, but like, I think it's the most sort of like, I feel like it's the highest art baby content. Like it really speaks, there's almost no talking in it. It's really simple. Although all the dialogue is super, super, super simple, you know, and it's like a one to three year old can like really connect with it. Like it feels like it's almost aimed at like a one to three year old, but it's like great art and it's so imaginative and it's so beautiful. And like the first time I showed it to him, he was just like so invested in it, unlike I've ever, unlike anything else I'd ever shown him. Like he was just like crying when they cry and laughing when they laugh, like just like having this roller coaster of like emotions, like, and he learned a bunch of words. Like he was, and he started saying Totoro and started just saying all this stuff after watching Totoro, and he wants to watch it all the time. And I was like, man, why isn't there an industry of this? Like why aren't our best artists focusing on making art like for the birth of consciousness? Like, and that's one of the things I've been thinking I really wanna start doing. You know, I don't wanna speak before I do things too much, but like, I'm just like ages one to three, like we should be putting so much effort into that. And the other thing about Totoro is it's like, it's like better for the environment because adults love Totoro. It's such good art that everyone loves it. Like I still have all my old Totoro merch from when I was a kid. Like I literally have the most ragged old Totoro merch. Like everybody loves it, everybody keeps it. It's like, why does the art we have for babies need to suck and be not accessible to adults and then just be thrown out when, you know, they age out of it? Like, it's like, I don't know. I don't have like a fully formed thought here, but this is just something I've been thinking about a lot is like, how do we like, how do we have more Totoroesque content? Like how do we have more content like this that like is universal and everybody loves, but is like really geared to an emerging consciousness? Emerging consciousness in the first like three years of life that so much turmoil, so much evolution of mind is happening. It seems like a crucial time. Would you say to make it not suck, do you think of basically treating a child like they have the capacity to have the brilliance of an adult or even beyond that? Is that how you think of that mind or? No, cause they still, they like it when you talk weird and stuff. Like they respond better to, cause even they can imitate better when your voice is higher. Like people say like, oh, don't do baby talk. But it's like, when your voice is higher, it's closer to something they can imitate. So they like, like the baby talk actually kind of works. Like it helps them learn to communicate. I've found it to be more effective with learning words and stuff. But like, you're not speaking down to them. Like do they have the capacity\",\n          \"The following is a conversation with Sean Carroll. He's a theoretical physicist at Caltech specializing in quantum mechanics, gravity, and cosmology. He's the author of several popular books, one on the arrow of time called From Eternity to Here, one on the Higgs boson called Particle at the End of the Universe, and one on science and philosophy called The Big Picture on the Origins of Life, Meaning, and the Universe Itself. He has an upcoming book on quantum mechanics that you can preorder now called Something Deeply Hidden. He writes one of my favorite blogs on his website, preposterousuniverse.com. I recommend clicking on the Greatest Hits link that lists accessible, interesting posts on the arrow of time, dark matter, dark energy, the Big Bang, general relativity, string theory, quantum mechanics, and the big meta questions about the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's Hardcore History, Sean's Mindscape podcast is one of my favorite ways to learn new ideas or explore different perspectives and ideas that I thought I understood. It was truly an honor to meet and spend a couple hours with Sean. It's a bit heartbreaking to say that for the first time ever, the audio recorder for this podcast died in the middle of our conversation. There's technical reasons for this, having to do with phantom power that I now understand and will avoid. It took me one hour to notice and fix the problem. So, much like the universe is 68% dark energy, roughly the same amount from this conversation was lost, except in the memories of the two people involved and in my notes. I'm sure we'll talk again and continue this conversation on this podcast or on Sean's. And of course, I look forward to it. This is the Artificial Intelligence podcast. If you enjoy it, subscribe on YouTube, iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman. And now, here's my conversation with Sean Carroll. What do you think is more interesting and impactful, understanding how the universe works at a fundamental level or understanding how the human mind works? You know, of course this is a crazy, meaningless, unanswerable question in some sense, because they're both very interesting and there's no absolute scale of interestingness that we can rate them on. There's a glib answer that says the human brain is part of the universe, right? And therefore, understanding the universe is more fundamental than understanding the human brain. But do you really believe that once we understand the fundamental way the universe works at the particle level, the forces, we would be able to understand how the mind works? No, certainly not. We cannot understand how ice cream works just from understanding how particles work, right? So I'm a big believer in emergence. I'm a big believer that there are different ways of talking about the world beyond just the most fundamental microscopic one. You know, when we talk about tables and chairs and planets and people, we're not talking the language of particle physics and cosmology. So, but understanding the universe, you didn't say just at the most fundamental level, right? So understanding the universe at all levels is part of that. I do think, you know, to be a little bit more fair to the question, there probably are general principles of complexity, biology, information processing, memory, knowledge, creativity that go beyond just the human brain, right? And maybe one could count understanding those as part of understanding the universe. The human brain, as far as we know, is the most complex thing in the universe. So there's, it's certainly absurd to think that by understanding the fundamental laws of particle physics, you get any direct insight on how the brain works. But then there's this step from the fundamentals of particle physics to information processing, which a lot of physicists and philosophers may be a little bit carelessly take when they talk about artificial intelligence. Do you think of the universe as a kind of a computational device? No, to be like, the honest answer there is no. There's a sense in which the universe processes information, clearly. There's a sense in which the universe is like a computer, clearly. But in some sense, I think, I tried to say this once on my blog and no one agreed with me, but the universe is more like a computation than a computer because the universe happens once. A computer is a general purpose machine, right? That you can ask it different questions, even a pocket calculator, right? And it's set up to answer certain kinds of questions. The universe isn't that. So information processing happens in the universe, but it's not what the universe is. And I know your MIT colleague, Seth Lloyd, feels very differently about this, right? Well, you're thinking of the universe as a closed system. I am. So what makes a computer more like a PC, like a computing machine is that there's a human that every once comes up to it and moves the mouse around. So input. Gives it input. Gives it input. And that's why you're saying it's just a computation, a deterministic thing that's just unrolling. But the immense complexity of it is nevertheless like processing. There's a state and then it changes with good rules. And there's a sense for a lot of people that if the brain operates, the human brain operates within that world, then it's simply just a small subset of that. And so there's no reason we can't build arbitrarily great intelligences. Yeah. Do you think of intelligence in this way? Intelligence is tricky. I don't have a definition of it offhand. So I remember this panel discussion that I saw on YouTube. I wasn't there, but Seth Lloyd was on the panel. And so was Martin Rees, the famous astrophysicist. And Seth gave his shtick for why the universe is a computer and explained this. And Martin Rees said, so what is not a computer? And Seth was like, oh, that's a good question. I'm not sure. Because if you have a sufficiently broad definition of what a computer is, then everything is, right? And the simile or the analogy gains force when it excludes some things. You know, is the moon going around the earth performing a computation? I can come up with definitions in which the answer is yes, but it's not a very useful computation. I think that it's absolutely helpful to think about the universe in certain situations, certain contexts, as an information processing device. I'm even guilty of writing a paper called Quantum Circuit Cosmology, where we modeled the whole universe as a quantum circuit. As a circuit. As a circuit, yeah. With qubits kind of thing? With qubits basically, right, yeah. So, and qubits becoming more and more entangled. So do we wanna digress a little bit? Let's do it. It's kind of fun. So here's a mystery about the universe that is so deep and profound that nobody talks about it. Space expands, right? And we talk about, in a certain region of space, a certain number of degrees of freedom, a certain number of ways that the quantum fields and the particles in that region can arrange themselves. That number of degrees of freedom in a region of space is arguably finite. We actually don't know how many there are, but there's a very good argument that says it's a finite number. So as the universe expands and space gets bigger, are there more degrees of freedom? If it's an infinite number, it doesn't really matter. Infinity times two is still infinity. But if it's a finite number, then there's more space, so there's more degrees of freedom. So where did they come from? That would mean the universe is not a closed system. There's more degrees of freedom popping into existence. So what we suggested was that there are more degrees of freedom, and it's not that they're not there to start, but they're not entangled to start. So the universe that you and I know of, the three dimensions around us that we see, we said those are the entangled degrees of freedom making up space time. And as the universe expands, there are a whole bunch of qubits in their zero state that become entangled with the rest of space time through the action of these quantum circuits. So what does it mean that there's now more degrees of freedom as they become more entangled? Yeah, so. As the universe expands. That's right, so there's more and more degrees of freedom that are entangled, that are playing part, playing the role of part of the entangled space time structure. So the basic, the underlying philosophy is that space time itself arises from the entanglement of some fundamental quantum degrees of freedom. Wow, okay, so at which point is most of the entanglement happening? Are we talking about close to the Big Bang? Are we talking about throughout the time of the life? Throughout history, yeah. So the idea is that at the Big Bang, almost all the degrees of freedom that the universe could have were there, but they were unentangled with anything else. And that's a reflection of the fact that the Big Bang had a low entropy. It was a very simple, very small place. And as space expands, more and more degrees of freedom become entangled with the rest of the world. Well, I have to ask John Carroll, what do you think of the thought experiment from Nick Bostrom that we're living in a simulation? So I think, let me contextualize that a little bit more. I think people don't actually take this thought experiments. I think it's quite interesting. It's not very useful, but it's quite interesting. From the perspective of AI, a lot of the learning that can be done usually happens in simulation from artificial examples. And so it's a constructive question to ask, how difficult is our real world to simulate? Right. Which is kind of a dual part of, if we're living in a simulation and somebody built that simulation, if you were to try to do it yourself, how hard would it be? So obviously we could be living in a simulation. If you just want the physical possibility, then I completely agree that it's physically possible. I don't think that we actually are. So take this one piece of data into consideration. You know, we live in a big universe, okay? There's two trillion galaxies in our observable universe with 200 billion stars in each galaxy, et cetera. It would seem to be a waste of resources to have a universe that big going on just to do a simulation. So in other words, I want to be a good Bayesian. I want to ask under this hypothesis, what do I expect to see? So the first thing I would say is I wouldn't expect to see a universe that was that big, okay? The second thing is I wouldn't expect the resolution of the universe to be as good as it is. So it's always possible that if our superhuman simulators only have finite resources, that they don't render the entire universe, right? That the part that is out there, the two trillion galaxies, isn't actually being simulated fully, okay? But then the obvious extrapolation of that is that only I am being simulated fully. Like the rest of you are just non player characters, right? I'm the only thing that is real. The rest of you are just chat bots. Beyond this wall, I see the wall, but there is literally nothing on the other side of the wall. That is sort of the Bayesian prediction. That's what it would be like to do an efficient simulation of me. So like none of that seems quite realistic. I don't see, I hear the argument that it's just possible and easy to simulate lots of things. I don't see any evidence from what we know about our universe that we look like a simulated universe. Now, maybe you can say, well, we don't know what it would look like, but that's just abandoning your Bayesian responsibilities. Like your job is to say under this theory, here's what you would expect to see. Yeah, so certainly if you think about simulation as a thing that's like a video game where only a small subset is being rendered. But say the entire, all the laws of physics, the entire closed system of the quote unquote universe, it had a creator. Yeah, it's always possible. Right, so that's not useful to think about when you're thinking about physics. The way Nick Bostrom phrases it, if it's possible to simulate a universe, eventually we'll do it. Right. You can use that by the way for a lot of things. Well, yeah. But I guess the question is, how hard is it to create a universe? I wrote a little blog post about this and maybe I'm missing something, but there's an argument that says not only that it might be possible to simulate a universe, but probably if you imagine that you actually attribute consciousness and agency to the little things that we're simulating, to our little artificial beings, there's probably a lot more of them than there are ordinary organic beings in the universe or there will be in the future, right? So there's an argument that not only is being a simulation possible, it's probable because in the space of all living consciousnesses, most of them are being simulated, right? Most of them are not at the top level. I think that argument must be wrong because it follows from that argument that, if we're simulated, but we can also simulate other things, well, but if we can simulate other things, they can simulate other things, right? If we give them enough power and resolution and ultimately we'll reach a bottom because the laws of physics in our universe have a bottom, we're made of atoms and so forth, so there will be the cheapest possible simulations. And if you believe the original argument, you should conclude that we should be in the cheapest possible simulation because that's where most people are. But we don't look like that. It doesn't look at all like we're at the edge of resolution, that we're 16 bit things. It seems much easier to make much lower level things than we are. And also, I questioned the whole approach to the anthropic principle that says we are typical observers in the universe. I think that that's not actually, I think that there's a lot of selection that we can do that we're typical within things we already know, but not typical within all of the universe. So do you think there's intelligent life, however you would like to define intelligent life, out there in the universe? My guess is that there is not intelligent life in the observable universe other than us, simply on the basis of the fact that the likely number of other intelligent species in the observable universe, there's two likely numbers, zero or billions. And if there had been billions, you would have noticed already. For there to be literally like a small number, like, you know, Star Trek, there's a dozen intelligent civilizations in our galaxy, but not a billion, that's weird. That's sort of bizarre to me. It's easy for me to imagine that there are zero others because there's just a big bottleneck to making multicellular life or technological life or whatever. It's very hard for me to imagine that there's a whole bunch out there that have somehow remained hidden from us. The question I'd like to ask is what would intelligent life look like? What I mean by that question and where it's going is what if intelligent life is just in some very big ways different than the one that has on Earth? That there's all kinds of intelligent life that operates at different scales of both size and temporal. Right, that's a great possibility because I think we should be humble about what intelligence is, what life is. We don't even agree on what life is, much less what intelligent life is, right? So that's an argument for humility, saying there could be intelligent life of a very different character, right? Like you could imagine the dolphins are intelligent but never invent space travel because they live in the ocean and they don't have thumbs, right? So they never invent technology, they never invent smelting. Maybe the universe is full of intelligent species that just don't make technology, right? That's compatible with the data, I think. And I think maybe what you're pointing at is even more out there versions of intelligence, intelligence in intermolecular clouds or on the surface of a neutron star or in between the galaxies in giant things where the equivalent of a heartbeat is 100 million years. On the one hand, yes, we should be very open minded about those things. On the other hand, all of us share the same laws of physics. There might be something about the laws of physics, even though we don't currently know exactly what that thing would be, that makes meters and years the right length and timescales for intelligent life. Maybe not, but we're made of atoms, atoms have a certain size, we orbit stars or stars have a certain lifetime. It's not impossible to me that there's a sweet spot for intelligent life that we find ourselves in. So I'm open minded either way, I'm open minded either being humble and there's all sorts of different kinds of life or no, there's a reason we just don't know it yet why life like ours is the kind of life that's out there. Yeah, I'm of two minds too, but I often wonder if our brains is just designed to quite obviously to operate and see the world in these timescales and we're almost blind and the tools we've created for detecting things are blind to the kind of observation needed to see intelligent life at other scales. Well, I'm totally open to that, but so here's another argument I would make, we have looked for intelligent life, but we've looked at for it in the dumbest way we can, by turning radio telescopes to the sky. And why in the world would a super advanced civilization randomly beam out radio signals wastefully in all directions into the universe? That just doesn't make any sense, especially because in order to think that you would actually contact another civilization, you would have to do it forever, you have to keep doing it for millions of years, that sounds like a waste of resources. If you thought that there were other solar systems with planets around them, where maybe intelligent life didn't yet exist, but might someday, you wouldn't try to talk to it with radio waves, you would send a spacecraft out there and you would park it around there and it would be like, from our point of view, it'd be like 2001, where there was a monolith. Monolith. There could be an artifact, in fact, the other way works also, right? There could be artifacts in our solar system that have been put there by other technologically advanced civilizations and that's how we will eventually contact them. We just haven't explored the solar system well enough yet to find them. The reason why we don't think about that is because we're young and impatient, right? Like, it would take more than my lifetime to actually send something to another star system and wait for it and then come back. So, but if we start thinking on hundreds of thousands of years or million year time scales, that's clearly the right thing to do. Are you excited by the thing that Elon Musk is doing with SpaceX in general? Space, but the idea of space exploration, even though your, or your species is young and impatient? Yeah. No, I do think that space travel is crucially important, long term. Even to other star systems. And I think that many people overestimate the difficulty because they say, look, if you travel 1% the speed of light to another star system, we'll be dead before we get there, right? And I think that it's much easier. And therefore, when they write their science fiction stories, they imagine we'd go faster than the speed of light because otherwise they're too impatient, right? We're not gonna go faster than the speed of light, but we could easily imagine that the human lifespan gets extended to thousands of years. And once you do that, then the stars are much closer effectively, right? And then what's a hundred year trip, right? So I think that that's gonna be the future, the far future, not my lifetime once again, but baby steps. Unless your lifetime gets extended. Well, it's in a race against time, right? A friend of mine who actually thinks about these things said, you know, you and I are gonna die, but I don't know about our grandchildren. That's, I don't know, predicting the future is hard, but that's at least a plausible scenario. And so, yeah, no, I think that as we discussed earlier, there are threats to the earth, known and unknown, right? Having spread humanity and biology elsewhere is a really important longterm goal. What kind of questions can science not currently answer, but might soon? When you think about the problems and the mysteries before us that may be within reach of science. I think an obvious one is the origin of life. We don't know how that happened. There's a difficulty in knowing how it happened historically actually, you know, literally on earth, but starting life from non life is something I kind of think we're close to, right? We're really. You really think so? Like how difficult is it to start life? Well, I've talked to people, including on the podcast about this. You know, life requires three things. Life as we know it. So there's a difference with life, which who knows what it is, and life as we know it, which we can talk about with some intelligence. So life as we know it requires compartmentalization. You need like a little membrane around your cell. Metabolism, you need to take in food and eat it and let that make you do things. And then replication, okay? So you need to have some information about who you are that you pass down to future generations. In the lab, compartmentalization seems pretty easy. Not hard to make lipid bilayers that come into little cellular walls pretty easily. Metabolism and replication are hard, but replication we're close to. People have made RNA like molecules in the lab that I think the state of the art is, they're not able to make one molecule that reproduces itself, but they're able to make two molecules that reproduce each other. So that's okay. That's pretty close. Metabolism is harder, believe it or not, even though it's sort of the most obvious thing, but you want some sort of controlled metabolism and the actual cellular machinery in our bodies is quite complicated. It's hard to see it just popping into existence all by itself. It probably took a while, but we're making progress. And in fact, I don't think we're spending nearly enough money on it. If I were the NSF, I would flood this area with money because it would change our view of the world if we could actually make life in the lab and understand how it was made originally here on earth. And I'm sure it'd have some ripple effects that help cure disease and so on. I mean, just that understanding. So synthetic biology is a wonderful big frontier where we're making cells. Right now, the best way to do that is to borrow heavily from existing biology, right? Well, Craig Venter several years ago created an artificial cell, but all he did was, not all he did, it was a tremendous accomplishment, but all he did was take out the DNA from a cell and put in entirely new DNA and let it boot up and go. What about the leap to creating intelligent life on earth? Yeah. Again, we define intelligence, of course, but let's just even say Homo sapiens, the modern intelligence in our human brain. Do you have a sense of what's involved in that leap and how big of a leap that is? So AI would count in this, or do you really want life? Do you want really an organism in some sense? AI would count, I think. Okay. Yeah, of course, of course AI would count. Well, let's say artificial consciousness, right? So I do not think we are on the threshold of creating artificial consciousness. I think it's possible. I'm not, again, very educated about how close we are, but my impression is not that we're really close because we understand how little we understand of consciousness and what it is. So if we don't have any idea what it is, it's hard to imagine we're on the threshold of making it ourselves. But it's doable, it's possible. I don't see any obstacles in principle. So yeah, I would hold out some interest in that happening eventually. I think in general, consciousness, I think we would be just surprised how easy consciousness is once we create intelligence. I think consciousness is a thing that's just something we all fake. Well, good. No, actually, I like this idea that in fact, consciousness is way less mysterious than we think because we're all at every time, at every moment, less conscious than we think we are, right? We can fool things. And I think that plus the idea that you not only have artificial intelligent systems, but you put them in a body, right, give them a robot body, that will help the faking a lot. Yeah, I think creating consciousness in artificial consciousness is as simple as asking a Roomba to say, I'm conscious, and refusing to be talked out of it. Could be, it could be. And I mean, I'm almost being silly, but that's what we do. That's what we do with each other. This is the kind of, that consciousness is also a social construct. And a lot of our ideas of intelligence is a social construct. And so reaching that bar involves something that's beyond, that doesn't necessarily involve the fundamental understanding of how you go from electrons to neurons to cognition. No, actually, I think that is an extremely good point. And in fact, what it suggests is, so yeah, you referred to Kate Darling, who I had on the podcast, and who does these experiments with very simple robots, but they look like animals, and they can look like they're experiencing pain, and we human beings react very negatively to these little robots looking like they're experiencing pain. And what you wanna say is, yeah, but they're just robots. It's not really pain, right? It's just some electrons going around. But then you realize, you and I are just electrons going around, and that's what pain is also. And so what I would have an easy time imagining is that there is a spectrum between these simple little robots that Kate works with and a human being, where there are things that sort of by some strict definition, Turing test level thing are not conscious, but nevertheless walk and talk like they're conscious. And it could be that the future is, I mean, Siri is close, right? And so it might be the future has a lot more agents like that. And in fact, rather than someday going, aha, we have consciousness, we'll just creep up on it with more and more accurate reflections of what we expect. And in the future, maybe the present, for example, we haven't met before, and you're basically assuming that I'm human as it's a high probability at this time because the yeah, but in the future, there might be question marks around that, right? Yeah, no, absolutely. Certainly videos are almost to the point where you shouldn't trust them already. Photos you can't trust, right? Videos is easier to trust, but we're getting worse that, we're getting better at faking them, right? Yeah, so physical embodied people, what's so hard about faking that? So this is very depressing, this conversation we're having right now. So I mean, To me, it's exciting. To me, you're doing it. So it's exciting to you, but it's a sobering thought. We're very bad, right? At imagining what the next 50 years are gonna be like when we're in the middle of a phase transition as we are right now. Yeah, and I, in general, I'm not blind to all the threats. I am excited by the power of technology to solve, to protect us against the threats as they evolve. I'm not as much as Steven Pinker optimistic about the world, but in everything I've seen, all of the brilliant people in the world that I've met are good people. So the army of the good in terms of the development of technology is large. Okay, you're way more optimistic than I am. I think that goodness and badness are equally distributed among intelligent and unintelligent people. I don't see much of a correlation there. Interesting. Neither of us have proof. Yeah, exactly. Again, opinions are free, right? Nor definitions of good and evil. We come without definitions or without data opinions. So what kind of questions can science not currently answer and may never be able to answer in your view? Well, the obvious one is what is good and bad? What is right and wrong? I think that there are questions that, science tells us what happens, what the world is and what it does. It doesn't say what the world should do or what we should do, because we're part of the world. But we are part of the world and we have the ability to feel like something's right, something's wrong. And to make a very long story very short, I think that the idea of moral philosophy is systematizing our intuitions of what is right and what is wrong. And science might be able to predict ahead of time what we will do, but it won't ever be able to judge whether we should have done it or not. So, you're kind of unique in terms of scientists. Listen, it doesn't have to do with podcasts, but even just reaching out, I think you referred to as sort of doing interdisciplinary science. So you reach out and talk to people that are outside of your discipline, which I always hope that's what science was for. In fact, I was a little disillusioned when I realized that academia is very siloed. Yeah. And so the question is, how, at your own level, how do you prepare for these conversations? How do you think about these conversations? How do you open your mind enough to have these conversations? And it may be a little bit broader, how can you advise other scientists to have these kinds of conversations? Not at the podcast, the fact that you're doing a podcast is awesome, other people get to hear them, but it's also good to have it without mics in general. It's a good question, but a tough one to answer. I think about a guy I know who's a personal trainer, and he was asked on a podcast, how do we psych ourselves up to do a workout? How do we make that discipline to go and work out? And he's like, why are you asking me? I can't stop working out. I don't need to psych myself up. So, and likewise, he asked me, how do you get to have interdisciplinary conversations on all sorts of different things, all sorts of different people? I'm like, that's what makes me go, right? Like that's, I couldn't stop doing that. I did that long before any of them were recorded. In fact, a lot of the motivation for starting recording it was making sure I would read all these books that I had purchased, right? Like all these books I wanted to read, not enough time to read them. And now if I have the motivation, cause I'm gonna interview Pat Churchland, I'm gonna finally read her book. You know, and it's absolutely true that academia is extraordinarily siloed, right? We don't talk to people. We rarely do. And in fact, when we do, it's punished. You know, like the people who do it successfully generally first became very successful within their little siloed discipline. And only then did they start expanding out. If you're a young person, you know, I have graduate students. I try to be very, very candid with them about this, that it's, you know, most graduate students are to not become faculty members, right? It's a tough road. And so live the life you wanna live, but do it with your eyes open about what it does to your job chances. And the more broad you are and the less time you spend hyper specializing in your field, the lower your job chances are. That's just an academic reality. It's terrible, I don't like it, but it's a reality. And for some people, that's fine. Like there's plenty of people who are wonderful scientists who have zero interest in branching out and talking to things, to anyone outside their field. But it is disillusioning to me. Some of the, you know, romantic notion I had of the intellectual academic life is belied by the reality of it. The idea that we should reach out beyond our discipline and that is a positive good is just so rare in universities that it may as well not exist at all. But that said, even though you're saying you're doing it like the personal trainer, because you just can't help it, you're also an inspiration to others. Like I could speak for myself. You know, I also have a career I'm thinking about, right? And without your podcast, I may have not have been doing this at all, right? So it makes me realize that these kinds of conversations is kind of what science is about in many ways. The reason we write papers, this exchange of ideas, is it's much harder to do interdisciplinary papers, I would say. And conversations are easier. So conversations is the beginning. And in the field of AI, it's obvious that we should think outside of pure computer vision competitions on a particular data sets. We should think about the broader impact of how this can be, you know, reaching out to physics, to psychology, to neuroscience and having these conversations so that you're an inspiration. And so never know how the world changes. I mean, the fact that this stuff is out there and I've a huge number of people come up to me, grad students, really loving the podcast, inspired by it. And they will probably have that, they'll be ripple effects when they become faculty and so on and so on. We can end on a balance between pessimism and optimism. And Sean, thank you so much for talking to me, it was awesome. No, Lex, thank you very much for this conversation. It was great.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_pre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 318,\n        \"samples\": [\n          \"follow convers michael jordan professor berkeley one influenti peopl histori machin learn statist artifici intellig cite 170 000 time mentor mani world class research defin field ai today includ andrew ng zubin garamani ben taskar yoshua bengio impress 32 000 point six nba championship michael j jordan basketbal fame nonzero probabl talk michael jordan given connect love chicago bull 90 pick one go michael jordan statist comput scienc yann lecun call mile davi machin learn blog post titl artifici intellig revolut happen yet michael argu broaden scope artifici intellig field mani way underli spirit podcast see artifici intellig deepli human endeavor engin algorithm robot understand empow human be level abstract individu civil whole artifici intellig podcast enjoy subscrib youtub give five star appl podcast support patreon simpli connect twitter lex friedman spell f r n usual one two minut ad never ad middl break flow convers hope work hurt listen experi show present cash app number one financ app app store get use code lex podcast cash app let send money friend buy bitcoin invest stock market littl 1 sinc cash app fraction share trade let mention order execut algorithm work behind scene creat abstract fraction order algorithm marvel great prop cash app engin solv hard problem end provid easi interfac take step next layer abstract stock market make trade access new investor diversif much easier get cash app app store googl play use code lex podcast get 10 cash app also donat 10 first one favorit organ help advanc robot stem educ young peopl around world convers michael jordan given one great field ai machin learn comput scienc trivial call michael jordan machin learn although know born first technic mj michael jordan basketbal anyway favorit yann lecun call mile davi machin learn say reinvent period sometim leav fan scratch head chang direct put first historian hat give histori comput scienc ai saw experienc includ four gener ai success seen talk sure yeah first much prefer yann metaphor mile davi real explor jazz coher stori think one one live one think later historian look back revisit think happen right ai intellectu aspir still aliv today aspir think akin develop chemic engin chemistri electr engin electromagnet go back 30 40 yet chemic engin chemistri fluid flow mechan peopl pretti clearli view interest goal tri build factori make chemic product viabli safe make good one scale peopl start tri cours factori work viabl explod parallel develop whole field call chemic engin electr engin field bone theoret aspect practic aspect engin quot unquot real thing real concept need thing electr engin maxwel equat sens everyth know electromagnet need figur build circuit build modul put togeth bring electr one point anoth safe forth whole field develop call electr engin think happen right proto field statist theoret side algorithm side comput scienc enough start build thing thing system bring valu human be use human data mix human decis engin side ad hoc emerg fact wan na call machin learn field think proto form engin base statist comput idea previou gener think someth deeper ai dream aspir compar chemic engin electr engin well dream aspir mayb 500 year think like greek sit say would neat get moon someday think clue brain comput clueless even wors greek anyth interest scientif era linger moment stand complet uniqu littl bit uniqu clariti elabor intuit like stand understand human brain lot peopl say know scientist say far understand human brain like say dark well know uniqu even think clariti talk real neuroscientist realli studi real synaps real neuron agre agre hundr year task build slowli sure signal clear think metaphor think electr mayb chemic whole soup ion protein cell even around like singl synaps look electron micrograph singl synaps citi one littl thing dendrit tree extrem complic electrochem thing spike voltag fli around protein take take dna know problem next centuri fantast metaphor econom devic like immun system like layer set know arithmet comput metaphor fun real scienc per se neurosci neurosci right like greek specul get moon fun right think like say fairli strongli think lot young peopl think verg lot peopl talk clearli let understood ye kind brain inspir kind close know breakthrough horizon scrupul peopl sometim need money lab say scrupul peopl oversel need money lab studi comput neurosci go oversel much step gray area metaphor engin sure familiar brain comput interfac compani like elon musk neuralink work put electrod brain tri abl read read send electr signal said even basic mechan commun brain someth understand hope without understand fundament principl brain work abl someth interest gray area metaphor area hope sens like anybodi els hope interest thing happen research would expect someth like alzheim get figur modern neurosci lot human suffer base brain diseas throw thing like lithium brain kind work one clue quit true mostli know even biochemistri brain lead mood swing thought emerg realli realli complet dim might want hook electrod tri signal process tri find pattern fine mean go scientif point like kind sit satellit watch emiss citi tri infer thing microeconomi even though microeconom concept realli kind thing ye find signal someth interest use control cursor mous brain yeah absolut imagin busi model base even medic applic understand algorithm allow us realli tie deepli brain comput agre elon musk think even gener even centuri hope get dream mention kolmogorov ture might pop think might breakthrough get sit back five 10 year say wow oh sure think demo impress think comput call restaur pretend human breakthrough right peopl know peopl present imit human intellig even put cough thing make bit pr stunt fine world run thing want diminish hard work engin goe behind thing like ultim valu human race scientif understand know peopl work thing scientif understand meantim got kind know train got run got mouth feed got thing noth wrong would call though engin want distinguish engin field like electr engin chemic engin origin emerg real principl realli know littl scientif understand mayb even complet becam predict realli gave valu human life understood want muddl much water know abl versu realli way go impress next need wow think someon come along 20 year younger person absorb technolog wow think deepli impress young kolmogorov would wow stunt see right come big compani demo think breakthrough kolmogorov would give question chanc think scientif fundament principl arena think possibl fundament breakthrough engin mean know would say thing elon musk work spacex other sort tri revolution fundament engin manufactur say problem know demo actual take scale yeah go kind breakthrough like terminolog scientist work thing day day thing move along eventu say wow someth happen like languag much also like prize theoret breakthrough practic one tend theoretician think lot arena right point kolmogorov might point edison era mayb musk bit like know musk god bless also say thing ai know littl lead peopl astray talk thing know anyth tri program comput understand natur languag involv dialogu right go happen lifetim could fake mimic sort take old sentenc human use retread deep understand languag go happen hope perceiv deeper yet deeper kind aspect intellig go happen breakthrough think googl breakthrough think amazon breakthrough know think uber breakthrough know bring valu human be scale new brand new way base data flow lot thing slightli broken kind engin field take econom valu context data know planetari scale worri extern privaci know field think thing well see emerg know look back 100 year constitut breakthrough era like electr engin breakthrough earli part last centuri chemic engin breakthrough scale market talk get seen sort breakthrough earli day realli interest stuff get take quick step back give kind throw historian hat mean briefli said histori ai kind mimic histori chemic engin keep say machin learn keep want say ai let know know resist think ai realli john mccarthi almost philosoph say cool could put thought comput could mimic human capabl think put intellig sens comput interest philosoph question want make philosophi want actual write logic formula algorithm would perfectli valid reason thing happen era reason keep say ai actual love hear think machin learn particular set method tool mayb version mine open optim sampl system learn machin learn system learn make decis make decis pattern recognit know find pattern make decis real world close feedback loop someth like symbol ai expert system reason system knowledg base represent kind thing search neighbor fit think machin learn even like word machin learn think field talk make larg collect decis uncertainti larg collect entiti right principl scale say principl singl entiti make decis singl agent singl human realli immedi goe network decis good word good word kind part problem continu convers use ai want kind rais flag know intellig real intellig know much abstract reason level human clue tri build clue eventu may emerg make know breakthrough eventu start get glimmer happen right okay take data tri make good decis base tri scale tri econom viabli tri build market tri keep valu scale aspect look intellig comput dumb seem intellig use buzzword intellig use sens machin learn scope narrowli learn data pattern recognit talk topic mayb data scienc anoth word could throw mix realli import decis part consequenti decis real world go medic oper go drive street thing scarciti thing impact human be environ base data adapt use comput help kind thing go forward whatev want call let call ai let agre call ai let say goal intellig goal realli good work system planetari scale never seen reclaim word ai dartmouth confer mani decad ago dream human want reclaim want new word think bad choic mean read one littl thing histori basic mccarthi need new name cybernet alreadi exist like one realli like norbert wiener norbert wiener kind island felt encompass sens look languag cybernet everyth talk control theori signal process notion intellig close feedback loop data word live partli mayb person mccarthi need new word say differ part show got invent word think forward movi would made great choic think forward creat sober academ real world disciplin terribl choic led promis true understand understand artifici perhap understand intellig small tangent one great person machin learn whatev heck call field think scienc progress person fundament principl theori research outsid person say one kind person mine prefer kind network around feed agre disagre kind person need right think person littl exuber littl bit readi promis moon littl bit much ascend think good certainli attract lot young peopl field lot peopl come strong misconcept unlearn find someth think got multipl voic hear enough sober voic continu fun tangent speak vibrant person would yeah think technic speak possibl help know answer less anonym littl local know world kind enter trust peopl world start discuss know peopl go hurt go total wast time lot wast time know lot us pull facebook earli caus clearli go wast lot time even though valu yeah world somehow enter know get kind appeal might new thing might happen kind trust world deep interest complex psycholog aspect around anonym chang human behavior quit dark quit dark yeah think lot us especi us realli love advent technolog love social network came see neg start see comment section think mayb know cnn someth start go wow dark know technolog amplifi sorri big philosoph question topic think human be caus also thing foot psycholog think human be fundament good like us good intent could mind depend context environ everybodi could evil answer fundament good fundament limit us know blinker see person pain easili see person point view easili much head world good day think technolog could open us know perspect less blinker understand know lot war human histori happen ignor thought person person huge amount lifetim seen technolog realli help way yet believ know think fundament human good peopl suffer peopl grievanc grudg thing caus thing probabl want regret often think know part progress technolog inde allow littl easier real good person actual well think individu human life societi could model optim problem way think typic mean talk one complex phenomenon whole know individu human life societi whole mean individu human life amazingli complex know optim kind one branch mathemat talk certain kind thing feel way limit complex thing properti optim problem think think interest problem could solv optim kind properti surfac non convex convex linear kind thing saddl point well optim one piec mathemat know like even era awar say sampl come exampl someth come distribut optim sampl well kind certain kind mathematician tri blend make seem sort thing optim roughli speak tri find point singl point optimum criterion function kind sampl tri surfac treat distribut densiti find point high densiti want entir distribut sampl paradigm want know singl point best point optim paradigm optim space probabl measur output could whole probabl distribut start make thing mathemat go high kind abstract hierarchi start lose know abil interest theorem kind tri tri overli abstract small tangent kind worldview find appeal one determinist stochast well easi mean statistician know world highli stochast know go happen next five minut right go ask go say due uncertainti due massiv uncertainti yeah know massiv uncertainti best come rough sens probabl distribut thing somehow use reason distribut scale multi agent system look like optim optim sort make lot sens sort least robot perspect singl robot singl agent tri optim object function start enter real world game theoret concept start pop see optim talk market scale look like see optim see sampl see like mark blend togeth system design think build incentiv system blend thing know particl potenti well optim function call lagrangian right particl know algorithm run happen descript mathemat someth help us understand analyst happen right thing happen talk know mixtur human comput market forth certain principl allow us understand happen whether actual algorithm use sens clear point may set multi agent market kind system think individu agent system ask task incentiv way get certain signal util point know answer may optim find answer okay artist could embed insid overal market know game theori broad often studi narrowli certain kind problem roughli speak know go kind anticip littl bit anticip anticip kind go back forth mind run kind thought experi talk interest point term game theori know optim problem realli hate saddl point mayb describ saddl point heard kind mention branch optim could tri explicitli look saddl point good thing oh optim game theori kind differ equilibria game theori highli explanatori behavior attempt algorithm tri say happen equilibrium would see certain kind behavior see real life economist want especi behavior economist continu differenti game theori continu space simplest equilibria saddl point nash equilibrium saddl point special kind saddl point classic game theori tri find nash equilibria algorithm game theori tri find algorithm would find tri find saddl point mean liter tri know economist know nash equilibria limit definit explanatori mani situat realli want kind equilibria name associ came histori certain peopl work new one emerg know one exampl stackelberg equilibrium know nash play game mayb cooper go think go decid go thing simultan know stackelberg go first mover go make move go look move go make sinc know go look move anticip go someth stupid know also anticip kind go back forth first mover thing differ equilibria right mathemat yeah thing certain topolog certain shape like algorithm dynam move toward move away thing know question answer studi other especi becom stochast especi larg number decentr thing know young peopl get field kind think done know tensorflow well open problem realli import interest strateg set collect data suppos know go know well right well got collect data mayb want push part space know much get data caus later realiz never never go way game set know part overal know data analysi context even game poker fascin space whenev uncertainti lack inform super excit space linger optim second look deep learn essenti minim complic loss function someth insight hope see kind function surfac loss function deep learn real world tri optim someth interest usual kind problem optim think optim point view surfac first pretti smooth secondli parameter kind lot path reason optima kind get downhil optimum view hard might expect high dimens fact optima tend realli good one other good tend sometim find good one sort still need explan yeah particular surfac come particular gener neural net kind suspect chang 10 year exactli surfac other optim theori help contribut surfac algorithm year arithmet oper littl bit nonlinear come neurosci per se mean mayb mind peopl work think brain arithmet circuit kind field comput scienc control theori layer could transform thing certain way smooth mayb could find paramet valu sort big discoveri work abl work scale think stuck certainli stuck caus understand brain term algorithm side sort gradient descent think stuck gradient descent varianc varianc find interest think someth els invent abl walk optim space interest way co design surfac architectur algorithm ask stay kind architectur neural net know phase retriev architectur matrix complet architectur know think kind come place yeah stochast gradient algorithm domin version littl better other guarante robust ongo research kind figur best arm situat think start co evolv put pressur actual architectur particular way differ way algorithm avail differ way realli anticip co evolut process know gradient amaz mathemat object lot peopl start studi deepli mathemat kind shock think way suppos tell move along x axi go uphil object three unit wherea move along axi go uphil seven unit right go allow move certain unit distanc right go well peopl say go go along axi get biggest bang buck know buck one unit go put axi right even take strength step size put x axi get less bang buck seem like complet clear argument wrong gradient direct go along axi take littl bit x axi understand know math even trivial call oper like gradient trivial know exploit properti still import know pervad descent got kind problem get stuck mani way never know good dimens depend line work recent kind stochast get dimens depend theori come pretti favor result certain kind stochast suffici condit gener know give good guarante necessari condit must done certain way gener stochast much random inject walk along gradient kind random random good process stochast good yeah give simpl answer sens kind amaz stochast know particular featur surfac could hurt one thing determinist hurt chanc littl chanc would get hurt stochast kind save particular featur surfac fact think surfac discontinu first deriv like absolut valu function go hit point nondifferenti run determinist algorithm point realli someth bad wherea stochast mean pretti unlik go happen go hit point nontrivi analyz especi higher dimens also stochast intuit good properti kind appeal high dimens lot larg number reason part mathemat kind fun work field get tri understand mathemat long stori short know partli empir discov stochast gradient effect theori kind follow say see get clearli beauti mysteri profound idea optim know let say nesterov work nesterov acceler pretti surpris pretti deep elabor well nesterov acceler suppos go use gradient move around space reason allud nice direct move suppos tell allow use gradient go allow use local person sens kind chang surfac go give kind comput abl store previou gradient start learn someth surfac go restrict mayb move direct like linear span gradient kind move arbitrari direct right well defin mathemat complex model certain class algorithm other ask certain kind surfac fast get optimum answer smooth convex function answer one number step squar within ball size k step gradient descent particular slower rate one k could ask gradient descent actual even though know good algorithm best algorithm answer well clear yet one k squar lower bound probabl best gradient one k someth better think surpris nesterov discov new algorithm got two piec two gradient put togeth certain kind obscur way thing even move downhil time sometim goe back uphil physicist kind make sens build momentum kind right intuit intuit enough understand kind work achiev one k squar mathemat structur still kind day lot us write paper tri explor understand lot cool idea optim kind use gradient think number one goe back know 150 year nesterov think made major contribut idea like said gradient sens mysteri trivial trivial coordin descent trivial one pick one coordin think human mind think human mind think gradient easi human mind grappl absurd question statist littl bit somewher math scienc technolog somewher convex hole set principl allow make infer got reason believ also principl allow make decis reason believ go make error requir assumpt mean error mean probabl start make assumpt led conclus ye guarante way probabl make error small probabl continu make error time small probabl found someth real small high decis make big part decis make big part yeah statist short histori goe back formal disciplin 250 year call invers probabl around era probabl develop sort especi explain gambl situat cours interest would say well given state natur certain roulett board certain mechan kind outcom expect see especi thing long amount time outcom see physicist start pay attent peopl said well let turn problem around saw certain outcom could infer underli mechan invers problem fact quit statist call invers probabl name field believ laplac work napoleon govern need censu franc learn peopl went gather data analyz data determin polici said well let call field kind thing statist word state french etat studi data state anyway caught call statist ever sinc time got formal sort 30 around time game theori decis theori develop nearbi peopl era think either comput scienc statist control econ von neumann develop game theori also think decis theori wald econometrician develop decis theori turn statist data analyz loss function care question tri ask probabl model risk face make certain decis day advanc statist curricula teach decis theori start point branch two branch bayesian frequentist decis statist beauti mysteri mayb surpris idea come across yeah good question mean bunch surpris one someth way technic thing someth call jame stein estim kind surpris realli take time wrap head around tri mayb think want even want tri let say colleagu steven stigler univers chicago wrote realli beauti paper jame stein estim help view paradox kind defeat mind attempt understand steve nice perspect one troubl statist like physic quantum physic multipl interpret wave particl dualiti physic get use time still kind haunt realli quit understand relationship electron wave electron particl well thing happen bayesian way think frequentist differ sometim becom sort practic physic differ practic give rather differ answer much like wave particl dualiti someth kind get use field defin bayesian frequentist yeah decis theori make video peopl could see call bayesian frequentist kind help tri make realli clear come decis theori know decis theori talk loss function function data x paramet theta function two argument okay neither one argument known know data priori random paramet unknown right function two thing know tri say want function small want small loss right well go sort say well go averag quantiti maxim someth know turn uncertainti someth certain could look first argument averag could look second argument averag bayesian frequentist frequentist say go look x data go take random go averag distribut take expect loss x theta held fix right call risk look data set could get right say well certain procedur data set call frequentist guarante right think appropri like build piec softwar ship peopl use kind data set want stamp guarante peopl run mani mani data set never even thought 95 time right thing perfectli reason bayesian perspect say well go look argument loss function theta part okay unknown uncertain could person probabl know mani tall peopl tri infer averag height popul idea roughli height go averag theta loss function one argument gone function x bayesian say well let focu particular x got data set got condit condit x say someth loss bayesian approach thing bayesian argu relev look data set could gotten averag frequentist approach realli data set got right agre especi situat work scientist learn lot domain realli focus certain kind data gather data make infer agre though know sens need frequentist guarante write softwar peopl use want say someth two thing got fight littl bit blend long stori short set idea right middl call empir bay empir bay sort start bayesian framework kind arguabl philosoph know reason kosher write bunch math kind flow realiz bunch thing know real world know everyth uncertain certain quantiti point ask reason way plug estim thing okay case quit reason thing plug natur thing observ world plug littl bit mathemat assur realli good base math base human expertis good oh go bayesian framework allow put lot human expertis math kind guid along path kind reassur end could put stamp approv certain assumpt thing work ask question favorit know surpris nice idea one access someth call fals discoveri rate know make one hypothesi test make one decis make whole bag bag decis look one made discoveri announc someth interest happen right go subset big bag one made discoveri subset bad fals fals discoveri like fraction fals discoveri among discoveri small differ criterion accuraci precis recal sensit specif differ quantiti latter one almost frequentist flavor say given truth null hypothesi true accuraci would get given altern true would get kind go forward state natur data bayesian goe direct data back state natur actual fals discoveri rate say given made discoveri okay condit data probabl hypothesi go direct classic frequenc look well know prior need empir bayesian goe ahead plow forward start write formula realiz point thing actual estim reason way kind beauti set idea kind line argument come certainli mine sort came robbin around 1960 brad efron written beauti variou paper book fdr know benjamin israel john stori bayesian interpret use absorb thing year find healthi way think statist let ask intellig jump slightli back philosophi perhap said mayb elabor said defin even question intellig difficult question use question think one day understand fundament human intellig mean know good benchmark gener intellig put machin work topic much realli ask question psychologist realli studi consid least expert point know psychologist aim understand human intellig right think mani psychologist know fairli humbl might tri understand babi understand know whether someth solid liquid whether someth hidden mayb child start learn mean certain word verb noun also know slowli sure tri figur thing human abil take realli complic environ reason abstract find right abstract commun interact know realli staggeringli rich complic know think humil think kind aim near futur certain psychologist experi babi lab peopl talk much limit aspir know kahneman tverski would look reason pattern deepli understand reason sort say hey odditi reason thing think also emphas thing write know ai revolut happen yet yeah great blog post emphas know step back look intellig system kind whatev mean intellig human anim know plant whatev know market bring good citi know food restaur someth everi day system decentr set decis look far enough away like collect neuron everi neuron make littl decis presum way step back enough everi littl part econom system make decis like brain know individu neuron overal goal right someth happen aggreg level thing economi peopl eat citi robust work scale small villag big citi work thousand year work rain shine adapt kind know adject one tend appli intellig system robust adapt know need keep adjust self heal whatev plu perfect know intellig never perfect market perfect believ era say well comput human smart know market market intellig human evolv market particip right market per se neuron could view market econom know neurosci kind perspect interest pursu point though studi human realli world best psychologist studi thousand year come theori human intellig might never discov principl market know suppli demand curv know match auction real principl lead form intellig mayb human intellig arguabl anoth kind intellig probabl third kind intellig fourth none us realli think much right realli relev comput system futur certainli market one relev right wherea understand human intellig clear relev right probabl want gener intellig whatev one mean know understand intellig deep sens definit human intellig got ta broader thing mysteri market intellig know definit philosoph stanc say got move beyond intellig sound ridicul yeah blog post defin differ kind like intellig infrastructur ai realli like concept describ see see earth human civil singl organ think intellig organ think perspect market intellig infrastructur increas increas linearli increas exponenti think futur intellig yeah know tend think tend answer question like know scienc fiction hope catch guard well said far futur fun ask probabl know like said predict futur realli nearli imposs say axiom one day creat human level superhuman level intellig scale market scale individu think think would take mayb ask anoth question would system differ biolog human be see around us today possibl say anyth interest question stupid question stupid question scienc fiction scienc fiction total happi read scienc fiction think time life love like brain vat kind know littl thing peopl talk student rememb know imagin know brain bodi know bunch wire right suppos everi one replac liter wire suppos wire turn actual littl wireless know receiv sender brain got sender receiv know exit know axon dendrit bodi replac sender receiv could move bodi somewher put brain vat right could thing like start kill sender receiv one one kill person know thought bodi walk around world move scienc fiction thing fun think intrigu thought think everi 18 year old take philosophi class think thing think everyon think could happen societi kind bad realli think right thing us age group think realli think mani present know first challeng danger real thing build know spend much time scienc fiction least public like think mayb beer privat right well go broadcast beer go go facebook want lot peopl show yeah love facebook twitter amazon youtub optimist hope mayb mayb ground optim hope let ask mentor brightest sort semin figur field give advic peopl undergradu today take take know advic journey interest machin learn idea market econom psycholog kind thing explor step take journey well yeah first door open second journey like languag brilliant great brilliant idea therefor know success enter field apprentic spend lot time work hard thing tri pull back broad talk lot peopl like enter kind creativ commun year need human connect critic know think know musician artist someth know immedi day one know geniu therefor know practic realli realli hard basic humbl realiz never expert everyth kind pick lot random lot kind luck luck kind pick branch tree go go branch yeah commun graduat school still think one wonder phenomena world much apprenticeship advisor much group peopl belong four five year process plenti time start kind noth come someth know expertis start creativ start flower even surpris self cooper endeavor think lot peopl think scienc highli competit think field might way cooper might imagin peopl alway teach someth peopl alway happi clear feel expert certain kind thing much expert lot thing lot relev lot know societi know alway will reveal ignor peopl around teach thing think lot us feel way field cooper might add also intern cooper see barrier nation see especi current era everyth odd way us think human endeavor cooper much tri togeth know benefit everybodi last question learn french languag beauti english french great question first think italian actual beauti french english also speak marri italian kid speak italian anyway kid asid everi languag allow express thing bit differ one great fun thing life explor thing fact kid teen colleg student ask studi say well heart heart certainli lot math math good everybodi poetri histori languag know throughout life want think person want done french learn say late teen live middl countri kansa much go kansa due respect kansa parent happen french book shelf boredom pull found fun kind learn languag read first heard spoken idea spoken realiz somehow knew previou life made connect travel love go beyond barrier comfort whatev found train franc next say older peopl live whole life abil commun special abil also see peopl shoe empathi kind work languag part kind experi also embed french cultur quit amaz languag rich someth inher beauti creativ went learn lot song read poem read book actual mit podcast today young professor yet marri lot friend area kind bore person said heard lot italian around happen lot italian mit italian professor reason kind vagu understand talk said well learn languag later met spous italian becam part life go china lot day go asia go europ everi time go kind amaz rich human experi peopl idea travel kind amazingli rich love divers buzzword realli mean someth love emb peopl experi yeah learn languag big part think said interview point million dollar infinit time whatev would realli work realli want ai natur languag realli done right deep understand languag amazingli interest scientif challeng one far away one far away good natur languag peopl kind realli invest think lot see core ai understand realli help human commun understand someth human mind semant come human mind agre think long time career caus kind behind earli day kind know enough stuff mit learn much languag late point kind spend whole career admir field littl way learn languag know kind part brain train jan right truli mile davi machin learn think better place mike huge honor talk today merci beaucoup right pleasur thank listen convers michael jordan thank present sponsor cash app download use code lexpodcast get 10 10 go first organ inspir educ young mind becom scienc technolog innov tomorrow enjoy podcast subscrib youtub give five star appl podcast support patreon simpli connect twitter lex friedman let leav word wisdom michael jordan blog post titl artifici intellig revolut happen yet call broaden scope ai field embrac fact wit creation new branch engin term engin often invok narrow sens academia beyond overton cold effectless machineri neg connot loss control human engin disciplin want current era real opportun conceiv someth histor new human centric engin disciplin resist give emerg disciplin name acronym ai continu use let awar real limit placehold let broaden scope tone hype recogn seriou challeng ahead thank listen hope see next time say interest disagr jan lacun jan old friend say think disagre much realli kind let build kind mental work kind mental kind concret speak french speak french togeth lot common one want highlight disagr realli fundament one think kind emphas jan emphas pattern recognit emphas predict interest tri take far could perfect predict would give kind thought experi think way limit perfect predict never data set allow figur readi question go ask next clue never know thing moreov us find day kind situat anticip kind novel variou way moment want think want also go market forc act us like go street full crane street got got think got think might realli want got sort think much cost action versu action got think risk involv lot current pattern recognit predict system risk evalu error bar right got think peopl decis around got think collect decis even think like medic treatment know go take predict neural net health someth consequenti readi heart attack number 0 7 even data world ever collect heart attack better doctor ever go trust output neural net predict heart attack go want ask question around go want look us possibl data causal thing go want dialogu doctor thing think gather data know could go hope see think say predict everyth miss stuff predict plu decis make everyth equal import field emphas predict jan rightli seen power cost peopl awar decis make rubber realli hit road human live stake risk taken got gather data got think error bar got think consequ decis other got think economi around decis blah blah blah blah one work smaller tribe right one peopl talk know go real world industri know amazon say half peopl work decis make half know pattern recognit import word pattern recognit predict think distinct linger word distinct constrain sort lab data set versu decis make talk consequenti decis real world messi uncertainti real world whole whole mess actual touch human be scale forc distinct help add perspect broader perspect right total agre hand real predict person cours want real world want predict real world event say possibl data set context know strateg thing someon data might gather thing could gather reason process around data take data make predict base data one thing work sure other work hear often talk especi clariti talk think excit concern area ai term decis make talk ai system help make decis scale distribut way million billion decis sort market decis start point sort give exampl system think think kind system yeah first absolut get territori beyond expertis lot thing go obviou think like like think histori littl bit think put back sixti kind bank system computer realli databas theori emerg databas peopl think actual move data around actual money know valid transact atm happen actual know valid forth kind issu get start get seriou sort thing like like think kind almost thought experi help think someth simpler music market first order music market world right countri sure someth call thing call record compani make money prop realli good musician make superstar make huge amount money long tail huge number peopl make lot lot realli good music actual listen peopl famou peopl market career make money creator creator creator call influenc whatev diminish peopl make extrem good music especi hip hop latin world day laptop weekend anoth job week put soundcloud site eventu get stream get turn bit econom valuabl inform lost get put peopl stream walk around big citi see peopl headphon especi young kid listen music time look data littl music listen famou peopl music none old music latest stuff peopl made latest stuff like 16 year old somewher never make career never make money cours counter exampl record compani incentiv pick highlight long stori short miss market consum produc relationship level actual creativ act pipelin spotifi world take stuff stream along make money subscript advertis thing make money right offer bit piec peopl highlight simul market anyway real market would creator music actual somebodi good enough peopl want listen data avail dashboard show map unit state last week place song listen transpar vetabl someon provid see listen 10 000 time provid know real data know real data come give show broadcast peopl listen come right could go make 20 000 three time year start career sens ai creat job take away human job creat new job creat new market creat market connect produc consum person make music say someon come show lot hey play daughter wed 10 000 say 8 000 say 9 000 get incom 100 000 go millionair even think realli valu music person connect even much young kid want wear tshirt favorit musician signatur listen music internet internet abl provid button push merchandis arriv next day well kid bought shirt happi person made music get money advertis need creat market produc consum take 5 cut compani perfectli sound go forward futur creat new market rais human happi seem like well easi creat dashboard kind creat connect think uber whatev think challeng real world thing like actual new principl go need tri creat new kind two way market differ scale ever done go unwant aspect market bad peopl data get use wrong way fail way deliv think like anyon ran big auction ran big match servic econom think thing mayb get huge issu aris start creat market start least solidifi thought allow move forward think yeah talk head research spotifi actual think longterm goal said least one million creator make comfort live put spotifi think articul realli nice vision world digit cyberspac market think compani like spotifi youtub netflix creat market ai problem interfac problem interfac design kind econom problem hire solv problem well part top silicon valley attitud know creat system like googl search box good everyon adopt everyth said realli think miss kind cultur liter 16 year old abl creat song creat silicon valley entiti hire per se creat ecosystem want belong cultur credibl thing like netflix credit want credibl creat show content call content terribl word cultur movi kind go give larg sum money somebodi graduat usc film school whole thing kind like rich white peopl thing american cultur much rich white peopl immigr african came brought cultur rhythm world creat whole new thing american cultur compani artifici creat say hey go buy got partner anyway denigr compani tri sure ask question even make effort partli respect cultur technolog person got blend technolog cultur mean much role think algorithm machin learn connect consum creator sort recommend system aspect yeah great question think pretti high magic algorithm good recommend system way better bad recommend system recommend system billion dollar industri back even 10 20 year ago continu extrem import go forward favorit recommend system put someth well histor one first went amazon first like amazon put book peopl busi librari local booksel went busi come accept probabl book sold poor peopl read ever local book store come back econom sometim work go go anyway final start go bought book realli pleas see anoth book recommend never would thought bought bunch obvious good busi model learn thing still day kind brows use servic think lot peopl get lot good aspect recommend system learn peer indirect way algorithm meant impos learn realli tri find data work well kind entiti complex human life like shirt go get recommend shirt interest tri recommend restaur hard hard scale blend recommend system econom idea match realli realli still open research wise new compani go emerg well think go messi difficult land say polit thing like youtub twitter deal term recommend system abl suggest think facebook launch facebook news recommend kind news like interest think ai solvabl whatev term want use think solvabl problem machin deepli human problem unsolv even think level think broken compani monet advertis least facebook want critiqu realli tri connect produc consum econom way right one want pay anyth know start googl facebook went back playbook know televis compani back day one want pay signal pay tv box signal least back day advertis kind fill gap advertis new interest somehow take live quit right fast forward googl provid servic peopl want pay somewhat surprisingli nineti made end make huge amount corner advertis market seem like go happen least littl thing right hand side screen seem econom interest compani mayb choic tv market go away billboard got think sadli googl well make money think much wait minut produc consum relationship set us advertis market creat actual market produc consum produc person creat video clip person made websit person could make thing person could adjust function demand person side ask differ kind thing know see glimmer influenc kind littl glimmer market done 20 year ago thought creat parallel advertis ecosystem facebook inherit think also think much fast forward make huge amount money advertis news thing click feed advertis connect advertis want peopl click certain thing money flow facebook much incentiv start find break peopl tell well get troubl tri adjust smart ai algorithm right figur bad click mayb click rate someth els find pretti much hopeless get complex human life tri fix could also fix whole busi model busi model realli human produc consum econom valu liber connect directli valuabl peopl abl pay right micro payment like small payment micro even micro like exampl suppos go next week go india never india right coupl day mumbai idea right could go web right search go kind hopeless go find know lot advertis face right realli want broadcast world go mumbai someon side market look recommend system look possibl peopl come mumbai look peopl relev someon age group someon kind know level give littl privaci happi go get back person make littl video go write littl two page paper cool thing want move week especi right go look go pay micro payment go pay know hundr dollar whatev real valu like journal um honest subscript go pay person moment compani go take 5 person got gig economi know done know think littl bit behind youtub actual peopl could make thing connect market would make thing independ tell incentiv way um yeah compani think thought long hard distinguish facebook one side thought thing think uh think ai fix everyth uh amazon think time alreadi real world deliv packag peopl door worri market worri seller know worri thing great thing mayb great know busi model say googl sort hover somewher think long long time got think probabl see youtub pregnant possibl might thought probabl head direct um uh know silicon valley domin googl facebook kind mental subscript advertis core problem right fake news actual ride top mean monet clip rate core problem got remov advertis go linger mean interest thesi know everyon realli deepli think right thought advertis model thing thing ever fix build algorithm despit busi model know find better angel natur good societi individu think slowli think first differ could say slowli move away advertis model direct connect consum creator question also advertis model success term make huge amount money therefor abl build big compani provid realli smart peopl work creat good servic think possibl clarifi think move away well think yeah know societi yeah well compani mean first full disclosur day week amazon kind want learn thing know speak amazon way know go actual believ get littl bit tri creat market realli use advertis crucial part well good question becom crucial becom present go amazon websit know without reveal mani deep secret amazon tell know lot peopl compani question huge question go want world zero advertis actual bad world okay way think compani like amazon tri bring product custom right custom given moment want buy vacuum cleaner say want know avail know go obviou littl bit work recommend system sort help right suppos person made world know spent huge amount energi great idea made great vacuum cleaner know realli nail mit know whiz kid made great new vacuum cleaner right go recommend system one know algorithm find ai fix okay right allow vacuum cleaner start get front peopl sold well advertis advertis signal believ product enough will pay real money consum look signal say well first know cheap littl ad caus right know know super cheap know penni see ad actual know compani make know real money kind flow see ad may pay attent actual might want see hey guy spent money vacuum cleaner mayb someth good look part overal inform flow good market advertis role problem cours signal complet gone know domin tini littl thing add big money compani know think think chang societi know stick thing annoy lot peopl advertis current annoy peopl provid inform think googl probabl smart enough figur dead bad model even though hard huge amount money figur pull away slowli sure ceo figur need need reduc advertis zero reduc time bring produc consum actual real valu deliv real money paid take 5 cut 5 could start get big enough cancel lost revenu kind poor kind advertis think good compani realiz facebook know god bless bring know grandmoth bring children pictur grandmoth live fantast need think new busi model core problem start connect produc consum think continu make money buy next social network compani buy next one innov level high health issu go away apolog kind return word think exact term matter sort defens advertis think kind direct connect consum creator produc advertis strive right best advertis liter facebook listen convers heard go india abl actual start automat make connect start give offer like apolog matter term draw distinct possibl make advertis better better better algorithm actual becom connect almost direct connect good question let compon first talk defend advertis okay defend way get signal market come way especi algorithm sign someon spent money sign think valuabl think thing someon els think valuabl trust peopl might will listen trust facebook though intermediari think care okay think find creepi know go india next week convers think could put pr hat think find facebook creepi trust major popul silicon valley compani saw like approv rate rank much peopl trust compani facebook gutter gutter includ peopl insid facebook attribut come find creepi right talk might walk street right unknown person know kind come say hear go india mean even facebook want transpar human societi want know someth actual reason know someth someth look later audit kind approv know someth care way care relationship even econom one someth someon could exploit way know care troubl whatev world right happen way much facebook know thing lot peopl could exploit exploit time think peopl find creepi facebook care real sens big brother care us role compani like wait big brother part care trust mean compani link lot compani lot inform us would argu compani like microsoft inform us facebook yet trust microsoft well microsoft pivot microsoft know satya nadella decid realli import want creepi thing realli want peopl trust us actual use inform way realli would approv decid right kind ad health market connect someon produc consum random produc consum peopl see like sens transact happi go side compani help moment choos choos fine also think differ know brows versu buy right moment life want buy know gadget someth need someth moment need ammonia hous someth got problem spill want go want advertis moment want led variou know annoy want go extrem easi want moment might say like today go shop mall want walk around see thing see peopl expos stuff want control though want compani algorithm decid right think thing total loss control facebook think take control us decid want certain kind inform inform much relat know us realli want know us want help way want help decid control want total agre facebook way optimist thing think facebook kind person inform us could creat beauti thing realli optimist facebook could could see think optim misplac bit busi model behind thing creat beauti thing realli let let clear someth peopl would valu think busi model think suddenli discov know long hot shower disagre disagre term discov lot amaz thing shower say said come shower think lot peopl discov think guy also full disclosur compani call unit master board creat music market hundr thousand artist sign done thing like gone nba nba music find behind nba clip right music right compani right busi model mind get go right execut day one valu brought kid made song suddenli song nba websit right real econom valu peopl know differ optim abl sort chang direct titan right yeah older seen titan crash got elabor caus total agre want know difficult think problem exampl want read news would lot time day someth make either smile think way like conscious think realli gave valu like sometim listen daili podcast new york time way better new york time way peopl listen like real journal happen reason podcast space make sens often listen 20 minut would will pay like 5 10 experi difficult kind get littl transact difficult creat frictionless system like uber exampl thing intuit first pay littl bit money know send someth call court financi thing like medium site pay would great post medium would love pay dollar other want per se also site actual goal goal actual broadcast channel monet way chose mean could peopl know could fine also musician make music think right model pay littl subscript fee right peopl copi bit easili somewher valu valu connect made real human be follow right creat yet valu think lot open question hot open question also yeah want good recommend system recommend cool stuff pretti hard right like recommend stuff base brows histori like base stuff know quot unquot unknown interest realli interest question may disagre mayb think love recommend system want give everyth way trust yeah exampl morn click know pretti sleepi morn click stori queen england ye right give damn queen england realli clickbait kind look funni say heck talk want life know head direct brows histori system reason system think care queen england brows histori right say trace digit exhaust whatev kind model collect stuff go figur us well tri figur like kind one person like trump someth mayb could figur tri figur know 500 million peopl know way way think think think human amazingli rich complic everi one us littl quirk everi one us littl thing could intrigu us even know intrigu us sign past god come know fall love want compani tri figur anticip want provid forum market place kind go hook crook happen know walk street hear chilean music play never knew like chilean music wow side want provid limit know interest place go right tri use ai kind know figur put world figur know creat huge space human be creativ style enrich come forward lot transpar peopl randomli anonym put comment special base stuff know fact know broken right know especi celebr know anybodi anonym peopl hurt lot lot peopl right part thing silicon valley think know collect inform use great way pessimist much optimist natur think wrong path whole technolog take limit creat let human rise tri replac ai mantra tri anticip tri predict go go abl thing go make thing wors okay right give chanc right recommend system creepi peopl shadow watch everi move look trace directli interact sort close friend famili way know convers actual interact back forth think place recommend system sort step caus emphas valu human human connect yeah give chanc ai human connect role ai system convers term tri figur kind music like watch listen actual convers natur languag otherwis yeah want push back mayb say option facebook think misplac think distribut yeah good go hard spot yeah good human interact like daili context around home someth want big compani know would happi technolog help kind technolog well know alexa amazon well good alexa done right think alexa research platform right anyth els alexa done right know could thing like leav water run garden say hey alexa water run garden even alexa figur mean wife come home told littl bit reason would call ai kind stretch littl bit reason actual kind would make life littl easier better know call wow moment kind think overal rise human happi kind thing lone alexa know loneli want alexa feel intrus want design system kind work realli want lot control want transpar control compani stand give context new technolog think good first way success current gener like said mention microsoft realli think pivot kind trust old uncl know think get way go let peopl find technolog empow control control privaci rich set interact peopl go like lot right busi model go forward control privaci look like think abl view data much mean first individu decis peopl want privaci want whole life peopl want privaci zero one legal thing data avail like recal peopl know coupl hundr year ago everyon realli big citi everyon live countrysid villag villag everybodi knew everyth privaci bad better well know arguabl get loss certain kind privaci well peopl help know everyth know someth bad happen help right live big citi one know get help kind depend answer want certain peopl trust relationship kind manag know agenc drift sea technolog agenc want go read thing check box know privaci research per se recogn vast complex technolog legal scholar meet technologist got ta kind whole layer around allud emerg engin field big part electr engin came one around time plug electr wall kind work like underwrit laboratori reassur plug go burn hous machin everyth whole peopl instal thing peopl watch instal whole layer know onion kind thing thing deep interest privaci least interest electr go take decad kind work go requir lot new structur right kind hard talk say lot money made get right someth look lot money made thing provid human servic peopl recogn use part live yeah yeah dialogu sometim goe exuber technologist technolog good kind know public discours know far see much kind thing sober discuss middl challeng want need convers know actual mani forum fora know kind would look mayb could go could read comment section someth would actual kind dialogu go back forth see much right actual resurg podcast peopl realli hungri convers technolog help much comment section anyth includ youtub hurt help\",\n          \"becom cyborg brain fundament chang everyon grew electron fundament differ previou homo sapien call us homo techno think evolv homo techno like essenti new speci previou technolog mean may even profound move us certain degre think comput make us homo techno think brain augment like allow actual evolut like comput acceler degre technolog also acceler would classifi homo sapien homo techno definit homo techno one earliest speci think us follow convers grime artist musician songwrit produc director fascin human think lot histori futur human civil studi dark period past help form optimist vision futur lex friedman podcast support pleas check sponsor descript dear friend grime oh yeah cloud lifter go go know stuff ever use cloud lifter yeah actual microphon cloud lifter michael jackson use realli yeah like thriller stuff mic cloud lifter yeah incred microphon flatter vocal use lot great demo vocal great room sometim easier record vocal room music play wan na feel headphon mic pretti direct think good mic vibe get real good vocal take vibe room anyway michael jackson quinci jone microphon feel way badass right wan na get guess right one name least space time c like letter c told c mean lot thing speed light render rate univers ye spanish crescent moon happen favorit program languag basic run world also power fast danger mess thing realli bad pointer anyway associ name c coolest mean coolest speed light obvious speed light say render rate univers think mean speed light essenti render see think know simul speed light chang improv render speed well alreadi pretti good alreadi pretti good improv know probabl like okay updat upgrad well fast enough us human seem immedi delay latenc term us human earth interact thing like intergalact speci oper much larger scale gon na start notic weird stuff oper like around black hole gon na start see render issu go faster speed light correct realli limit abil one abil travel space theoret wormhol noth gener rel preclud faster speed light travel seem gon na realli funki stuff heavi thing like weird basic terror space time know navig know navig yeah fold space basic make wormhol name c ye think multipl peopl one person know like morn differ person tonight say record basic midnight awesom ye thank much think eight hour late right time good morn begin new day soon anyway person morn even multipl peopl think one person mayb clue giant mysteri okay realli intens question let go let go ask like look mirror peopl tell even mean mean think person chang everyon talk inconsist person yeah person person interact person materi mood like go like megalomaniac like know like total hermit shi combinatori combin mood person interact yeah mood peopl interact think everyon like mayb well everybodi acknowledg abl introspect bring kind person kind mood bring best artist human introspect like best friend like peopl like super confid know gon na understand everyth say like best friend start realli funni alway like peak mode like yeah take lot get let talk constraint talk constraint limit help artist human get way like constraint creat music creat art live life like constraint world put hate constraint move good right like like progress technolog chang constraint like artist creation know make video music stuff get lot cheaper constantli new technolog new softwar make faster easier much freedom 70 like michael jackson know record thriller microphon like use mix desk stuff like probabl even get studio probabl realli expens realli good singer know use like mix desk everyth know make made whole album comput lot freedom also constrain differ way like liter million artist like much bigger play field like also learn music natur musician know anyth actual music know like comput realli kind like mess around like tri thing well yeah mean natur music chang say know actual music music chang music becom talk becom like merg technolog ye becom someth like note piano becom weird composit requir engin skill program skill kind human robot interact skill still thing michael jackson like good ear good sens tast good final thing put togeth like allow enabl empow laptop layer stuff start like layer insan amount stuff super easi think music product realli underr art form feel like peopl realli appreci look publish split way peopl like pay produc stuff super produc deepli underr like mani song popular right last 20 year like part reason popular product realli interest realli sick realli cool like think listen like peopl realli understand music product sort like weird discombobul art form like formal new like formal train path mostli driven like autodidact like like almost everyon know good product like go music school anyth taught mostli differ like music produc know common time togeth differ kind weirdo caus hung rick rubin know yeah mean rick rubin like liter one god music product like one peopl first know like made music product know made product import actual lyric note thing interest know speak hang seem sit silenc close eye listen like almost noth noth somehow give freedom best version music product somehow like encourag less simplifi like push toward minim mean guess mean work differ rick rubin caus rick rubin produc artist wherea like mostli produc differ situat also think rick rubin would say advanc categori produc like like earn engin stuff peopl like stuff usual like stuff engin produc artist yeah guess would say era like post rick rubin era like come kind like skrillex school thought like yeah engin produc artist like mean late sometim work produc gentli sort delic start collabor bit like think kind like whatev 2010 explos thing everyth becam avail comput kind got like lone wizard energi thing go embrac loneli loneli somehow engin creativ like stuff creativ quot unquot geniu quot privaci mind ye well thing talk daniel eck said like artist 10 year like 10 good year usual stop make like vital shit feel like sort like near end 10 year becom somebodi els like process becom somebodi els reinvent work peopl never work peopl find make like except rejuven make like vital work ever made think anoth human brain like one best tool possibl find like funni way put love like tool like know whatev hp plu one like add like stat charact like anoth human brain like squar instead like ad someth doubl experi point love also mention play tavern music love first think first stop tavern music yeah audio okay okay make yeah make podcast annoy add post add post one want listen podcast probabl would make remind like video game like role play video game experi point someth realli joy wander place like elder scroll like skyrim explor landscap anoth world get experi point work differ skill somehow progress life know simpl messi complex life usual bad guy fight skyrim dragon sure elden ring bunch monster fight love feel like elden ring feel like good analog music product though like feel like engin peopl creat open world sort like similar peopl music produc like hidden archetyp like one realli understand one realli know like like artist engin like art fairli complex engin well say get enough credit kind chang becom person everyth engin well mean other gone know like timbaland skrillex peopl like know famou think gener think peopl get confus realli know per se see song like like hit song like tri think like go like even basic pop hit like like rule dua lipa someth product actual like realli crazi mean song also great like product except memor like know like one even know produc song like part like rhetor discuss creation art sort like consid music produc think music produc use simpli record thing yeah interest think movi talk actor actress also talk director talk like music often beatl music produc one first kind guy one first peopl sort introduc crazi sound design pop music forget name forget name know like weird stuff like drop piano like yeah oh get yeah yeah yeah get sound get authent sound lyric think fit import heartbroken learn elvi write song mad lot peopl write song understand thing feel like desir authent use like realli mad like peopl write produc music like fake realiz like weird bitter like agronu art authent kind like weird realiz recent start think like art sort decentr collect thing like art kind convers artist ever live know like like realli sort like anyon reinvent wheel like kind take know thousand year art like run littl algorithm like make interpret join convers artist came beauti way look like like feel like everyon alway like copyright ip authent like think need stop see like egotist thing like oh creativ geniu lone creativ geniu like think art think art someth sort bring human togeth also art also kind collect memori human like give fuck whatev ancient egypt like much grain got sent day send record like know like went know mani shield need produc like rememb art like know like day day life stuff seem import art help us function surviv gone like thing realli gon na left art technolog obsolet fascin like human dead true good compress human histori art gener across differ centuri differ millennia alien come alien come gon na find hieroglyph pyramid mean art could broadli defin might find like engin marvel bridg rocket guess sort classifi though architectur art consid engin format art sure suck like digit art easier delet apocalyps nuclear war disappear ye physic someth still valuabl physic manifest art suck like music exampl play somebodi yeah think foundat type situat like know like seed bank north stuff like probabl like solar power geotherm littl bunker like human knowledg mention daniel ek spotifi think artist spotifi empow spotifi consum super excit make easi access music kind artist get explor kind music make super easi sort curat playlist fun liber let go know use collect know album cd like hord album yeah like matter realiti could know realli liber could let go let go album kind collect allow find new music explor new artist kind stuff know perspect artist could like mention competit could kind constraint artist platform think better artist mean might propaganda convers daniel ek could easili propaganda victim somebodi propaganda let accept daniel ek tell know understand realli difficult concept differ way like emot intellig someth deep within oh yeah like x hurt like x bite realli hard like ow like get sad like sad hurt accid yeah huge hurt lot accid yeah interest mind emerg children realli memori time even convers yeah thank god memori time like think like mean youngest babi like like like read sci fi short stori mouth must scream good titl oh man mean read mouth must scream hate get rocco basilisk shit kind stori like ai like tortur someon etern like bodi way describ sort sound like feel like like babi like consciou get input everywher muscl like jelli like move tri like commun commun like like like hell state think good rememb like littl babi exit like start like get muscl like autonomi like watch go open phase like like seem good oh think kind like like think suck think might realli violent like violent mental violent psycholog violent conscious emerg think violent thing never thought think possibl carri quit bit trauma think would good thing studi think think address trauma like think might oh mean like echo still shadow somewher think got ta feel help helpless like existenti like fear like unknown place bombard input complet helpless like got ta somewher deep brain good think conscious whole convers imposs difficult question think debbi said like hard yeah talk music like two minut right music music yeah still like purpos love music mean music greatest thing ever favorit thing like everi interview like process like know done anyth want ask abl live oh tell ableton ableton sick one ever ask ableton though yeah well need tech support mainli help help ableton tech anyway ableton back conscious think thing human capabl robot consciou like think entiti think alien consciou like consciou conscious terrenc mckenna quot found fuck love allow swear ye natur love courag make commit natur respond commit remov imposs obstacl dream imposs dream world grind lift trick teacher philosoph realli count realli touch alchem gold understood shaman danc waterfal magic done hurl abyss discov feather bed yeah reason think technolog limit think like alreadi happen like imposs insan done limit amount time acceler rate think digit conscious inevit may abl even understand mean like hurl abyss surround mysteri keep hurl like fearlessli keep discov cool shit yeah like think like like even know law physic law physic probabl current like say speed light current render rate like simul abl upgrad like sort suspect made jame webb telescop like part reason made upgrad know space render see yeah think human super super super limit cognit wonder allow creat intellig be see univers render rate upgrad mayb cognit limit everyon keep talk cognit limit ai gon na render us obsolet like know like thing like amoeba becom allig like like creat ai intellig design liter religion base god creat conscious like god make like incred profound like even comput even much wors like like unfathom wors like know omnipot kind ai like think would think stupid think would recogn profund accomplish god god person mean kind guy complic complic like would acknowledg valu well hope acknowledg valu pay respect creativ ancestor think would think cool think curios trait quantifi put ai think ai curiou curiou us hate dismiss us might know see us know like like oh fuck dog let kill dog love dog dog great util dog like provid lot make friend deep connect anthropomorph like real love dog cat reason even though intellectu much less us think someth sacr us like look univers like whole univers like cold dead sort robot like know ai intellig know kind like univers like cold know logic know abid law physic whatev like like loosey goosey weird art thing happen think beauti like think even think one valu conscious thing worth preserv think case think conscious think kind like religi spiritu thing conscious sacr like know still think even ai render us obsolet climat chang bad get hit comet becom multi planetari speci fast enough like ai abl popul univers like imagin like ai would find planet capabl host biolog life form like recreat fun watch yeah fun watch yeah believ ai magic conscious within conscious know know kind might differ magic might like strang strang differ right gon na hormon like feel like lot magic hormon kind know think magic limit constraint within hormon kind stuff finit life get given limit get come creativ solut danc around limit partner like penguin cold fall love love ultim kind allow us delud mortal finit life ultim live alon born alon die alon love like moment long time forget come creativ hack make life like fascinatingli fun yeah yeah yeah fun yeah ai might differ kind fun ye hope fun intersect think would littl intersect fun yeah yeah think role love human condit think use use like hack like fundament mean human capac love mean think love evolutionari mechan like begin intellig design like read know kropotkin like anarchist like old russian anarchist live next door michael malic know know anarchist modern day anarchist okay anarchist fun kind get anarch littl bit probabl good rout take oh think listen expos idea harm think idea think anarchist challeng system interest way think interest way good soul like refresh mental palett think actual actual ascrib never actual gone deep anarchi philosophi still think though read listen read russian revolut lot soviet lenin kropotkin anarchist sect sort interest kind technocrat actual like women equal applianc realli use technolog reduc amount work peopl kropotkin biologist someth studi anim realli time like think natur magazin think might even start russian magazin publish studi everyon realli darwin time surviv fittest war mechan becom better real cement idea societi violenc kill weak becom better kropotkin kind interest look instanc find instanc natur anim like help stuff like actual love surviv mechan like mani instanc anim kingdom like cooper like help weaker creatur stuff actual evolutionari mechan mean even look child rear like child rear like immens amount love goodwil like immedi get immedi feedback like win competit liter like actual use love evolutionari mechan much use war think like miss part reorient cultur reorient like scienc philosophi orient around darwin littl bit much kropotkin model think equal valid like like cooper love stuff essenti speci surviv evolut power surviv mechan context evolut come back like think engin much import motherhood like lose motherhood engin mean noth human like think societi surviv way see conceptu evolut realli chang also includ idea guess yeah weird thing seem irrat also core mean human love one thing could make lot irrat thing depth connect loyalti power thing irrat ration like like know mayb lose thing order like keep famili togeth order like like actual valu well right mean ration thing cold economist perspect know motherhood sacrif career love know term salari term econom wellb term flourish human could seen kind metric irrat decis suboptim decis manifest love could optim thing kind say save one life save world thing doctor often face like well consid irrat profit model includ social good ye yeah profit model includ social good suddenli would ration decis might difficult know requir shift think profit might difficult measur social good ye learn measur lot thing yeah digit lot thing actual know quantifi vision stuff like like know like go facebook like facebook pretti much predict behavior like surpris amount thing seem like mysteri conscious soul thing quantifi point sure quantifi thing yeah us move digit space want ask someth fan perspect kind know musician onlin person seem like ident play one cool thing internet seem like play ident move digit world mayb even call metavers mean love metavers love idea like way play go well peopl mad think need like think temporari think temporari like know celebr got togeth sang song imagin jeff leonard everyon start hate song imagin hope temporari damn good song think temporari like actual virtual world whatev call metavers otherwis becom know well virtual world like video game elden ring play elden ring play elden ring realli afraid play game liter amaz look way fun look would wan na go stay forev yeah fun nice oh man yeah yeah metavers metavers realli immers sens three dimens like virtual realiti integr necessari realli take close eye kind plug 2d screen becom time realli enjoy journey take almost becom longer c longer lex creatur whatev hell game yeah mean love video game realli becom peopl time like seem like idea metavers idea digit space well even twitter get chanc somebodi prolong period time like across lifespan know twitter account year decad person know good thing feel torment twitter specif social media represent feel like public percept gotten distort find kind disturb one thing disincentiv like want keep make art like complet lost control narr narr stupid lot like like hijack forc far beyond control kind got head thing like random indian musician got like drag geopolit matter like financi like stock market shit like power peopl variou point time vest interest make seem insan fuck fight like peopl realli want celebr figur like consist stay like peopl lot like emot invest certain thing like first like like artifici famou everybodi famou artifici famou like like weird nich indi thing make pretti challeng challeng weird fuck shit lot accident proxi got like foist sort like weird celebr cultur like media train put mani hour media train would love see bf fli wall like tri hard like learn thing like got like got got got stop say like mouth say thing like like thing crazi thing like need crazi thing jar peopl contradictori stuff associ like know like weird posit public imag avatar total crazi thing lost control feel burden avatar static avatar twitter avatar instagram social platform burden becom like caus like peopl want accept chang avatar chaotic avatar avatar stupid shit sometim think avatar moral wrong think avatar mayb like question time like like like know everyon right wrong know like know lot time peopl ascrib intent thing worst possibl intent point peopl think know fine kind word ye ye fine complain curios live doubl tripl quadrupl live life like peopl know life real life interest probabl mean guess probabl yeah luxuri differ know like know avatar mediat avatar nice luxuri luxuri mayb intent tri realli hard make sure differ avatar privat person wear suit time yeah wear suit time recent get recogn lot wear suit hide introvert social anxieti kind stuff hide away love wear suit make feel like take moment serious like know make feel like weirdo best possibl way suit feel great everi time wear suit like know fashion gener know realli awesom thing yeah think definit pain way use social media empow way know us know tri figur peopl think doja cat incred incred like master know like follow okay take anyth serious joke absurd humor kind thing think doja cat might like greatest live comedian right like entertain doja cat actual comedian like realli fuck funni internet great social media know yeah natur humor like humor social media also beauti thing absurd absurd meme like wan na like take moment love like talk art credit authent love mean meme like longer like meme like new still emerg art form complet egoless anonym know made like forefront comedi total anonym feel realli beauti feel like beauti collect human art project like like decentr comedi thing make meme add much day mani peopl day like know think peopl ever think stop enough appreci sick meme exist also make whole brand new art form like modern era like exist like mean sort exist way exist like like know like friend like joke go like mine meme farm meme like video game like meme dealer like whatev like know whole meme whole like new comed languag well art form interest thing lame peopl seem good meme like corpor infiltr meme yeah realli tri could tri like weird caus like tri hard everi like fine like got good one think seen like one two good one like yeah realli caus even corpor infiltr web three make realli sad infiltr meme think someth realli beauti give power dogecoin power like right gon na f sort anybodi tri central tri control rich peopl tri roll control control narr wow thought would fix twitter would fix social media like optimist posit person bit cynic current particular littl slice human tend think twitter could beauti cynic cynic actual refus cynic principl ye briefli express person patho person stuff person patho like like vent littl bit speak cancer love famili good life biggest one biggest problem good life yeah know brief although think lot issu twitter term like public mental health due proxim current drama honestli feel opinion think elon end get twitter arbit truth public discuss respons qualifi respons want say someth might like dismantl democraci like actual actual think opinion truli want wrong opinion think close actual situat wherein thought brain think scare proxim situat crazi word could say could chang world affair hurt peopl mean natur celebr certain point littl bit littl bit much destroy put much constraint littl bit think impact word mean human talk somebodi bar think impact word like say posit thing say neg thing affect direct one life social media word affect direct mani live crazi crazi world live worthwhil consid respons take serious sometim like choos kind silenc choos sort respect like lot thought matter thought wrong one situat stake high mention back cult center around bureaucraci realli anyth involv lot paperwork realli love cult like kafkaesqu ye like mean like joke know love idea holi rain empir yeah like kafkaesqu pro bureaucraci cult feel like human civil said like oh kind human bureaucraci cult yeah theori realli think realli bureaucraci start kill us think like need reorient law stuff like think need sunset claus everyth like think rate chang cultur happen fast rate chang technolog everyth happen fast like see hear like social media cambridg analytica everyon talk like even point much technolog chang happen like hear like tri make law ai stuff feel like updat thing like everi five year like one big issu societi right get bog law make hard chang thing develop thing austin wan na speak much like one friend work hous bill austin tri like prevent like san francisco situat happen obvious get littl mini san francisco like hous price skyrocket caus massiv gentrif realli bad anyon super rich like much bureaucraci part reason happen need permit build take like year get permit like build anyth hard build limit hous massiv influx peopl like know microcosm like problem happen world like deal law like 10 20 30 40 100 200 year old longer relev slow everyth caus massiv social pain yeah like also make sad see politician talk technolog realli get importantli lack curios like like inspir excit like stuff work stuff like see cynic view technolog like tech compani tri evil world perspect curios like recommend system work ai system work natur languag process robot work comput vision work know alway take cynic possibl interpret technolog would use definit concern constantli worri regul base go slow innov think huge prioriti right undo bad energi surround emerg silicon valley like think like lot thing irrespons time know like even current whole thing twitter everyth like lot neg outcom sort technocraci boom one thing happen like alien peopl want care technolog actual think technolog probabl better probabl best think fix lot problem easili technolog know fight power know go back star war quot buckminst fuller quot let go dark question may time darkest place ever gone mind time period time moment rememb difficult mean 18 best friend die heroin overdos like shortli one best friend commit suicid sort like come adulthood deal two import peopl life die extrem disturb violent way lot lot miss yeah definit miss make think life finit life place mind go ever distanc far away contempl death mayb even take life oh never oh love life fathom suicid scare death scare death manag manag like zen guy manag alway like need accept death need accept death like look medit medit accept death like fight terrifi death like fight although actual think death import recent went meet immort process actual topic meet sorri girl bunch peopl work like anti age stuff like like seminari thing went realli excit like yeah like okay like got like live 500 year thousand year like cours meet like sort like right like two three day russian invas start like man like putin immort like like man mayb immort good mean like get later dune stuff immort caus lot problem caus talk earlier music like brain calcifi like good peopl could becom immort bad peopl could becom immort also think even best peopl power corrupt power alien like common human experi right peopl get power even best peopl like whose brain amaz like think death might import think death part know like think ai one thing might want consid know talk ai expert probabl everyon idea alreadi figur talk nobodi expert anyth see okay go ahead talk yeah like like think kind prune tricki thing much focu youth cultur wisdom feel like tricki tricki moment right societi like realli perfect live long time realli like old peopl like realli vote wellb young peopl know like like student dead need like healthcar like univers healthcar like vote like best interest young peopl wisdom like yeah need commun stuff like like liter got cancel one point iron use stalin quot high school yearbook actual like diss high school saw yeah peopl like use stalinist class traitor like like oh man like pleas googl stalin pleas googl stalin like know ignor lesson histori ye like realli weird middl ground like find happi medium wisdom fresh idea fight like like realli like need like fresh idea wisdom like collabor like fight way search happi medium way mayb find happi medium mayb happi medium look like ai system know reinforc learn danc explor exploit sort crazi stuff see someth better think optim optim thing danc back forth would stuart russel know know ai guy think sort control super intellig ai system idea inject uncertainti sort humil ai system never get wiser wiser wiser intellig never realli sure alway doubt sens think young peopl mechan doubt like societi doubt whether thing converg toward right answer voic young peopl societi ask question way stuff past 50 year mayb wrong way within one ai system also think though need mean actual actual realli interest realli cool also think fine balanc think mayb also overvalu idea old system alway bad think thing perfect might accident overthrow thing actual gotten good point valu disrupt much valu fight gener us much also aspect sometim take two step forward one step back okay mayb kind solv thing like fuck know think like middl ground yeah search happi medium let ask bunch crazi question okay right answer short way long way scariest thing ever done question gon na ridicul someth tini someth big someth big skydiv tour first record go podcast two crazi brush like realli scari brush death randomli got away scay know talk well know think might luckiest person aliv though like might dark podcast though feel like know like good content podcast know good content might hijack safer one mean babi realli scare birth process surgeri like babi realli scari like medic aspect respons readi respons readi mother beauti thing come motherhood talk chang readi feel readi think took nine month start get readi still get readi keep realiz thing start get conscious grow stuff notic first one seen first one older notic like sort like existenti horror come conscious babi babi sailor mar whatev like mani name point realli need probabl settl one could someon els day someon aliv today somebodi met yet would would model brain state would bodi choos degre model brain state caus still take third person perspect realiz realiz aliv dead oh would brought back life right dead yeah bring peopl back definit hitler stalin wan na understand evil would need oh experi feel like wan na brain feel feel might chang forev return ye think would also help understand prevent fix might one thing experi burden know caus abl transfer yeah lot thing burden use burden use burden yeah sure wan na understand evil psychopathi fake twitter account go differ algorithm bubbl tri understand keep get fight peopl realiz actual fight think use exist monocultur social media stuff kinda got fed thing speak cultur languag think recent one thing diagnos properli enough social media differ dialect mani differ dialect chines becom differ dialect english realiz peopl say exact thing use complet differ verbiag punish use correct verbiag complet misunderstand peopl misunderstand peopl say got fight friend anarch commun shit two hour end convers say someth like liter say like like fuck differ like english way understand terminolog like drastic like algorithm bubbl creat mini dialect languag interpret languag use fascin like argument need polar happen need happen got like algorithm creat dialect occur plu top also differ part world speak differ languag liter lost translat kind commun happen know russian languag know differ english languag wonder much lost littl bit man actual caus question song come tomorrow speak russian band speak littl bit russian look titl titl english match titl russian curiou caus look say titl english last day titl russian new day pronunci suck new day like like new day new day yeah new day new day like two differ mean yeah new day yeah yeah yeah new day new day last day new day last day would last day yeah mayb mayb titl includ russian mayb mayb bilingu honest novodin sound better music like novodin new day current one posledniy den last day think novodin like novodin mean differ kind awesom actual though explicit sort contrast like everyon earth disappear left would day look like like would everybodi dead far corps well serious big let think big differ like bird sing versu like corps litter street yeah corps everywher sorri actual know happen know surviv even know other seem clear gone would would listen somebodi realli enjoy moment enjoy life would go like enjoy inanim object would look food basic surviv listen take walk look outsid happi get exist planet abl breath air beauti full color kind stuff mani thing life life consciou life fuck awesom would enjoy also mayb week engin would start come like wan na build thing mayb alway hope search anoth human mayb probabl search anoth human probabl tri get tv radio station broadcast someth interest think like realli maxim abil connect other yeah like probabl tri find anoth person would excit see meet anoth person terrifi know excit matter yeah yeah yeah yeah alon last howev long life would realli bad one instanc might think kill might kill love peopl love connect human yeah kinda hate peopl yeah love hate relationship yeah feel like bunch weird nietzsch question stuff though oh yeah like wonder caus like podcast like interest peopl like know mayb peopl like listen podcast like lore like hard lore like love like dan carlin like give fact like like fact bloodstream also know like fascin mind explor realiz talk stuff stuff taken grant actual uniqu fascin way think alway like way reason thing fascin thing listen peopl kind see oh human think differ explor thought differ cool also cool yeah dan carlin retel histori way retel histori think excit histori way think histori think dan carlin one peopl like dan carlin one peopl realli start get excit like revolution educ like dan carlin instil alreadi like realli like histori instil like obsess love histori point like fuck read like go bed read like part four rise fall third reich whatev like got like dens ass histori like like open door like made want scholar topic like like feel like good teacher like know sort made feel like one thing could educ like find like world great teacher like creat passion topic autodidactric know say properli like self teach like much faster lectur like much effici sort like abl teach ask teacher question know like know like univers stuff like learn much materi much faster lot learn go teacher get stuck like teacher inspir passion topic think one invalu skill whole speci like like ai like ai go teach much effici teach need get point teach find motiv right yeah like inspir yeah could teach make fact mention rise fall third reich read yeah read twice read twice ye okay one even know yeah like wait thought like super poppin book super pop yeah like far interest yeah written person import kind know start like could possibl happen read rise fall third reich like peopl tri realli hard happen peopl tri almost reinstat monarchi one point tri stop happen like almost like abandon democraci tri get happen least way make feel bunch small moment histori turn ye like small meet ye human interact terrifi inspir like even attempt assassin hitler like time time fail close like oper valkyri good also role realli heavi burden geopolit perspect role leader see evil truli becom evil anticip stand evil evil actual pretti rare world scale hitler tend know modern discours kind call peopl evil quickli look ancient histori like ton hitler actual think norm like go back like sort intellig design theori think one thing success slow move surviv fittest intellig design kind erad like look like ancient assyria stuff like shit like brutal like head like brutal like genghi khan like genocid genocid like throw plagu bodi wall decim whole citi like muslim conquest like damascu shit like peopl citi use get level fuck time okay get bronz age collaps basic like almost like roman level like societi like like world like global trade like everyth awesom mix think bit climat chang develop iron basic bronz could come way make bronz like everyth funnel one iranian mine like one suppli chain one thing make worri suppli chain think need thought think biggest issu societi right like thing like go wrong probabl suppli chain collaps war climat chang whatev like anyth caus suppli chain collaps popul big handl like thing seem caus dark age mass suppli chain collaps bronz age collaps happen like sort like ancient collaps happen like liter like ancient egypt citi everyth got like decim destroy abandon citi like hundr like flourish societi like almost come modern everyth got level mini dark age like littl write record time like lot inform bronz age collaps basic equival like mediev mediev dark age happen know year like thousand year earlier sort like recov bronz age collaps empir reemerg write trade everyth reemerg cours contemporari dark age time design mechan lessen lessen capabl destruct power center emerg record contemporari dark age think like better understand avoid still think high risk think one big risk right natur state human lot hitler gotten realli good make hard emerg gotten better collabor resist power like authoritarian come power tri go countri countri like move past kind like slowli increment like move toward like scari old school war stuff think see happen countri least nomin like suppos move past scari remind us happen like place move supposedli hope move past possibl civil level like said suppli chain collaps might make peopl resourc constraint might make peopl desper angri hate violent drag us right back mean suppli chain collaps like ultim thing caus middl age suppli chain collaps like peopl peopl reliant certain level technolog like peopl like look like britain like glass like peopl aqueduct peopl like indoor heat cool like run water like buy food world trade market like peopl know hunt forag gather similar situat educ enough surviv without technolog suppli chain collaps like limit access technolog like massiv starvat violenc displac war like know like yeah opinion like primari marker like dark age well technolog kind enabl us resili term suppli chain term differ catastroph event happen us although pandem kind challeng prepared catastroph think coolest invent human come wheel fire cook meat comput comput freak comput internet comput one think previou technolog mean may even profound move us certain degre think comput make us homo tech think brain augment like allow actual evolut like comput acceler degre technolog also acceler would classifi homo sapien homo techno definit homo techno one earliest speci think us like said like think like look brain scan us versu human hundr year ago would look differ think physiolog differ even interact devic chang brain well look lot studi come show like degre inherit memori physiolog chang theori pass like know like instanc physiolog chang gon na fizzl theori progress like offspr speak offspr advic would give young person like high school whether artist creativ engin kind career path mayb life gener live life proud think one big thought like especi kid think spend enough time teach creativ think creativ muscl like thing lot emphasi know learn play piano write song like learn technic stuff thing think like friend like world greatest guitar player like know amaz sort like produc work peopl realli sort like know like engin record thing like solo realli like make music talk like dude talent music like make music whatev like caus got old never learn creativ muscl like know embarrass like learn creativ muscl take lot failur also sort creativ know throw paint wall lot stuff fail like part like toler failur humili somehow easier develop young persist young everyth easier develop young ye younger better could destroy mean shitti thing creativ know failur could destroy care risk worth take also young age develop toler failur good fail time like stupid shit time like public privat get cancel make kind mistak like resili make mistak like lot thing like peopl like think greatest asset creativ like think pain like toler failur super essenti thing taught thing brilliant advic yeah yeah wish everybodi encourag sort failur oppos kind caus like punish failur like like teach kid like wrong like know like x keep like like wrong know met came furiou spotifi like grill super hard got answer say like sort peak cd industri like 20 000 artist make million million dollar like like tini kind 1 spotifi kind democrat industri think said million artist make good live spotifi heard like honestli would rather make less money like decent live artist abl even though like wish could includ everyon yeah realli hard argu youtub youtub mission want basic mani creator possibl make live kind live hard argu hard think better way manag actual wish like would brought manag build app manag like help organ percentag get publish dah dah dah dah dah take middlemen much bigger like autom get autom manag autom manag publish legal read app build read contract like tell one issu music right get paid enough art industri fill middlemen artist good busi begin like frank sinatra mob stuff like music industri run busi peopl artist artist realli get small cut like make think part reason technocrat mean fan gon na technocrat one gon na mad like fan hate say kind thing gener public like technocrat like technocrat like watch battl angel alita like martian technocraci like yeah martian technocraci like evil like oh okay like caus martian technocraci sound sick yeah intuit technocrat would creat kind beauti world exampl manag work creat app remov need lawyer could smart contract blockchain remov need like manag organ stuff like read stuff explain collect royalti know like small amount amount money get spotifi actual mean lot goe lot farther remov bureaucraci ineffici make life great could yeah think issu enough like issu ineffici realli posit sum mindset know win win mindset like instead know fight scrap make worri scarciti like instead scarciti mindset increas effici know way expand size pie let ask experiment said beauti musician like convers came much creat music like kind convers tri fit cultur trend much like tri much possibl outsid come someth total new like think experi tri total differ total weird tri fit man hard feel like kind process semi retir music like old brain yeah bring like shelf put tabl coupl minut poke think bit think forc engag new music realli great neuroplast like think know peopl part reason music market young peopl young peopl neuroplast like 16 like 23 whatev gon na realli easi love new music older get harder harder harder think one beauti thing musician constantli forc listen new music think keep brain realli plastic think realli good exercis think everyon listen new music hate think keep forc like okay well peopl like like know make brain form new neural pathway open chang realli brilliant actual sorri interrupt like exercis realli amaz sort embrac chang embrac sort practic neuroplast like one thing fall love certain band kind stay rest life never understand modern music realli good exercis stream spotifi like classic rock stuff like new music make small chunk play spotifi think like good sign us speci think yeah good measur speci open minded chang often listen new music brain let put music brain back shelf got ta pull futurist brain second wild way think futur say like 30 year mayb 50 year mayb hundr year differ current way life earth talk augment realiti virtual realiti mayb robot mayb space travel mayb video game mayb genet engin keep go cyborg alien world war mayb destruct nuclear war good bad think futur imagin weirdest wildest could read surfac detail iain bank surfac detail favorit depict oh wow read book liter greatest scienc fiction book possibl ever written iain bank man yeah sure read player game read titl copyright steal like player game sick nice yeah name album like alway want romeo juliet someth alway want name album war peac nice like would like good good heard like could also thing public domain peopl clue song call player game ye oh yeah iain bank surfac detail opinion best futur ever read heard scienc fiction basic relationship super intellig like artifici super intellig like great want credit person coin term love term feel like young women get enough credit yeah go protopia futur instagram name person donor experi scale ai power donor experi monica bealskit say wrong probabl gon na probabl butcher bit protopia sort utopia unattain protopia sort like know wow awesom instagram protopia futur great futur know good get futur posit futur ai central ai surfac detail distribut kind ai mostli exist giant super ship like sort like guild ship dune like giant ship kind move peopl around ship sentient talk passeng mean lot differ type ai banksyan futur open scene surfac detail place call cultur cultur basic protopian futur protopian futur think like futur like obvious utopia perfect like caus like strive utopia think feel hopeless sort like mayb best terminolog use like pretti good place like mostli like know super intellig biolog be exist fairli harmoni much war like close equal get know like approxim good futur like realli awesom stuff open scene girl born sex slave outsid cultur societi adher cultur valu tri kill guy like master kill unbeknownst travel ship cultur like say like crazi thing like x keep like like bubbl car bubbl car like know like bubbl car like like like want like wrong like think weird crazi shit like know bubbl car like creat world might intern consist might discov someth fundament world yeah like rewrit song like word prefer like instead babi shark say babi car like mayb onto someth let ask big ridicul question kind danc around think mean whole thing human civil life earth gener life mean life c read nova scene yet jame lovelock lot realli good book recommend even finish huge fraud yet like realli earli book say amaz thing like feel like everyon sad cynic like everyon like fermi paradox everyon keep hear peopl like fuck alon like oh ah like ah ah like okay like wait begin like nova scene say gon na correct like memor quot say someth like conscious like right like univers wake like instead discov univers univers like evolut liter univers like separ univers like univers wake univers see first time like univers becom consciou first time part yeah caus like separ univers like could like incred sacr moment mayb like social media thing stuff get connect togeth like mayb neuron connect like collect super intellig wake yeah like know like mayb instead someth cynic mayb someth discov like mayb know blast assist like incred kind conscious like first three year life human children forget suffer go think probabl forget mean probabl know artifici intellig eventu render us obsolet think malici way think probabl weak sun expand like know like hope get mar like pretti vulner know like think coexist long time ai also probabl make less vulner know think conscious sentienc self awar like think might singl greatest like moment evolut ever like mayb know big like true begin life blue green alga like singl cell organ someth amaz univers awaken yeah well see incred person fascin mind definit friend liv mention guy think mayb talk would love explor mind kind media podcast kind way awesom person honor know honor get sit late night like surreal realli enjoy thank talk today yeah mean huge honor feel underqualifi big fan listen podcast lot yeah liv would appreci advic help definit gon na yeah anytim thank cool thank thank listen convers grime support podcast pleas check sponsor descript let leav word oscar wild ye dreamer dreamer one find way moonlight punish see dawn rest world thank listen hope see next time one day ship put neural lace head neural lace sort like basic neuralink life imit art inde inde wake open scene memori upload neural lace kill get choos new bodi ai interfac record memori neural lace help like hello dead neural lace memori upload want choos new bodi go born cultur like start new life like open like sick ship super intellig ship kind super intellig still want preserv kind rich fulfil experi human yeah like like friend human bunch ship want exist biolog be place like way thing necessarili pretti protopian exist pretti peac yeah mean exampl one main fight book fight artifici hell peopl think ethic artifici hell like basic peopl crime get sent like die memori get sent artifici hell etern tortur way societi decid whether artifici hell simul like simul war instead actual blood know peopl basic essenti fight video game choos outcom still experienc suffer artifici hell experi stuff artifici hell suck lot peopl cultur want get rid artifici hell simul war happen artifici hell simul war happen outsid artifici hell polit faction polit faction say simul hell deter crime polit faction say simul hell uneth instead like know blow nuke like giant fortnit battl decid know protopia like okay war without death know think simul hell think definit one way technolog could go wrong almost punish peopl digit space someth like yeah like tortur peopl memori either deterr like commit crime also person pleasur sick dement human world dan carlin actual episod hardcor histori pain attain oh episod fuck dark kind goe human histori say like human seem enjoy secretli enjoy use openli enjoy sort tortur death watch death tortur human think peopl consent allow gladiatori match consent hard achiev situat alway start get slipperi like could also forc consent like start get weird way much excit like highlight someth human natur want see violenc realli dark hope sort overcom aspect human natur still within us somewher well think right theori import current moment evolut surviv fittest point line kind fuzzi recent past mayb even right get point choos intellig design like probabl sinc like integr iphon like becom cyborg like brain fundament chang everyon grew electron fundament differ previou homo sapien call us homo techno think evolv homo techno like essenti new speci like look way took mri brain took mri like mediev brain think would differ way evolv think historian look back time see like fundament shift human think think still homo sapien believ homo techno think evolv think right way evolv choos think reckless like social media think idea like time choos intellig design taken serious like moment reprogram human comput like go blind visual cortex get taken function choos evolut chang way brain work actual huge respons think sure respons definit adequ educ inund technolog fundament chang physic structur brain adequ respond choos wan na evolv could evolv could realli whatev want think realli import time think choos correctli choos wise conscious could exist long time integr ai could extrem posit think enough peopl focus specif situat think might irrevers screw thing get thing wrong flip side seem human pretti adapt mayb way figur thing screw like social media gener see neg effect social media build new social media keep improv stuff learn failur past human seem realli adapt flip side get wrong way liter creat weapon war increas hate past certain threshold realli lot damag mean think optim notic neg thing would actual say one thing think peopl notic look silicon valley look technocraci like happen silicon valley start facebook profit crap realli particular guess use sort whatev see lab grown meat compost biodegrad singl use cutleri medit app think actual evolv chang technolog chang think mayb quit enough educ also know quit enough incent think way capit work defin profit also work old model defin profit realli think chang idea profit includ social good econom profit social good also count profit would incentiv thing use whatev spiritu technolog posit technolog thing help reprogram human comput good way thing help us intellig design new brain yeah reason within framework capit word profit idea profit also incorpor well human like long term well long term happi even exampl talk motherhood like part reason late get babi bed like keep think motherhood capit like extrem essenti job difficult compens sort like valu thing much compens realli devalu motherhood societi pretti much societi like capit recogn motherhood job suppos free like feel like produc great human seen great profit capit like like huge social good like everi awesom human get made add much world like integr profit structur know potenti found way compens motherhood come compens much broader money could money like made know know pay like mean start get realloc resourc peopl get upset well like made like motherhood dow yeah yeah know use fund like singl mother like know pay make babi mean creat put beauti thing onto world could compani bridg could art could lot thing could children educ anyth valu societi somehow incorpor framework market like contribut children world valu respect sort celebr like proport thing fuel human civil yeah like kind import feel like everyon alway say mean think differ social sphere everyon alway say like dismantl capit like well okay well think govern everyth like think privat ownership like scari know like start get weird stuff sort like feel almost way without polic state know obvious capit major flaw think actual mac show idea call social capit form capit like consid social good also profit like know like right compani need like suppos grow everi quarter whatev like show function well like okay well kept amount profit still green also social good like realli need extra econom growth could add social good count know know economist idea could achiev think economist know anyth could achiev either pretend thing construct model go tv show sound like expert definit economist mother becom mother chang human would say man think kind chang everyth still chang lot actual chang right moment like today like like recent month stuff elucid chang like wake morn look becom differ would say think realli reorient prioriti first realli fight somehow felt like failur femin someth like felt like like bad like kid start matter work like recent start sort analyz thought like also kind construct like devalu motherhood much cultur like feel guilti care kid care work femin includ break whatev construct continu break like freedom empow free mean also like mother like much creativ like believ massiv amount brain growth think caus like stake higher somehow think like trippi watch conscious emerg like like go crazi journey someth like craziest scienc fiction novel could ever read crazi watch conscious come time like forc valu time much like creativ time sacr need like realli frick thing use like cynic use wan na like last album call miss anthropocen like like like studi villaini like like well instead old god like new god like miss anthropocen like misanthrop like anthropocen like know like goddess climat chang whatev like destroy world like like dark like studi villaini sort like like use like problem make cynic angri scari art anyth wrong think kid make optimist inher make wan na optimist bad like feel respons make optimist thing get lot shit everyon like oh privileg stop talk like pie sky stupid concept focu like like think ideat futur could good abl get everyth blade runner gon na end blade runner like said earlier life imit art like life realli imit art realli need protopian utopian art think incred essenti futur human think current discours seen think protopia utopia seen dismiss problem current think incorrect mindset like kid make wan na imagin amaz futur like mayb abl build abl build want yeah seem like ideat precursor creation imagin order abl build sad thing human natur somehow cynic view world seen insight view know cynic often confus insight sad see optim confus naivet ye ye like blind mayb privileg whatev blind someth certainli blind sad sad see seem like optimist one creat futur one build order build crazi thing optimist either stupid excit passion mad enough actual believ built peopl built favorit quot time star war episod 8 know everyon hate like star war episod 8 yeah probabl would say would probabl hate yeah strong feel let backtrack strong feel star war tolkien person dragon orc ogr yeah mean tolkien forev realli want one son call thought tao tecno tolkien would cool lot like yeah well tao six two eight two pi yeah tao tecno yeah yeah yeah techno obvious best genr music also like technocraci sound realli good yeah right techno tolkien tao tecno tolkien good tao tecno tolkien star war episod 8 know lot peopl issu person record think best star war film start troubl today yeah kill hate save love kill hate kill hate save love think societi right diagnosi mode diagnos diagnos diagnos tri kill hate tri save love enough buckminst fuller quot gon na butcher rememb correctli someth along line tri destroy old bad model render obsolet better model mayb need destroy oil industri mayb creat great new batteri technolog sustain transport make econom unreason still continu reli fossil fuel like kill hate save love make new thing render old thing unus like colleg debt bad univers expens feel like educ becom obsolet feel like could complet revolution educ could make free like look jstor pay get studi everyth creat dao bought jstor creat dao fund studi studi open sourc free everyon open sourc educ decentr educ made free research internet outcom studi internet one student debt take test appli job qualifi work like know anyth work randomli rant like humil got ta think basic first principl problem broken idea get excit idea share excit tear kill thing often end kill like war one side like gon na go kill like gon na get stab like think talk nexu point point societi switch intellig design think part switch intellig design need choos nonviol need like think choos start think erad violenc speci think need littl bit think choos realli reorient primit brain fight scarciti attack orient move optim creativ build yeah interest think happen educ live life introspect mind tri live better angel natur one us kind thing scale sort start minim amount destruct war world probabl technolog realli promis way like social media realli promis way way connect know part realli enjoy social media know neg stuff engag neg stuff even like block kind stuff let enter mind like like somebodi say someth neg see immedi think posit thought forget exist move like neg energi return neg energi go get excit neg way right back kind viciou cycl would think technolog would assist us process let go take thing person engag neg unfortun social media profit neg current model mean social media like gun like take cours use like like mean like say reprogram human comput like school learn social media optim know rais cortisol level make angri crazi stress like learn hygien use social media yeah choos focu neg stuff know sure social media guess exist sure mean messi experiment phase like work yeah earli day even know say social media know even mean earli day think social media basic human connect digit realm think exist mani way bad way mani way good way discuss human right talk freedom speech talk sort violenc space digit media talk hate speech talk thing figur back day physic space figur digit space like babi stage print press came like pure chao minut know like inject massiv inform inject gener popul gon na feel like print press year like print press came shit got realli fuck bad minut got enlighten like think like second come print press probabl gon na shitti time minut gon na recalibr better understand consum media deliv media speak program human comput mention babi x young conscious come came cell like whole thing even make sens came dna yeah babi comput like grow grow grow grow consciou extrem impress cognit capabl met ye yeah yeah actual realli smart realli smart yeah weird yeah babi know lot babi seem smart zach hang babi often babi impress lot prank stuff oh like like like give treat take away laugh like stuff like like chess player cognit sort comput program take environ interact specif set human would first let ask want ask program comput also make sens consciou right give lot crisi thought think realli hard think part reason like struggl focu art stuff right caus babi x becom consciou like reorient brain like brain suddenli total shift like oh shit like way rais children like hate babi book everyth hate like oh art bad like stuff everyth aesthet like like ah like program languag use program babi comput good yeah like think like good answer know think realli realli hard recent watch totoro studio ghibli like fantast film like respond know suppos show babi screen much like think sort like feel like highest art babi content like realli speak almost talk realli simpl although dialogu super super super simpl know like one three year old like realli connect like feel like almost aim like one three year old like great art imagin beauti like first time show like invest unlik ever unlik anyth els ever shown like like cri cri laugh laugh like like roller coaster like emot like learn bunch word like start say totoro start say stuff watch totoro want watch time like man industri like best artist focus make art like birth conscious like one thing think realli wan na start know wan na speak thing much like like age one three like put much effort thing totoro like like better environ adult love totoro good art everyon love like still old totoro merch kid like liter rag old totoro merch like everybodi love everybodi keep like art babi need suck access adult thrown know age like like know like fulli form thought someth think lot like like totoroesqu content like content like like univers everybodi love like realli gear emerg conscious emerg conscious first like three year life much turmoil much evolut mind happen seem like crucial time would say make suck think basic treat child like capac brillianc adult even beyond think mind caus still like talk weird stuff like respond better caus even imit better voic higher like peopl say like oh babi talk like voic higher closer someth imit like like babi talk actual kind work like help learn commun found effect learn word stuff like speak like capac\",\n          \"follow convers sean carrol theoret physicist caltech special quantum mechan graviti cosmolog author sever popular book one arrow time call etern one higg boson call particl end univers one scienc philosophi call big pictur origin life mean univers upcom book quantum mechan preorder call someth deepli hidden write one favorit blog websit preposterousunivers com recommend click greatest hit link list access interest post arrow time dark matter dark energi big bang gener rel string theori quantum mechan big meta question philosophi scienc god ethic polit academia much much final perhap famous host podcast call mindscap subscrib support patreon along joe rogan experi sam harri make sens dan carlin hardcor histori sean mindscap podcast one favorit way learn new idea explor differ perspect idea thought understood truli honor meet spend coupl hour sean bit heartbreak say first time ever audio record podcast die middl convers technic reason phantom power understand avoid took one hour notic fix problem much like univers 68 dark energi roughli amount convers lost except memori two peopl involv note sure talk continu convers podcast sean cours look forward artifici intellig podcast enjoy subscrib youtub itun support patreon simpli connect twitter lex friedman convers sean carrol think interest impact understand univers work fundament level understand human mind work know cours crazi meaningless unanswer question sens interest absolut scale interesting rate glib answer say human brain part univers right therefor understand univers fundament understand human brain realli believ understand fundament way univers work particl level forc would abl understand mind work certainli understand ice cream work understand particl work right big believ emerg big believ differ way talk world beyond fundament microscop one know talk tabl chair planet peopl talk languag particl physic cosmolog understand univers say fundament level right understand univers level part think know littl bit fair question probabl gener principl complex biolog inform process memori knowledg creativ go beyond human brain right mayb one could count understand part understand univers human brain far know complex thing univers certainli absurd think understand fundament law particl physic get direct insight brain work step fundament particl physic inform process lot physicist philosoph may littl bit carelessli take talk artifici intellig think univers kind comput devic like honest answer sens univers process inform clearli sens univers like comput clearli sens think tri say blog one agre univers like comput comput univers happen comput gener purpos machin right ask differ question even pocket calcul right set answer certain kind question univers inform process happen univers univers know mit colleagu seth lloyd feel differ right well think univers close system make comput like pc like comput machin human everi come move mous around input give input give input say comput determinist thing unrol immens complex nevertheless like process state chang good rule sens lot peopl brain oper human brain oper within world simpli small subset reason build arbitrarili great intellig yeah think intellig way intellig tricki definit offhand rememb panel discuss saw youtub seth lloyd panel martin ree famou astrophysicist seth gave shtick univers comput explain martin ree said comput seth like oh good question sure suffici broad definit comput everyth right simil analog gain forc exclud thing know moon go around earth perform comput come definit answer ye use comput think absolut help think univers certain situat certain context inform process devic even guilti write paper call quantum circuit cosmolog model whole univers quantum circuit circuit circuit yeah qubit kind thing qubit basic right yeah qubit becom entangl wan na digress littl bit let kind fun mysteri univers deep profound nobodi talk space expand right talk certain region space certain number degre freedom certain number way quantum field particl region arrang number degre freedom region space arguabl finit actual know mani good argument say finit number univers expand space get bigger degre freedom infinit number realli matter infin time two still infin finit number space degre freedom come would mean univers close system degre freedom pop exist suggest degre freedom start entangl start univers know three dimens around us see said entangl degre freedom make space time univers expand whole bunch qubit zero state becom entangl rest space time action quantum circuit mean degre freedom becom entangl yeah univers expand right degre freedom entangl play part play role part entangl space time structur basic underli philosophi space time aris entangl fundament quantum degre freedom wow okay point entangl happen talk close big bang talk throughout time life throughout histori yeah idea big bang almost degre freedom univers could unentangl anyth els reflect fact big bang low entropi simpl small place space expand degre freedom becom entangl rest world well ask john carrol think thought experi nick bostrom live simul think let contextu littl bit think peopl actual take thought experi think quit interest use quit interest perspect ai lot learn done usual happen simul artifici exampl construct question ask difficult real world simul right kind dual part live simul somebodi built simul tri hard would obvious could live simul want physic possibl complet agre physic possibl think actual take one piec data consider know live big univers okay two trillion galaxi observ univers 200 billion star galaxi et cetera would seem wast resourc univers big go simul word want good bayesian want ask hypothesi expect see first thing would say expect see univers big okay second thing expect resolut univers good alway possibl superhuman simul finit resourc render entir univers right part two trillion galaxi actual simul fulli okay obviou extrapol simul fulli like rest non player charact right thing real rest chat bot beyond wall see wall liter noth side wall sort bayesian predict would like effici simul like none seem quit realist see hear argument possibl easi simul lot thing see evid know univers look like simul univers mayb say well know would look like abandon bayesian respons like job say theori would expect see yeah certainli think simul thing like video game small subset render say entir law physic entir close system quot unquot univers creator yeah alway possibl right use think think physic way nick bostrom phrase possibl simul univers eventu right use way lot thing well yeah guess question hard creat univers wrote littl blog post mayb miss someth argument say might possibl simul univers probabl imagin actual attribut conscious agenc littl thing simul littl artifici be probabl lot ordinari organ be univers futur right argument simul possibl probabl space live conscious simul right top level think argument must wrong follow argument simul also simul thing well simul thing simul thing right give enough power resolut ultim reach bottom law physic univers bottom made atom forth cheapest possibl simul believ origin argument conclud cheapest possibl simul peopl look like look like edg resolut 16 bit thing seem much easier make much lower level thing also question whole approach anthrop principl say typic observ univers think actual think lot select typic within thing alreadi know typic within univers think intellig life howev would like defin intellig life univers guess intellig life observ univers us simpli basi fact like number intellig speci observ univers two like number zero billion billion would notic alreadi liter like small number like know star trek dozen intellig civil galaxi billion weird sort bizarr easi imagin zero other big bottleneck make multicellular life technolog life whatev hard imagin whole bunch somehow remain hidden us question like ask would intellig life look like mean question go intellig life big way differ one earth kind intellig life oper differ scale size tempor right great possibl think humbl intellig life even agre life much less intellig life right argument humil say could intellig life differ charact right like could imagin dolphin intellig never invent space travel live ocean thumb right never invent technolog never invent smelt mayb univers full intellig speci make technolog right compat data think think mayb point even version intellig intellig intermolecular cloud surfac neutron star galaxi giant thing equival heartbeat 100 million year one hand ye open mind thing hand us share law physic might someth law physic even though current know exactli thing would make meter year right length timescal intellig life mayb made atom atom certain size orbit star star certain lifetim imposs sweet spot intellig life find open mind either way open mind either humbl sort differ kind life reason know yet life like kind life yeah two mind often wonder brain design quit obvious oper see world timescal almost blind tool creat detect thing blind kind observ need see intellig life scale well total open anoth argument would make look intellig life look dumbest way turn radio telescop sky world would super advanc civil randomli beam radio signal wast direct univers make sens especi order think would actual contact anoth civil would forev keep million year sound like wast resourc thought solar system planet around mayb intellig life yet exist might someday tri talk radio wave would send spacecraft would park around would like point view like 2001 monolith monolith could artifact fact way work also right could artifact solar system put technolog advanc civil eventu contact explor solar system well enough yet find reason think young impati right like would take lifetim actual send someth anoth star system wait come back start think hundr thousand year million year time scale clearli right thing excit thing elon musk spacex gener space idea space explor even though speci young impati yeah think space travel crucial import long term even star system think mani peopl overestim difficulti say look travel 1 speed light anoth star system dead get right think much easier therefor write scienc fiction stori imagin go faster speed light otherwis impati right gon na go faster speed light could easili imagin human lifespan get extend thousand year star much closer effect right hundr year trip right think gon na futur far futur lifetim babi step unless lifetim get extend well race time right friend mine actual think thing said know gon na die know grandchildren know predict futur hard least plausibl scenario yeah think discuss earlier threat earth known unknown right spread human biolog elsewher realli import longterm goal kind question scienc current answer might soon think problem mysteri us may within reach scienc think obviou one origin life know happen difficulti know happen histor actual know liter earth start life non life someth kind think close right realli realli think like difficult start life well talk peopl includ podcast know life requir three thing life know differ life know life know talk intellig life know requir compartment need like littl membran around cell metabol need take food eat let make thing replic okay need inform pass futur gener lab compartment seem pretti easi hard make lipid bilay come littl cellular wall pretti easili metabol replic hard replic close peopl made rna like molecul lab think state art abl make one molecul reproduc abl make two molecul reproduc okay pretti close metabol harder believ even though sort obviou thing want sort control metabol actual cellular machineri bodi quit complic hard see pop exist probabl took make progress fact think spend nearli enough money nsf would flood area money would chang view world could actual make life lab understand made origin earth sure rippl effect help cure diseas mean understand synthet biolog wonder big frontier make cell right best way borrow heavili exist biolog right well craig venter sever year ago creat artifici cell tremend accomplish take dna cell put entir new dna let boot go leap creat intellig life earth yeah defin intellig cours let even say homo sapien modern intellig human brain sens involv leap big leap ai would count realli want life want realli organ sens ai would count think okay yeah cours cours ai would count well let say artifici conscious right think threshold creat artifici conscious think possibl educ close impress realli close understand littl understand conscious idea hard imagin threshold make doabl possibl see obstacl principl yeah would hold interest happen eventu think gener conscious think would surpris easi conscious creat intellig think conscious thing someth fake well good actual like idea fact conscious way less mysteri think everi time everi moment less consciou think right fool thing think plu idea artifici intellig system put bodi right give robot bodi help fake lot yeah think creat conscious artifici conscious simpl ask roomba say consciou refus talk could could mean almost silli kind conscious also social construct lot idea intellig social construct reach bar involv someth beyond necessarili involv fundament understand go electron neuron cognit actual think extrem good point fact suggest yeah refer kate darl podcast experi simpl robot look like anim look like experienc pain human be react neg littl robot look like experienc pain wan na say yeah robot realli pain right electron go around realiz electron go around pain also would easi time imagin spectrum simpl littl robot kate work human thing sort strict definit ture test level thing consciou nevertheless walk talk like consciou could futur mean siri close right might futur lot agent like fact rather someday go aha conscious creep accur reflect expect futur mayb present exampl met basic assum human high probabl time yeah futur might question mark around right yeah absolut certainli video almost point trust alreadi photo trust right video easier trust get wors get better fake right yeah physic embodi peopl hard fake depress convers right mean excit excit sober thought bad right imagin next 50 year gon na like middl phase transit right yeah gener blind threat excit power technolog solv protect us threat evolv much steven pinker optimist world everyth seen brilliant peopl world met good peopl armi good term develop technolog larg okay way optimist think good bad equal distribut among intellig unintellig peopl see much correl interest neither us proof yeah exactli opinion free right definit good evil come without definit without data opinion kind question scienc current answer may never abl answer view well obviou one good bad right wrong think question scienc tell us happen world say world part world part world abil feel like someth right someth wrong make long stori short think idea moral philosophi systemat intuit right wrong scienc might abl predict ahead time ever abl judg whether done kind uniqu term scientist listen podcast even reach think refer sort interdisciplinari scienc reach talk peopl outsid disciplin alway hope scienc fact littl disillus realiz academia silo yeah question level prepar convers think convers open mind enough convers may littl bit broader advis scientist kind convers podcast fact podcast awesom peopl get hear also good without mic gener good question tough one answer think guy know person trainer ask podcast psych workout make disciplin go work like ask stop work need psych likewis ask get interdisciplinari convers sort differ thing sort differ peopl like make go right like stop long record fact lot motiv start record make sure would read book purchas right like book want read enough time read motiv caus gon na interview pat churchland gon na final read book know absolut true academia extraordinarili silo right talk peopl rare fact punish know like peopl success gener first becam success within littl silo disciplin start expand young person know graduat student tri candid know graduat student becom faculti member right tough road live life wan na live eye open job chanc broad less time spend hyper special field lower job chanc academ realiti terribl like realiti peopl fine like plenti peopl wonder scientist zero interest branch talk thing anyon outsid field disillus know romant notion intellectu academ life beli realiti idea reach beyond disciplin posit good rare univers may well exist said even though say like person trainer help also inspir other like could speak know also career think right without podcast may right make realiz kind convers kind scienc mani way reason write paper exchang idea much harder interdisciplinari paper would say convers easier convers begin field ai obviou think outsid pure comput vision competit particular data set think broader impact know reach physic psycholog neurosci convers inspir never know world chang mean fact stuff huge number peopl come grad student realli love podcast inspir probabl rippl effect becom faculti end balanc pessim optim sean thank much talk awesom lex thank much convers great\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "podcast_pre_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc7v2J77yArk",
        "outputId": "1dba5f4d-0d41-4c39-86f2-7790a8257dc5"
      },
      "id": "nc7v2J77yArk",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(319, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar los resultados en un archivo CSV\n",
        "podcast_pre_df.to_csv('/content/drive/My Drive/Colab Notebooks/week11/data/podcast_pre_df.csv', index=False)"
      ],
      "metadata": {
        "id": "f_dD1StJslD5"
      },
      "id": "f_dD1StJslD5",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Step 4: Vector Space Representation - TF-IDF\n",
        "\n",
        "Create TF-IDF vector representations of the transcripts."
      ],
      "metadata": {
        "id": "fDrasbA7s9ti"
      },
      "id": "fDrasbA7s9ti"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tfidf_representation(corpus_df):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    X_tfidf = tfidf_vectorizer.fit_transform(corpus_df['text_pre'])\n",
        "    tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "    return tfidf_df,tfidf_vectorizer"
      ],
      "metadata": {
        "id": "rt_jTCjms-oj"
      },
      "id": "rt_jTCjms-oj",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(podcast_pre_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlTVCWlFzccc",
        "outputId": "3512b9d3-f8a5-49bc-e62a-e707625d2346"
      },
      "id": "RlTVCWlFzccc",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['guest', 'title', 'text', 'text_pre'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la representacin TF-IDF\n",
        "podcast_tfidf_df, vectorizer = create_tfidf_representation(podcast_pre_df)"
      ],
      "metadata": {
        "id": "tajJQAOXtOnN"
      },
      "id": "tajJQAOXtOnN",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRepresentacin TF-IDF:\")\n",
        "podcast_tfidf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "msTU9EVMtQ2h",
        "outputId": "e1af04c0-daa1-4cc4-b988-b0b26403477a"
      },
      "id": "msTU9EVMtQ2h",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Representacin TF-IDF:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      00       000  0000  0000001  000073  0001  000hour  000th  000x  001  \\\n",
              "0    0.0  0.009230   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "1    0.0  0.007667   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "2    0.0  0.024692   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "3    0.0  0.000000   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "4    0.0  0.007691   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "..   ...       ...   ...      ...     ...   ...      ...    ...   ...  ...   \n",
              "314  0.0  0.015218   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "315  0.0  0.000000   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "316  0.0  0.000000   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "317  0.0  0.036824   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "318  0.0  0.004496   0.0      0.0     0.0   0.0      0.0    0.0   0.0  0.0   \n",
              "\n",
              "     ...                      \n",
              "0    ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "1    ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "2    ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "3    ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "4    ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "..   ...    ...   ...     ...          ...  ...    ...    ...  ...   ...  ...  \n",
              "314  ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "315  ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "316  ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "317  ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "318  ...    0.0   0.0     0.0          0.0  0.0    0.0    0.0  0.0   0.0  0.0  \n",
              "\n",
              "[319 rows x 29840 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad78264b-fa03-4168-bcb0-76285389f91d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>0000001</th>\n",
              "      <th>000073</th>\n",
              "      <th>0001</th>\n",
              "      <th>000hour</th>\n",
              "      <th>000th</th>\n",
              "      <th>000x</th>\n",
              "      <th>001</th>\n",
              "      <th>...</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007691</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015218</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319 rows  29840 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad78264b-fa03-4168-bcb0-76285389f91d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad78264b-fa03-4168-bcb0-76285389f91d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad78264b-fa03-4168-bcb0-76285389f91d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad34773c-fafe-4da6-bc85-4d10b11ff25e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad34773c-fafe-4da6-bc85-4d10b11ff25e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad34773c-fafe-4da6-bc85-4d10b11ff25e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e0f04c51-1128-4c92-86c0-5c708d2ac51b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('podcast_tfidf_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e0f04c51-1128-4c92-86c0-5c708d2ac51b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('podcast_tfidf_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "podcast_tfidf_df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Vector Space Representation - BERT\n",
        "\n",
        "Create BERT vector representations of the transcripts using a pre-trained BERT model."
      ],
      "metadata": {
        "id": "qOWdM40dqcVv"
      },
      "id": "qOWdM40dqcVv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "3aff22622b2e4eb28334a6ada86f80e1",
            "21f3232812ca4a20afb5f366ad32151e",
            "8d2e8ad2628b443eb3781ad9e23647f2",
            "80cc2f5a9b024729b3941b35ed164daa",
            "bdaf58a9ebb14a12ba1d3a5276b2f56c",
            "7b803d0122b84ce1abe75ee52cbfe6d6",
            "a042b5ce9c324fef9e506bdbb6834533",
            "38ddfa49f3254ed297a65a0ea44f125f",
            "542ba0560578403894979a90ee1b9d7a",
            "cb376b7356234e52838f5b4042172b80",
            "b2020d74784f4560b4e6b61b2768bf73",
            "0d5b1ba443624179814886b9c0047420",
            "88bd1df52b154aa0bf5ef87a95b5a491",
            "bb60eecee5b14a58a14f05cdbc89b12d",
            "3c1e127f8916432cb41ebf13f69c6a02",
            "ad5e517b816b435390053f5650f58956",
            "c0b8243c61ae4c50880e9f7016d26fd5",
            "0517c5ae52d94ee5bdee364aec1ba974",
            "4f05b8180b404644b8793f42b9cd4041",
            "d910d9e5c75b45e48df26f68dfee7044",
            "b1ee5f22357442cdb0921196e28fe907",
            "14cb3cc0f5b84788946b63d7523bec58",
            "cb957c7fab3246549e67c8bf65c8eec1",
            "5ee7dc014d264ffdb2df2d5a5a7e37b8",
            "b297b98d455f4c1da7a08057335c60cb",
            "67624bea01ed4e95be70da1cffcf4a13",
            "6365a2e4d32348f7ad36c7d41eea3653",
            "044e46551b034549a748b3cd6964b7d2",
            "386ad8c951b14bcd895697439f316421",
            "946b55770e004d4ab5ced4885137feb6",
            "a5ec54e37b21427a897dd29bc1357647",
            "b14b6701d6f04536a0d5f28cbf2bb0f3",
            "c18ea041e51a4b9397d262dc3292792b",
            "925c00bd16994ff4959218659b8b530f",
            "9b556e7d794a4c28b5d6c34b952132e3",
            "167cde39650e4814a2622202397d51e6",
            "c96ccd4a2e7d47e999087a3500d70dfd",
            "be168ad2fb4e4d6da7b3c681eb4dd886",
            "5a312f444fa648cebec9eba198f6e402",
            "50470bf9658f454c9b1cfa3508c67b9e",
            "ff0e6a44882d4659907176d5dc63b5bb",
            "fc03d2e99635490cb77bf5d44d6fdb39",
            "0a5f448582354bc48dedfbb9bd73358f",
            "b0eaf67700814947b382c6f5d207872c",
            "4d412bf015b94761812d123c56829b37",
            "650342e827c3487b90b80baa9caa540f",
            "5d73eaecb4264b19b090962bc0a9ab7b",
            "e4605aa917584da6be8d11730ad29e03",
            "e290318a22f2443d8b7d9efe166b345a",
            "581501b3a81644e987631ce05ad836e9",
            "f1925786d1cd47feb75e4fd7d9545632",
            "af090144a6594445aac6b9d5c60de0a4",
            "a5a47f9c066a44a88b0e309639844a3f",
            "f596ac033ed3464e99c590ca0efb9e02",
            "4cf114bde49844e48efcd0a5f8e4467a"
          ]
        },
        "id": "TVvSxpehuFss",
        "outputId": "2b0e9715-106b-4bca-f975-e218f78eac1f"
      },
      "id": "TVvSxpehuFss",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aff22622b2e4eb28334a6ada86f80e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d5b1ba443624179814886b9c0047420"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb957c7fab3246549e67c8bf65c8eec1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "925c00bd16994ff4959218659b8b530f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d412bf015b94761812d123c56829b37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bert_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token representation\n",
        "    return np.array(embeddings).transpose(0,2,1)\n",
        "\n",
        "bert_embeddings = generate_bert_embeddings(podcast_pre_df)\n",
        "print(\"BERT Embeddings:\", bert_embeddings)\n",
        "print(\"BERT Shape:\", bert_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzEaiBQIuNjz",
        "outputId": "662a0442-5c0c-46d2-de9d-bcf693d42141"
      },
      "id": "FzEaiBQIuNjz",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Embeddings: [[[-0.18896306]\n",
            "  [ 0.2624014 ]\n",
            "  [-0.15489869]\n",
            "  ...\n",
            "  [-0.12260249]\n",
            "  [ 0.24914369]\n",
            "  [ 0.24250938]]\n",
            "\n",
            " [[-0.41557804]\n",
            "  [ 0.15562901]\n",
            "  [ 0.09742901]\n",
            "  ...\n",
            "  [-0.30488974]\n",
            "  [-0.05800811]\n",
            "  [ 0.26350507]]\n",
            "\n",
            " [[-0.40360537]\n",
            "  [ 0.16065195]\n",
            "  [-0.16231938]\n",
            "  ...\n",
            "  [-0.21682927]\n",
            "  [ 0.20362087]\n",
            "  [ 0.5632472 ]]\n",
            "\n",
            " [[-0.18125309]\n",
            "  [ 0.03536531]\n",
            "  [-0.19476674]\n",
            "  ...\n",
            "  [-0.24290958]\n",
            "  [ 0.14357528]\n",
            "  [ 0.57741135]]]\n",
            "BERT Shape: (4, 768, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Query Processing\n",
        "\n",
        "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
      ],
      "metadata": {
        "id": "fR-x_Dxa0rQT"
      },
      "id": "fR-x_Dxa0rQT"
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_tfidf(query, vectorizer, tfidf_df, podcast_pre_df):\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vector, tfidf_df)\n",
        "    similarities_df = pd.DataFrame(similarities.T, columns=['sim'])\n",
        "    # Reset index of podcast_pre_df to ensure unique index for alignment\n",
        "    similarities_df['ep'] = podcast_pre_df.reset_index(drop=True)['title']  # Reset index of podcast_pre_df\n",
        "    return similarities_df.sort_values(by='sim', ascending=False)\n",
        "\n",
        "# Prueba con una consulta de ejemplo\n",
        "query = 'gpt'\n",
        "tfidf_results = retrieve_tfidf(query, vectorizer, podcast_tfidf_df, podcast_pre_df)\n",
        "tfidf_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DD5ExwM396ci",
        "outputId": "8c000131-710f-4bb2-e70d-3ecc3593a830"
      },
      "id": "DD5ExwM396ci",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          sim                                                 ep\n",
              "213  0.097006  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
              "17   0.031047                                     OpenAI and AGI\n",
              "120  0.027697                    Friendship with an AI Companion\n",
              "94   0.027369                                      Deep Learning\n",
              "117  0.024672  Math, Manim, Neural Networks & Teaching with 3...\n",
              "..        ...                                                ...\n",
              "103  0.000000             Computer Architecture and Data Storage\n",
              "102  0.000000                    Artificial General Intelligence\n",
              "101  0.000000                                     The War of Art\n",
              "100  0.000000  Artificial Consciousness and the Nature of Rea...\n",
              "109  0.000000                                    Computer Vision\n",
              "\n",
              "[319 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceb9e28a-62b7-4788-88f6-87999eaaa40e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0.097006</td>\n",
              "      <td>OpenAI Codex, GPT-3, Robotics, and the Future ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.031047</td>\n",
              "      <td>OpenAI and AGI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.027697</td>\n",
              "      <td>Friendship with an AI Companion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.027369</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.024672</td>\n",
              "      <td>Math, Manim, Neural Networks &amp; Teaching with 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>Computer Architecture and Data Storage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>Artificial General Intelligence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>The War of Art</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>Artificial Consciousness and the Nature of Rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>Computer Vision</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceb9e28a-62b7-4788-88f6-87999eaaa40e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceb9e28a-62b7-4788-88f6-87999eaaa40e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceb9e28a-62b7-4788-88f6-87999eaaa40e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-092db922-ade8-4074-91c4-4775cd0a5914\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-092db922-ade8-4074-91c4-4775cd0a5914')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-092db922-ade8-4074-91c4-4775cd0a5914 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cf852634-ed88-4136-9259-a7d4c3dcdda0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tfidf_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cf852634-ed88-4136-9259-a7d4c3dcdda0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tfidf_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tfidf_results",
              "summary": "{\n  \"name\": \"tfidf_results\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006338408645982421,\n        \"min\": 0.0,\n        \"max\": 0.09700578022143057,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.09700578022143057,\n          0.031047140937826748,\n          0.010751173470593504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Searching for Signs of Life on Venus and Other Planets\",\n          \"Going Big in Business, Investing, and AI\",\n          \"Fermat\\u2019s Library and the Art of Studying Papers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_bert(query, bert_embeddings, podcast_pre_df):\n",
        "    query_embedding = generate_bert_embeddings([query]) # Pass query as a single-element list\n",
        "    # Reshape embeddings to 2D\n",
        "    query_embedding = query_embedding.reshape(query_embedding.shape[0], -1)\n",
        "    bert_embeddings_2d = bert_embeddings.reshape(bert_embeddings.shape[0], -1)\n",
        "    similarities = cosine_similarity(query_embedding, bert_embeddings_2d)\n",
        "    similarities_df = pd.DataFrame(similarities.T, columns=['sim'])\n",
        "    # Reset index of podcast_pre_df to ensure unique index for alignment\n",
        "    similarities_df['ep'] = podcast_pre_df.reset_index(drop=True)['title']  # Reset index of podcast_pre_df\n",
        "    return similarities_df.sort_values(by='sim', ascending=False)\n",
        "\n",
        "# Prueba con una consulta de ejemplo\n",
        "bert_results = retrieve_bert(query, bert_embeddings, podcast_pre_df)\n",
        "bert_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "fBGNd2UtDMt4",
        "outputId": "fc0bc6a9-cbd6-47b7-896f-77731c3c015f"
      },
      "id": "fBGNd2UtDMt4",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sim                       ep\n",
              "2  0.750658  AI in the Age of Reason\n",
              "0  0.729068                 Life 3.0\n",
              "1  0.715500            Consciousness\n",
              "3  0.670224            Deep Learning"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14daa4ef-b155-4eaf-b115-6db278873cb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.750658</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.729068</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.715500</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.670224</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14daa4ef-b155-4eaf-b115-6db278873cb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14daa4ef-b155-4eaf-b115-6db278873cb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14daa4ef-b155-4eaf-b115-6db278873cb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8fffe7f5-8fe3-434f-9f09-d6f89d2b3e1e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fffe7f5-8fe3-434f-9f09-d6f89d2b3e1e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8fffe7f5-8fe3-434f-9f09-d6f89d2b3e1e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6a33d53c-8982-4281-8a30-f875914e9dfa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bert_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6a33d53c-8982-4281-8a30-f875914e9dfa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bert_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bert_results",
              "summary": "{\n  \"name\": \"bert_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7290675044059753,\n          0.6702241897583008,\n          0.7506580352783203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Life 3.0\",\n          \"Deep Learning\",\n          \"AI in the Age of Reason\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step** 7: Retrieve and Compare Results\n",
        "\n",
        "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n"
      ],
      "metadata": {
        "id": "tVx4k-Ig4CHv"
      },
      "id": "tVx4k-Ig4CHv"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_results(similarities_df, top_n=5):\n",
        "    return similarities_df.head(top_n)\n",
        "\n",
        "top_n = 5\n"
      ],
      "metadata": {
        "id": "fyfWQWDyIMZb"
      },
      "id": "fyfWQWDyIMZb",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve top results for TF-IDF\n",
        "top_tfidf_results = get_top_results(tfidf_results, top_n)\n",
        "print(\"Top TF-IDF Results:\")\n",
        "top_tfidf_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "-Vk_dhUKJN_6",
        "outputId": "01c87406-a17d-4f0e-e80e-d03e2b946721"
      },
      "id": "-Vk_dhUKJN_6",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TF-IDF Results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          sim                                                 ep\n",
              "213  0.097006  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
              "17   0.031047                                     OpenAI and AGI\n",
              "120  0.027697                    Friendship with an AI Companion\n",
              "94   0.027369                                      Deep Learning\n",
              "117  0.024672  Math, Manim, Neural Networks & Teaching with 3..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5eec72f-dfe1-495f-97a1-37e02c1aa9c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0.097006</td>\n",
              "      <td>OpenAI Codex, GPT-3, Robotics, and the Future ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.031047</td>\n",
              "      <td>OpenAI and AGI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.027697</td>\n",
              "      <td>Friendship with an AI Companion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.027369</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.024672</td>\n",
              "      <td>Math, Manim, Neural Networks &amp; Teaching with 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5eec72f-dfe1-495f-97a1-37e02c1aa9c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5eec72f-dfe1-495f-97a1-37e02c1aa9c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5eec72f-dfe1-495f-97a1-37e02c1aa9c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d464cb1e-ff40-4b89-bc68-09d6fd4e839f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d464cb1e-ff40-4b89-bc68-09d6fd4e839f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d464cb1e-ff40-4b89-bc68-09d6fd4e839f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0bdba9e2-e84c-4415-ab2c-953a438065ed\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_tfidf_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0bdba9e2-e84c-4415-ab2c-953a438065ed button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top_tfidf_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_tfidf_results",
              "summary": "{\n  \"name\": \"top_tfidf_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03107871788765496,\n        \"min\": 0.024671506616340114,\n        \"max\": 0.09700578022143057,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.031047140937826748,\n          0.024671506616340114,\n          0.027696712682671737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"OpenAI and AGI\",\n          \"Math, Manim, Neural Networks & Teaching with 3Blue1Brown\",\n          \"Friendship with an AI Companion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve top results for BERT\n",
        "top_bert_results = get_top_results(bert_results, top_n)\n",
        "print(\"\\nTop BERT Results:\")\n",
        "top_bert_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "Kf6QJIDaJbiG",
        "outputId": "d9606bea-8ee7-4dde-fddb-d2c2f93007ed"
      },
      "id": "Kf6QJIDaJbiG",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top BERT Results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sim                       ep\n",
              "2  0.750658  AI in the Age of Reason\n",
              "0  0.729068                 Life 3.0\n",
              "1  0.715500            Consciousness\n",
              "3  0.670224            Deep Learning"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3a4c03e-72e2-4299-9cb2-dc1dea065bea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.750658</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.729068</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.715500</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.670224</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3a4c03e-72e2-4299-9cb2-dc1dea065bea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3a4c03e-72e2-4299-9cb2-dc1dea065bea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3a4c03e-72e2-4299-9cb2-dc1dea065bea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b0e87cd-82de-4d1e-a349-ac76506dbf19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b0e87cd-82de-4d1e-a349-ac76506dbf19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b0e87cd-82de-4d1e-a349-ac76506dbf19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1d7da37b-4360-4f30-b38c-1eb07088870f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_bert_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d7da37b-4360-4f30-b38c-1eb07088870f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top_bert_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_bert_results",
              "summary": "{\n  \"name\": \"top_bert_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7290675044059753,\n          0.6702241897583008,\n          0.7506580352783203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Life 3.0\",\n          \"Deep Learning\",\n          \"AI in the Age of Reason\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Test the IR System\n",
        "* Test the system with a sample query.\n",
        "\n",
        "* Retrieve and display the top results using both TF-IDF and BERT representations"
      ],
      "metadata": {
        "id": "NMghIoolJkJK"
      },
      "id": "NMghIoolJkJK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test query\n",
        "sample_query = 'I think, reminding ourselves that the reason we try to solve problems'"
      ],
      "metadata": {
        "id": "QoThzIEKJw5H"
      },
      "id": "QoThzIEKJw5H",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve results using TF-IDF\n",
        "tfidf_results = retrieve_tfidf(sample_query, vectorizer, podcast_tfidf_df, podcast_pre_df)\n",
        "top_tfidf_results = get_top_results(tfidf_results, top_n)\n",
        "print(\"Top TF-IDF Results for query '{}':\".format(sample_query))\n",
        "top_tfidf_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "wpcokvghJ34V",
        "outputId": "37b2049e-295a-4a2b-a397-f81312e03176"
      },
      "id": "wpcokvghJ34V",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TF-IDF Results for query 'I think, reminding ourselves that the reason we try to solve problems':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          sim                                                 ep\n",
              "157  0.074143   The Next Generation of Big Ideas and Brave Minds\n",
              "17   0.071229                                     OpenAI and AGI\n",
              "15   0.065721     Reinforcement Learning, Planning, and Robotics\n",
              "44   0.059648  IBM Watson, Jeopardy & Deep Conversations with AI\n",
              "292  0.058319                                           DeepMind"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c06957d-35c8-4690-8684-08b004f71a08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0.074143</td>\n",
              "      <td>The Next Generation of Big Ideas and Brave Minds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.071229</td>\n",
              "      <td>OpenAI and AGI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.065721</td>\n",
              "      <td>Reinforcement Learning, Planning, and Robotics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.059648</td>\n",
              "      <td>IBM Watson, Jeopardy &amp; Deep Conversations with AI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>0.058319</td>\n",
              "      <td>DeepMind</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c06957d-35c8-4690-8684-08b004f71a08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c06957d-35c8-4690-8684-08b004f71a08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c06957d-35c8-4690-8684-08b004f71a08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e588244b-8e3f-476b-9a99-07f1a4252cb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e588244b-8e3f-476b-9a99-07f1a4252cb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e588244b-8e3f-476b-9a99-07f1a4252cb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a8f2e31f-63d3-461a-8cfe-ef3cdf15fe5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_tfidf_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a8f2e31f-63d3-461a-8cfe-ef3cdf15fe5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top_tfidf_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_tfidf_results",
              "summary": "{\n  \"name\": \"top_tfidf_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006944521099687101,\n        \"min\": 0.0583189539148678,\n        \"max\": 0.07414301591585488,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.07122932982938907,\n          0.0583189539148678,\n          0.06572084416498042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"OpenAI and AGI\",\n          \"DeepMind\",\n          \"Reinforcement Learning, Planning, and Robotics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve results using BERT\n",
        "bert_results = retrieve_bert(sample_query, bert_embeddings, podcast_pre_df)\n",
        "top_bert_results = get_top_results(bert_results, top_n)\n",
        "print(\"\\nTop BERT Results for query '{}':\".format(sample_query))\n",
        "top_bert_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "w7D6Y28xJ7dp",
        "outputId": "941b01a0-cdb3-4d30-f88d-d352b22e478d"
      },
      "id": "w7D6Y28xJ7dp",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top BERT Results for query 'I think, reminding ourselves that the reason we try to solve problems':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sim                       ep\n",
              "2  0.864473  AI in the Age of Reason\n",
              "0  0.852647                 Life 3.0\n",
              "1  0.842820            Consciousness\n",
              "3  0.801064            Deep Learning"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58d2d12b-92c8-4f36-8a17-b2d907f08964\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.864473</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.852647</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.842820</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.801064</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58d2d12b-92c8-4f36-8a17-b2d907f08964')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58d2d12b-92c8-4f36-8a17-b2d907f08964 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58d2d12b-92c8-4f36-8a17-b2d907f08964');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab5a0b64-e34e-40ec-aca3-25d238bf2156\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab5a0b64-e34e-40ec-aca3-25d238bf2156')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab5a0b64-e34e-40ec-aca3-25d238bf2156 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_90b16af7-0b0b-4b87-b1de-502e39cc4ac0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_bert_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_90b16af7-0b0b-4b87-b1de-502e39cc4ac0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top_bert_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_bert_results",
              "summary": "{\n  \"name\": \"top_bert_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8526467084884644,\n          0.8010636568069458,\n          0.8644731044769287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Life 3.0\",\n          \"Deep Learning\",\n          \"AI in the Age of Reason\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "6a934919d95ac2de"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 9: Compare Results\n",
        "\n",
        "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
        "\n",
        "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n"
      ],
      "id": "6a934919d95ac2de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example #1"
      ],
      "metadata": {
        "id": "o5s9hl4oP5Xh"
      },
      "id": "o5s9hl4oP5Xh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test query\n",
        "sample_query = 'machine learning'\n",
        "# Retrieve results using TF-IDF\n",
        "tfidf_results = retrieve_tfidf(sample_query, vectorizer, podcast_tfidf_df, podcast_pre_df)\n",
        "top_tfidf_results = get_top_results(tfidf_results, top_n)\n",
        "print(\"Top TF-IDF Results for query '{}':\".format(sample_query))\n",
        "print(top_tfidf_results)\n",
        "# Retrieve results using BERT\n",
        "bert_results = retrieve_bert(sample_query, bert_embeddings, podcast_pre_df)\n",
        "top_bert_results = get_top_results(bert_results, top_n)\n",
        "print(\"\\nTop BERT Results for query '{}':\".format(sample_query))\n",
        "print(top_bert_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9bUPCssPzXp",
        "outputId": "5faf5a82-88bf-4056-c85e-8112762e3f49"
      },
      "id": "F9bUPCssPzXp",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TF-IDF Results for query 'machine learning':\n",
            "     sim                                                 ep\n",
            "318  0.0  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
            "0    0.0                                           Life 3.0\n",
            "1    0.0                                      Consciousness\n",
            "2    0.0                            AI in the Age of Reason\n",
            "3    0.0                                      Deep Learning\n",
            "\n",
            "Top BERT Results for query 'machine learning':\n",
            "        sim                       ep\n",
            "2  0.839966  AI in the Age of Reason\n",
            "0  0.812407                 Life 3.0\n",
            "1  0.798970            Consciousness\n",
            "3  0.785222            Deep Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example #2"
      ],
      "metadata": {
        "id": "sVGrXa82QLO9"
      },
      "id": "sVGrXa82QLO9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test query\n",
        "sample_query = 'artificial intelligence'\n",
        "# Retrieve results using TF-IDF\n",
        "tfidf_results = retrieve_tfidf(sample_query, vectorizer, podcast_tfidf_df, podcast_pre_df)\n",
        "top_tfidf_results = get_top_results(tfidf_results, top_n)\n",
        "print(\"Top TF-IDF Results for query '{}':\".format(sample_query))\n",
        "print(top_tfidf_results)\n",
        "# Retrieve results using BERT\n",
        "bert_results = retrieve_bert(sample_query, bert_embeddings, podcast_pre_df)\n",
        "top_bert_results = get_top_results(bert_results, top_n)\n",
        "print(\"\\nTop BERT Results for query '{}':\".format(sample_query))\n",
        "print(top_bert_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5o6S9BeQKVV",
        "outputId": "35dc6669-2e87-422f-a71d-cb6e17783336"
      },
      "id": "w5o6S9BeQKVV",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TF-IDF Results for query 'artificial intelligence':\n",
            "     sim                                                 ep\n",
            "318  0.0  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
            "0    0.0                                           Life 3.0\n",
            "1    0.0                                      Consciousness\n",
            "2    0.0                            AI in the Age of Reason\n",
            "3    0.0                                      Deep Learning\n",
            "\n",
            "Top BERT Results for query 'artificial intelligence':\n",
            "        sim                       ep\n",
            "2  0.853677  AI in the Age of Reason\n",
            "0  0.832118                 Life 3.0\n",
            "1  0.816438            Consciousness\n",
            "3  0.777315            Deep Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test query\n",
        "sample_query = 'GPT'\n",
        "# Retrieve results using TF-IDF\n",
        "tfidf_results = retrieve_tfidf(sample_query, vectorizer, podcast_tfidf_df, podcast_pre_df)\n",
        "top_tfidf_results = get_top_results(tfidf_results, top_n)\n",
        "print(\"Top TF-IDF Results for query '{}':\".format(sample_query))\n",
        "print(top_tfidf_results)\n",
        "# Retrieve results using BERT\n",
        "bert_results = retrieve_bert(sample_query, bert_embeddings, podcast_pre_df)\n",
        "top_bert_results = get_top_results(bert_results, top_n)\n",
        "print(\"\\nTop BERT Results for query '{}':\".format(sample_query))\n",
        "print(top_bert_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xOV0IZZQXpj",
        "outputId": "75d4486c-78fd-4526-97d0-f754470f252f"
      },
      "id": "_xOV0IZZQXpj",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TF-IDF Results for query 'GPT':\n",
            "          sim                                                 ep\n",
            "213  0.097006  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
            "17   0.031047                                     OpenAI and AGI\n",
            "120  0.027697                    Friendship with an AI Companion\n",
            "94   0.027369                                      Deep Learning\n",
            "117  0.024672  Math, Manim, Neural Networks & Teaching with 3...\n",
            "\n",
            "Top BERT Results for query 'GPT':\n",
            "        sim                       ep\n",
            "2  0.750658  AI in the Age of Reason\n",
            "0  0.729068                 Life 3.0\n",
            "1  0.715500            Consciousness\n",
            "3  0.670224            Deep Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrieve and print the top results for a given query using both TF-IDF and BERT representations. This allows us to compare the outputs of the two methods directly, showing which podcast episodes are most relevant according to each approach. The TF-IDF results focus on keyword frequency and importance, while the BERT results capture the contextual meaning of the text, providing a richer, more nuanced match.\n",
        "For the queries \"machine learning,\" \"artificial intelligence,\" and \"GPT,\" the TF-IDF method produced very low or zero similarity scores, indicating it failed to effectively match the relevant episodes. In contrast, the BERT method produced higher similarity scores and consistently identified relevant episodes, such as \"AI in the Age of Reason,\" \"Life 3.0,\" and \"Deep Learning.\" This demonstrates that BERT's contextual understanding provides more accurate and meaningful results compared to the keyword-focused approach of TF-IDF, especially for complex queries related to AI and machine learning."
      ],
      "metadata": {
        "id": "MpDDSQlDPaai"
      },
      "id": "MpDDSQlDPaai"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions:\n",
        "\n",
        "* Follow the steps outlined above to implement the IR system.\n",
        "* Run the provided code snippets to understand how each part of the system works.\n",
        "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
        "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
        "* Document your findings and any improvements you make to the system."
      ],
      "metadata": {
        "id": "FJP-VuopKW2A"
      },
      "id": "FJP-VuopKW2A"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3aff22622b2e4eb28334a6ada86f80e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21f3232812ca4a20afb5f366ad32151e",
              "IPY_MODEL_8d2e8ad2628b443eb3781ad9e23647f2",
              "IPY_MODEL_80cc2f5a9b024729b3941b35ed164daa"
            ],
            "layout": "IPY_MODEL_bdaf58a9ebb14a12ba1d3a5276b2f56c"
          }
        },
        "21f3232812ca4a20afb5f366ad32151e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b803d0122b84ce1abe75ee52cbfe6d6",
            "placeholder": "",
            "style": "IPY_MODEL_a042b5ce9c324fef9e506bdbb6834533",
            "value": "tokenizer_config.json:100%"
          }
        },
        "8d2e8ad2628b443eb3781ad9e23647f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ddfa49f3254ed297a65a0ea44f125f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_542ba0560578403894979a90ee1b9d7a",
            "value": 48
          }
        },
        "80cc2f5a9b024729b3941b35ed164daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb376b7356234e52838f5b4042172b80",
            "placeholder": "",
            "style": "IPY_MODEL_b2020d74784f4560b4e6b61b2768bf73",
            "value": "48.0/48.0[00:00&lt;00:00,2.14kB/s]"
          }
        },
        "bdaf58a9ebb14a12ba1d3a5276b2f56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b803d0122b84ce1abe75ee52cbfe6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a042b5ce9c324fef9e506bdbb6834533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ddfa49f3254ed297a65a0ea44f125f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542ba0560578403894979a90ee1b9d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb376b7356234e52838f5b4042172b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2020d74784f4560b4e6b61b2768bf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d5b1ba443624179814886b9c0047420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88bd1df52b154aa0bf5ef87a95b5a491",
              "IPY_MODEL_bb60eecee5b14a58a14f05cdbc89b12d",
              "IPY_MODEL_3c1e127f8916432cb41ebf13f69c6a02"
            ],
            "layout": "IPY_MODEL_ad5e517b816b435390053f5650f58956"
          }
        },
        "88bd1df52b154aa0bf5ef87a95b5a491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b8243c61ae4c50880e9f7016d26fd5",
            "placeholder": "",
            "style": "IPY_MODEL_0517c5ae52d94ee5bdee364aec1ba974",
            "value": "vocab.txt:100%"
          }
        },
        "bb60eecee5b14a58a14f05cdbc89b12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f05b8180b404644b8793f42b9cd4041",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d910d9e5c75b45e48df26f68dfee7044",
            "value": 231508
          }
        },
        "3c1e127f8916432cb41ebf13f69c6a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ee5f22357442cdb0921196e28fe907",
            "placeholder": "",
            "style": "IPY_MODEL_14cb3cc0f5b84788946b63d7523bec58",
            "value": "232k/232k[00:00&lt;00:00,4.22MB/s]"
          }
        },
        "ad5e517b816b435390053f5650f58956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b8243c61ae4c50880e9f7016d26fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0517c5ae52d94ee5bdee364aec1ba974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f05b8180b404644b8793f42b9cd4041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d910d9e5c75b45e48df26f68dfee7044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ee5f22357442cdb0921196e28fe907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14cb3cc0f5b84788946b63d7523bec58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb957c7fab3246549e67c8bf65c8eec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee7dc014d264ffdb2df2d5a5a7e37b8",
              "IPY_MODEL_b297b98d455f4c1da7a08057335c60cb",
              "IPY_MODEL_67624bea01ed4e95be70da1cffcf4a13"
            ],
            "layout": "IPY_MODEL_6365a2e4d32348f7ad36c7d41eea3653"
          }
        },
        "5ee7dc014d264ffdb2df2d5a5a7e37b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044e46551b034549a748b3cd6964b7d2",
            "placeholder": "",
            "style": "IPY_MODEL_386ad8c951b14bcd895697439f316421",
            "value": "tokenizer.json:100%"
          }
        },
        "b297b98d455f4c1da7a08057335c60cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_946b55770e004d4ab5ced4885137feb6",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5ec54e37b21427a897dd29bc1357647",
            "value": 466062
          }
        },
        "67624bea01ed4e95be70da1cffcf4a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b14b6701d6f04536a0d5f28cbf2bb0f3",
            "placeholder": "",
            "style": "IPY_MODEL_c18ea041e51a4b9397d262dc3292792b",
            "value": "466k/466k[00:00&lt;00:00,7.63MB/s]"
          }
        },
        "6365a2e4d32348f7ad36c7d41eea3653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044e46551b034549a748b3cd6964b7d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386ad8c951b14bcd895697439f316421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "946b55770e004d4ab5ced4885137feb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ec54e37b21427a897dd29bc1357647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b14b6701d6f04536a0d5f28cbf2bb0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18ea041e51a4b9397d262dc3292792b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925c00bd16994ff4959218659b8b530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b556e7d794a4c28b5d6c34b952132e3",
              "IPY_MODEL_167cde39650e4814a2622202397d51e6",
              "IPY_MODEL_c96ccd4a2e7d47e999087a3500d70dfd"
            ],
            "layout": "IPY_MODEL_be168ad2fb4e4d6da7b3c681eb4dd886"
          }
        },
        "9b556e7d794a4c28b5d6c34b952132e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a312f444fa648cebec9eba198f6e402",
            "placeholder": "",
            "style": "IPY_MODEL_50470bf9658f454c9b1cfa3508c67b9e",
            "value": "config.json:100%"
          }
        },
        "167cde39650e4814a2622202397d51e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0e6a44882d4659907176d5dc63b5bb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc03d2e99635490cb77bf5d44d6fdb39",
            "value": 570
          }
        },
        "c96ccd4a2e7d47e999087a3500d70dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5f448582354bc48dedfbb9bd73358f",
            "placeholder": "",
            "style": "IPY_MODEL_b0eaf67700814947b382c6f5d207872c",
            "value": "570/570[00:00&lt;00:00,26.7kB/s]"
          }
        },
        "be168ad2fb4e4d6da7b3c681eb4dd886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a312f444fa648cebec9eba198f6e402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50470bf9658f454c9b1cfa3508c67b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff0e6a44882d4659907176d5dc63b5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc03d2e99635490cb77bf5d44d6fdb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a5f448582354bc48dedfbb9bd73358f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0eaf67700814947b382c6f5d207872c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d412bf015b94761812d123c56829b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650342e827c3487b90b80baa9caa540f",
              "IPY_MODEL_5d73eaecb4264b19b090962bc0a9ab7b",
              "IPY_MODEL_e4605aa917584da6be8d11730ad29e03"
            ],
            "layout": "IPY_MODEL_e290318a22f2443d8b7d9efe166b345a"
          }
        },
        "650342e827c3487b90b80baa9caa540f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_581501b3a81644e987631ce05ad836e9",
            "placeholder": "",
            "style": "IPY_MODEL_f1925786d1cd47feb75e4fd7d9545632",
            "value": "model.safetensors:100%"
          }
        },
        "5d73eaecb4264b19b090962bc0a9ab7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af090144a6594445aac6b9d5c60de0a4",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5a47f9c066a44a88b0e309639844a3f",
            "value": 440449768
          }
        },
        "e4605aa917584da6be8d11730ad29e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f596ac033ed3464e99c590ca0efb9e02",
            "placeholder": "",
            "style": "IPY_MODEL_4cf114bde49844e48efcd0a5f8e4467a",
            "value": "440M/440M[00:02&lt;00:00,256MB/s]"
          }
        },
        "e290318a22f2443d8b7d9efe166b345a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581501b3a81644e987631ce05ad836e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1925786d1cd47feb75e4fd7d9545632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af090144a6594445aac6b9d5c60de0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a47f9c066a44a88b0e309639844a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f596ac033ed3464e99c590ca0efb9e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf114bde49844e48efcd0a5f8e4467a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}